\documentclass[twoside]{book}
\setcounter{tocdepth}{1}
\usepackage[a4paper,
    inner=4cm,  % Inner margin (binding side)
    outer=3.5cm,  % Outer margin
    top=3cm,
    bottom=3cm
]{geometry}
\usepackage[hidelinks]{hyperref} 
%\usepackage{mathpazo}
%\usepackage{newtxtext,newtxmath}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{fancyhdr}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage[utf8]{inputenc}
\usepackage{tcolorbox}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt} 
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta, positioning}
\usepackage{pgfplots}
\usepackage{pgf-pie}
\pgfplotsset{compat=1.18}
\usetikzlibrary{fillbetween,patterns,shapes,arrows.meta}
\usetikzlibrary{calc}
\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black, fill=gray!10]
\tikzstyle{arrow} = [thick,->,>=stealth]
\usepackage{subcaption}
\pgfplotsset{compat=1.17}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{array}
\usepackage{float}
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0pt}
\tcbset{
  heading/.style={
    colback=white,
    colframe=gray!95!white,
    fonttitle=\bfseries,
    title=#1
  }
}
\newtcolorbox{textbox}[1][]{%
  colback=white,
  colframe=gray!95!white,
  #1
}

\title{Fundamentals of Probability and Statistics}
\author{Sandip Karar}
\date{\today}

\begin{document}

\begin{titlepage}
    \centering
    \vspace*{3cm}
    
    \begin{tikzpicture}[remember picture,overlay]
        % Draw a thin decorative frame around the page content area
        \draw[line width=1.5pt]
            ($(current page.north west)+(4cm,-3cm)$) rectangle ($(current page.south east)+(-3.5cm,3cm)$);
        \draw[line width=1.5pt]
            ($(current page.north west)+(3.7cm,-2.7cm)$) rectangle ($(current page.south east)+(-3.2cm,2.7cm)$);
            
    \end{tikzpicture}
    
    {\fontsize{24pt}{28pt}\bfseries\scshape Basics of Probability and Statistics\par}
    \vspace{1.2cm}
    
    
    {\Large\itshape An In-Depth Exploration of Core Concepts and Methods\par}
    
    \vspace{2cm}
    
    {\large\bfseries Sandip Karar\par}
    \vspace{0.5cm}
    
    {\normalsize\today\par}
    \vspace{2cm}
    
      \begin{center}   
        \begin{tikzpicture}
            \begin{axis}[
                no markers, domain=-4:4, samples=100,
                axis lines=center,
                xlabel={$x/\sigma$}, 
                axis y line=none,
                ymin=0, ymax=0.5,
                xmin=-4, xmax=4,
                height=8cm, width=12cm,
                ytick=\empty
              ]
              % PDF curve
              \addplot [very thick, blue] {1/sqrt(2*pi)*exp(-x^2/2)};
              % Shaded right-tail for z>1.5
              
              
              \addplot [draw=none, fill=red!20, domain=-3:3] {1/sqrt(2*pi)*exp(-x^2/2)-0.004} \closedcycle;
              % Vertical guide line
              \draw[thick, dashed] (axis cs:-3,0) -- (axis cs:-3,{1/sqrt(2*pi)*exp(-0.1^2/2)});
              \draw[thick, dashed] (axis cs:3,0) -- (axis cs:3,{1/sqrt(2*pi)*exp(-0.1^2/2)});
                        
              
              \addplot [draw=none, fill=green!20, domain=-2:2] {1/sqrt(2*pi)*exp(-x^2/2)-0.004} \closedcycle;
              % Vertical guide line
              \draw[thick, dashed] (axis cs:-2,0) -- (axis cs:-2,{1/sqrt(2*pi)*exp(-0.1^2/2)});
              \draw[thick, dashed] (axis cs:2,0) -- (axis cs:2,{1/sqrt(2*pi)*exp(-0.1^2/2)});
              
              \addplot [draw=none, fill=blue!20, domain=-1:1] {1/sqrt(2*pi)*exp(-x^2/2)-0.004} \closedcycle;
              % Vertical guide line
              \draw[thick, dashed] (axis cs:-1,0) -- (axis cs:-1,{1/sqrt(2*pi)*exp(-0.1^2/2)});
              \draw[thick, dashed] (axis cs:1,0) -- (axis cs:1,{1/sqrt(2*pi)*exp(-0.1^2/2)});
              
              \node at (axis cs:0,0.3) {\large $68.27\%$};
              \node at (axis cs:0,0.2) {\large $95.45\%$};
              \node at (axis cs:0,0.1) {\large $99.73\%$};
              
              \draw[ thick, black] (axis cs:-3,0.07) -- (axis cs:3,0.07);
              \draw[ thick, black] (axis cs:-2,0.17) -- (axis cs:2,0.17);
              \draw[ thick, black] (axis cs:-1,0.27) -- (axis cs:1,0.27);
            \end{axis}
          \end{tikzpicture}
      \end{center}
       
\end{titlepage}

%\maketitle

\tableofcontents

\chapter{Descriptive Statistics}

\section{Introduction}
Statistics is a branch of mathematics that deals with the collection, organization, analysis, interpretation, and presentation of data. It provides tools for making informed decisions in the presence of uncertainty.

\subsection{Uses of Statistics}

Statistics is widely used in various fields such as:

\begin{itemize}
    \item \textbf{Education}: Analyzing student performance and improving teaching methods.
    \item \textbf{Business}: Making informed decisions based on market trends and consumer behavior.
    \item \textbf{Healthcare}: Understanding the effectiveness of treatments and tracking disease outbreaks.
    \item \textbf{Government}: Planning and policy-making based on population data.
\end{itemize}

\subsection{Types of Data}

Data can be categorized based on their nature and measurement levels.

\textbf{1. Qualitative (Categorical) Data}

These are non-numeric data that describe categories or groups.

\begin{itemize}
    \item \textbf{Nominal}: Categories without any inherent order (e.g., colors, gender).
    \item \textbf{Ordinal}: Categories with a meaningful order but no fixed interval between them (e.g., rankings).
\end{itemize}

\textbf{2. Quantitative (Numerical) Data}

These are numeric data representing counts or measurements.

\begin{itemize}
    \item \textbf{Discrete}: Countable values (e.g., number of students).
    \item \textbf{Continuous}: Measurable quantities that can take any value within a range (e.g., height, weight).
\end{itemize}

\subsection{Data Collection Methods}

Collecting accurate data is crucial for meaningful analysis. Common methods include:

\begin{itemize}
    \item \textbf{Surveys}: Gathering information through questionnaires.
    \item \textbf{Experiments}: Conducting controlled studies to observe outcomes.
    \item \textbf{Observations}: Recording data based on direct observation.
    \item \textbf{Existing Records}: Utilizing previously collected data.
\end{itemize}

\subsection{Organizing Data}

Once data is collected, organizing it helps in understanding patterns and trends.

\textbf{1. Frequency Distribution Table}

A frequency distribution table lists data values and their corresponding frequencies.

\begin{table}[h]
\centering
\begin{tabular}{c|c}
\hline
\textbf{Number of Books} & \textbf{Number of Students} \\
\hline
0--2 & 5 \\
3--5 & 12 \\
6--8 & 17 \\
9--11 & 8 \\
12--14 & 3 \\
\hline
\end{tabular}
\caption{Number of Books Read by Students}
\end{table}

\textbf{2. Relative Frequency}

Relative frequency represents the proportion of observations within each category.

\begin{table}[h]
\centering
\begin{tabular}{c|c}
\hline
\textbf{Number of Books} & \textbf{Relative Frequency} \\
\hline
0--2 & 0.10 \\
3--5 & 0.24 \\
6--8 & 0.34 \\
9--11 & 0.16 \\
12--14 & 0.06 \\
\hline
\end{tabular}
\caption{Relative Frequency of Books Read}
\end{table}

\subsection{Displaying Data}

Visual representations make it easier to comprehend data.

\textbf{1. Bar Graph}

Bar graphs are used for categorical data.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    ybar,
    symbolic x coords={Red, Blue, Green, Yellow},
    xtick=data,
    ylabel={Number of Students},
    xlabel={Favorite Color},
    ymin=0,
    ymax=30,
    bar width=15pt,
    nodes near coords,
    width=0.8\textwidth,
    height=0.4\textwidth
]
\addplot coordinates {(Red,20) (Blue,25) (Green,15) (Yellow,10)};
\end{axis}
\end{tikzpicture}
\caption{Favorite Colors of Students}
\end{figure}

\textbf{2. Pie Chart}

Pie charts show the proportion of categories within a whole.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\pie[text=legend, radius=2.5]{40/Apples, 30/Bananas, 20/Cherries, 10/Dates}
\end{tikzpicture}
\caption{Fruit Preferences}
\end{figure}

\textbf{3. Histogram}

Histograms are used for continuous numerical data.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    ybar,
    ymin=0,
    ymax=15,
    xlabel={Marks Range},
    ylabel={Number of Students},
    xtick=data,
    symbolic x coords={0--10,11--20,21--30,31--40,41--50},
    bar width=15pt,
    nodes near coords,
    width=0.8\textwidth,
    height=0.4\textwidth
]
\addplot coordinates {(0--10,2) (11--20,5) (21--30,9) (31--40,12) (41--50,7)};
\end{axis}
\end{tikzpicture}
\caption{Distribution of Marks}
\end{figure}

\textbf{4. Line Graph}

Line graphs depict data trends over time.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    xlabel={Month},
    ylabel={Temperature ($^\circ$C)},
    xtick=data,
    symbolic x coords={Jan, Feb, Mar, Apr, May},
    ymin=0,
    ymax=40,
    width=0.8\textwidth,
    height=0.4\textwidth
]
\addplot coordinates {(Jan,15) (Feb,18) (Mar,25) (Apr,30) (May,35)};
\end{axis}
\end{tikzpicture}
\caption{Monthly Average Temperature}
\end{figure}

\section{Measures of Central Tendency}

Quite often, data exhibit a tendency to cluster around a central value. Measures of central tendency are numerical indicators that describe this central value of a data set. The most common measures include the mean, median, and mode. Each measure tells us something different about our data, and knowing when to use each one can really help us make sense of the numbers.

% \begin{center}
% \begin{tikzpicture}[
%   level 1/.style={sibling distance=30mm, level distance=20mm},
%   level 2/.style={sibling distance=45mm, level distance=20mm},
%   every node/.style={rectangle, draw=black, align=center, minimum width=2cm, minimum height=1cm}
%   ]

% \node {Measures of Central Tendency}
%   child {node {Mean}
%     child {node {Arithmetic Mean (AM)}}
%     child {node {Geometric Mean (GM)}}
%     child {node {Harmonic Mean (HM)}}
%   }
%   child {node {Median}}
%   child {node {Mode}};

% \end{tikzpicture}
% \end{center}

\begin{center}
    \includegraphics[scale=0.5]{pic/moct.drawio.png}
\end{center}

\subsection{Mean}

The mean (or average) is the most commonly used measure of central tendency and is defined in several forms:

\begin{itemize}
    \item \textbf{Arithmetic Mean (AM):} 
    \begin{itemize}
        \item Simple AM: For a dataset \( x_1, x_2, \dots, x_n \), the arithmetic mean is given by:
    \begin{textbox}
    \[
    \overline{x} = \dfrac{1}{n} \sum_{i=1}^{n} x_i
    \]
    \end{textbox}
    \item Weighted AM: When each value \( x_i \) has an associated frequency \( f_i \), the weighted arithmetic mean is:
    \begin{textbox}
    \[
    \overline{x} = \dfrac{\sum_{i=1}^{n} f_i x_i}{\sum_{i=1}^{n} f_i}
    \]
    \end{textbox}
    \end{itemize}

\begin{textbox}
        \textbf{Theorem}: If \( x_i = a \) (constant) for all \( i \), then the arithmetic mean is also \( a \), that is,
\[
\overline{x} = a.
\]
\end{textbox}

\textbf{Proof:}
\begin{align*}
\overline{x} &= \frac{1}{n} \sum_{i=1}^n x_i 
       = \frac{1}{n} \sum_{i=1}^n a = \frac{1}{n} \cdot n a = a
\end{align*}
\hfill $\blacksquare$

\begin{textbox}
\textbf{Theorem}: If \( y_i = a + x_i \), then the mean of \( y \) is given by:
\[
\overline{y} = a + \overline{x}.
\]
\end{textbox}

\textbf{Proof:}
\begin{align*}
\overline{y} &= \frac{1}{n} \sum_{i=1}^n y_i = \frac{1}{n} \sum_{i=1}^n (a + x_i) = \frac{1}{n} \left( \sum_{i=1}^n a + \sum_{i=1}^n x_i \right) \\
       &= \frac{1}{n} \left( n a + \sum_{i=1}^n x_i \right) = a + \overline{x}.
\end{align*}
\hfill $\blacksquare$

\begin{textbox}
\textbf{Theorem}: Let a dataset be composed of two distinct groups of observations:

\begin{itemize}
  \item Group 1 consists of \( n_1 \) observations with arithmetic mean \( \overline{x}_1 \),
  \item Group 2 consists of \( n_2 \) observations with arithmetic mean \( \overline{x}_2 \).
\end{itemize}

Then, the arithmetic mean \( \overline{x} \) of the combined dataset (of size \( n_1 + n_2 \)) is given by:
\[
\overline{x} = \dfrac{n_1 \overline{x}_1 + n_2 \overline{x}_2}{n_1 + n_2}.
\]
\end{textbox}

\textbf{Proof}: \text{Total sum of group 1} is $n_1 \overline{x}_1$ and \text{total sum of group 2} is $n_2 \overline{x}_2$.

Then total sum = $n_1 \overline{x}_1 + n_2 \overline{x}_2$

\text{Total number of observations} = $n_1 + n_2$

Therefore, combined AM = $\overline{x} = \dfrac{\text{Total sum}}{\text{Total number of observations}} \dfrac{n_1 \overline{x}_1 + n_2 \overline{x}_2}{n_1 + n_2}$

\hfill $\blacksquare$

    \item \textbf{Geometric Mean (GM):} Geometric mean of a set of $n$ observation is the $n$th root of their product. It is only defined for positive values.

    \begin{itemize}
        \item Simple GM:
        \begin{textbox}
    \[
    x_G = \left( \prod_{i=1}^{n} x_i \right)^{1/n} = \sqrt[n]{x_1 x_2 \dots x_n}
    \]
    \end{textbox}
    \item Weighted GM:
    \begin{textbox}
    \[
    x_G = \left( \prod_{i=1}^{n} x_i^{f_i} \right)^{1/N} = \sqrt[N]{x_1^{f_1} x_2^{f_2} \dots x_n^{f_n}}
    \]
    \end{textbox}
    \end{itemize}
    Where $$N = \sum_{i=1}^n f_i$$

        \begin{textbox}
        \textbf{Theorem}: The GM of a set of positive values \( x_1, x_2, \dots, x_n \) is equal to the antilogarithm (exponential) of the AM of their logarithms:
\[
\mathrm{GM} = \exp\left( \frac{1}{n} \sum_{i=1}^n \log x_i \right)
\]
    \end{textbox}

\textbf{Proof:}
\begin{align*}
\mathrm{GM} &= \left( \prod_{i=1}^n x_i \right)^{1/n} = \exp\left( \log \left( \prod_{i=1}^n x_i \right)^{1/n} \right) \\
            &= \exp\left( \frac{1}{n} \log \left( \prod_{i=1}^n x_i \right) \right) = \exp\left( \frac{1}{n} \sum_{i=1}^n \log x_i \right)
\end{align*}
\hfill $\blacksquare$

\begin{textbox}
\textbf{Theorem}: Suppose we have two groups:
\begin{itemize}
  \item Group 1 has \( N_1 \) positive values with geometric mean \( x_{G_1} \),
  \item Group 2 has \( N_2 \) positive values with geometric mean \( x_{G_2} \).
\end{itemize}
Then the combined geometric mean \( \mathrm{GM} \) of all \( N_1 + N_2 \) values is:
\[
\mathrm{GM} = \left( x_{G_1}^{N_1} \cdot x_{G_2}^{N_2} \right)^{1/(N_1 + N_2)}
\]
\end{textbox}

\textbf{Proof}: Let the product of values in group 1 be \( P_1 = \prod_{i=1}^{N_1} x_i \), so that:
\[
x_{G_1} = \left( P_1 \right)^{1/N_1} \Rightarrow P_1 = x_{G_1}^{N_1}
\]

Similarly, for group 2:
\[
P_2 = \prod_{j=1}^{N_2} y_j = x_{G_2}^{N_2}
\]

Then the overall product:
\[
P = P_1 \cdot P_2 = x_{G_1}^{N_1} \cdot x_{G_2}^{N_2}
\]

The combined GM is:
\begin{align*}
\mathrm{GM} &= \left( P \right)^{1/(N_1 + N_2)} = \left( x_{G_1}^{N_1} \cdot x_{G_2}^{N_2} \right)^{1/(N_1 + N_2)}
\end{align*}

\hfill $\blacksquare$

    \item \textbf{Harmonic Mean (HM):} Harmonic Mean of a set of observations is the reciprocal of the arithmetic mean of the reciprocals.
    \begin{itemize}
        \item Simple HM:
        \begin{textbox}
    \[
    x_H = \dfrac{1}{ \frac{1}{n}\sum_{i=1}^{n} \frac{1}{x_i}} = \dfrac{n}{\sum_{i=1}^{n} \frac{1}{x_i}}
    \]
    \end{textbox}
    \item Weighted HM:
    \begin{textbox}
    \[
    x_H = \dfrac{1}{ \frac{1}{N}\sum_{i=1}^{n} \frac{f_i}{x_i}} = \dfrac{N}{\sum_{i=1}^{n} \frac{f_i}{x_i}}
    \]
    \end{textbox}
    \end{itemize}

\end{itemize}

It is important to note where to use GM and where to use HM. GM is useful for averaging \textbf{ratios}, \textbf{rates} and \textbf{percentages}. As an illustration, we consider the following example.

\textbf{Example}: The ratio of the prices in 1994 and to those in 1982 for four commodities are $0.92, 1.25, 1.75$ and $0.85$. To get the average price ratio use geometric mean
\begin{align*}
    \log x_G &= \frac{1}{n}\left(\log 0.92+ \log 1.25+ \log 1.75 + \log 0.85\right)\\
    &= 0.5829 = \log 1.1436 \\
    \Rightarrow x_G &= 1.1436
\end{align*}


GM is also useful if one wants to determine the values of a variable at the midpoint of a time interval when the variable changes over time exponentially. Thus if the value at two points $0$ and $t$ be $a$ and $ar^t$, then its value at the midpoint $\frac{t}{2}$ is $(a \times ar^t)^{1/2} = ar^{t/2}$.

Now consider the following example:

\textbf{Example}: A person goes from $X$ to $Y$ on cycle at $20$ km/h and returns at $24$ km/h. What is the average speed for the entire trip?

If we use AM, then the average speed is
$$\frac{1}{2}(20+24) = 22 \text{ km/h}$$
But is this correct?

Consider the total distance between $X$ and $Y$ is $1$ km for the sake of simplicity. So the total distance covered = $2$ km. The time taken for the person to go from $X$ to $Y$ is $\frac{1}{20} = 0.05$ hr and the time taken to return is $\frac{1}{24} = 0.04166$ hr.

Therefore average speed = $\dfrac{\text{Total distance}}{\text{Total time}} = \dfrac{2}{0.05+0.04166} = 21.8$ km/h. 

Clearly, the AM value of $22$ km/h overestimates the actual average speed. Now consider the harmonic mean (HM) of the two speeds: $$\dfrac{2}{\frac{1}{20}+\frac{1}{24}} = 21.8 \text{ km/h}$$

This matches the correct value.

Now where to use the HM? The harmonic mean is particularly useful when dealing with quantities expressed in the form ``$x$ per unit $y$'', such as ``km per hour'', ``rupees per kg'', and similar rates. Here $x$ and $y$ are unit of measures, not numeric variables.

\medskip

\begin{textbox}
\textbf{Rule of Thumb:}
\begin{itemize}
    \item Use the \textbf{harmonic mean (HM)} when equal quantities of $x$ are involved.
    \item Use the \textbf{arithmetic mean (AM)} when equal quantities of $y$ are involved.
\end{itemize}
\end{textbox}

\medskip

This principle can be illustrated with the following example.

\textbf{Example}: Suppose a train covers \textbf{\( n \) equal distances}, each of \( s \) kilometers, with speeds \( v_1, v_2, \dots, v_n \) km/h. The average speed is the total distance divided by the total time taken. Thus,

\[
\text{Average speed} = \frac{ns}{\frac{s}{v_1} + \frac{s}{v_2} + \dots + \frac{s}{v_n}} 
= \frac{n}{\frac{1}{v_1} + \frac{1}{v_2} + \dots + \frac{1}{v_n}} 
= \frac{n}{\sum_{i=1}^n \frac{1}{v_i}}
\]

This is the \textbf{harmonic mean (HM)} of the given speeds.

\medskip

On the other hand, if the train travels for \textbf{\( n \) equal time intervals}, each of duration \( t \) hours, at speeds \( v_1, v_2, \dots, v_n \) km/h, then the total distance covered is:

\[
\text{Total distance} = v_1t + v_2t + \dots + v_nt = t(v_1 + v_2 + \dots + v_n)
\]

and the total time is \( nt \). So, the average speed is:

\[
\text{Average speed} = \frac{t(v_1 + v_2 + \dots + v_n)}{nt} = \frac{v_1 + v_2 + \dots + v_n}{n} 
= \frac{1}{n} \sum_{i=1}^n v_i
\]

which is the \textbf{arithmetic mean (AM)} of the given speeds.


\begin{textbox}
    \textbf{Theorem}: The sum of squared deviations from a constant \( A \) is minimized when \( A \) equals the arithmetic mean \( \overline{x} \), i.e.,

\[
\sum_{i=1}^n (x_i - A)^2 \text{ is minimized when } A = \overline{x}
\]
\end{textbox}

\textbf{Proof}: Let \( S(A) = \sum_{i=1}^n (x_i - A)^2 \). Expand this:

\[
S(A) = \sum_{i=1}^n (x_i^2 - 2Ax_i + A^2) 
= \sum x_i^2 - 2A\sum x_i + nA^2
\]

To minimize \( S(A) \), take derivative with respect to \( A \) and set it to zero:

\[
\frac{dS}{dA} = -2\sum x_i + 2nA = 0 \quad \Rightarrow \quad A = \frac{1}{n} \sum x_i = \overline{x}
\]

Now, take the second derivative:

\[
\frac{d^2S}{dA^2} = 2n > 0
\]

Since the second derivative is positive, the function \( S(A) \) has a minimum at \( A = \overline{x} \).

\hfill $\blacksquare$

\begin{textbox}
\textbf{Theorem}: For two observations, \[ \text{GM}^2 = \text{AM} \times \text{HM} \]
\end{textbox}

\textbf{Proof}: Let \( a \) and \( b \) be two observations (positive numbers).

Compute left-hand side:

\[
\text{GM}^2 = (\sqrt{ab})^2 = ab
\]

Compute right-hand side:

\[
\text{AM} \times \text{HM} = \left( \frac{a + b}{2} \right) \left( \frac{2ab}{a + b} \right) = ab
\]

Hence, \[ \text{GM}^2 = \text{AM} \times \text{HM} \]
\hfill $\blacksquare$

\begin{textbox}
\textbf{Theorem}: For any set of \( n \) positive real numbers \( x_1, x_2, \dots, x_n \), the following inequality holds:

\[
\text{AM} \geq \text{GM} \geq \text{HM}
\]

with equality if and only if \( x_1 = x_2 = \dots = x_n \).
\end{textbox}

\textbf{Proof}: Let \( x_1, x_2, \dots, x_n \) be positive real numbers.

\medskip
\begin{itemize}
\item \textbf{Step 1: Proving \( \text{AM} \geq \text{GM} \)}

We can prove this using the method of induction.

\begin{itemize}

\item  \textbf{Base Case}: Let us first consider two observations \( x_1 = a > 0 \), \( x_2 = b > 0 \). We have to prove:

\[
\frac{a + b}{2} \geq \sqrt{ab}
\]

Consider the square of the difference:

\[
\left( \frac{a - b}{2} \right)^2 \geq 0 \quad \Rightarrow \quad \frac{a^2 - 2ab + b^2}{4} \geq 0
\]

\[
\Rightarrow a^2 + b^2 \geq 2ab \quad \Rightarrow \quad (a + b)^2 \geq 4ab
\]

\[
\Rightarrow \left( \frac{a + b}{2} \right)^2 \geq ab \quad \Rightarrow \quad \frac{a + b}{2} \geq \sqrt{ab}
\]

Equality holds if and only if \( a = b \).

\medskip

\item \textbf{Inductive Step}: Assume the inequality holds for \( n = k \), i.e., for all positive \( x_1, \dots, x_k \):

\[
\frac{x_1 + x_2 + \dots + x_k}{k} \geq \left( x_1 x_2 \dots x_k \right)^{1/k}
\]

We must show it holds for \( n = k+1 \) too.

Let \( x_1, x_2, \dots, x_k, x_{k+1} \) be positive numbers. Define:

\[
A = \frac{x_1 + x_2 + \dots + x_k}{k}, \quad G = \left( x_1 x_2 \dots x_k \right)^{1/k}
\]

By the inductive hypothesis, \( A \geq G \).

Now apply the \( n = 2 \) case to the numbers \( A \) and \( x_{k+1} \):

\[
\frac{A + x_{k+1}}{2} \geq \sqrt{A x_{k+1}} \geq \sqrt{G x_{k+1}}
\]

Now note:

\[
\frac{x_1 + \dots + x_k + x_{k+1}}{k+1} = \frac{kA + x_{k+1}}{k+1}
\]

We now want to show:
\[
\frac{kA + x_{k+1}}{k+1} \geq \left( x_1 x_2 \dots x_k x_{k+1} \right)^{1/(k+1)}
\]

Let us define:

\[
B = \left( x_1 x_2 \dots x_k x_{k+1} \right)^{1/(k+1)} = \left( G^k \cdot x_{k+1} \right)^{1/(k+1)}
\]

Use the inequality between arithmetic and geometric mean on \( A \) and \( x_{k+1} \):

\[
\frac{kA + x_{k+1}}{k + 1} \geq \left( A^k \cdot x_{k+1} \right)^{1/(k+1)}
\]

Since \( A \geq G \), and exponentiation preserves the inequality for positive values:

\[
A^k \geq G^k \quad \Rightarrow \quad \left( A^k \cdot x_{k+1} \right)^{1/(k+1)} \geq \left( G^k \cdot x_{k+1} \right)^{1/(k+1)} = B
\]

Therefore,

\[
\frac{x_1 + \dots + x_{k+1}}{k + 1} \geq B = \left( x_1 x_2 \dots x_k x_{k+1} \right)^{1/(k+1)}
\]
\end{itemize}

This therefore proves that:
\[
\text{AM} \geq \text{GM}
\]

\medskip

\item \textbf{Step 2: Proving \( \text{GM} \geq \text{HM} \)}

Recall the definition of the harmonic mean:

\[
\text{HM} = \frac{n}{\frac{1}{x_1} + \frac{1}{x_2} + \dots + \frac{1}{x_n}}
\]

Now consider the reciprocals \( \frac{1}{x_1}, \frac{1}{x_2}, \dots, \frac{1}{x_n} \), which are also positive. Thus we can apply the AM–GM inequality to the reciprocals:

\[
\frac{1}{n} \left( \frac{1}{x_1} + \frac{1}{x_2} + \dots + \frac{1}{x_n} \right) \geq \left( \frac{1}{x_1 x_2 \dots x_n} \right)^{1/n}
\]

Taking reciprocals of both sides:

\[
\frac{n}{\frac{1}{x_1} + \dots + \frac{1}{x_n}} \leq \left( x_1 x_2 \dots x_n \right)^{1/n}
\]

\[
\Rightarrow \text{HM} \leq \text{GM}
\]

with equality if and only if \( x_1 = x_2 = \dots = x_n \).
\end{itemize}

\medskip

Combining both steps:

\[
\text{AM} \geq \text{GM} \geq \text{HM}
\]

with equality throughout if and only if all the \( x_i \) are equal.
\hfill $\blacksquare$

\subsection{Median}
\begin{textbox}
The \textbf{median} of a set of observation is the middlemost value when the observations are arranged in increasing or decreasing order of magnitude. 
    \end{textbox}

It is denoted by $M_i$ or $\tilde{x}$. It divides the dataset into two equal halves: 50\% of the values lie below the median and 50\% lie above.


\begin{enumerate}

\item \textbf{Median in a Simple Series (Ungrouped Data)}

For a dataset with \( n \) observations arranged in ascending order:

\begin{itemize}
    \item If \( n \) is odd, the median is the value at the \( \left( \frac{n + 1}{2} \right)^\text{th} \) position.
    \item If \( n \) is even, the median is the arithmetic mean of the values at the \( \left( \frac{n}{2} \right)^\text{th} \) and \( \left( \frac{n}{2} + 1 \right)^\text{th} \) positions.
\end{itemize}

\textbf{Example:} Find the median of the dataset:  
\[
7, 2, 5, 9, 4
\]  
Arranging in ascending order: \( 2, 4, 5, 7, 9 \).  
Since there are 5 values (odd), the median is the 3rd value:  
\[
\text{Median} = 5
\]

\item \textbf{Median in a Simple Frequency Distribution}

In a simple frequency distribution, each data value is associated with a frequency. The procedure is identical to that of a simple frequency distribution:

\begin{itemize}
    \item Arrange the data in ascending order.
    \item Compute cumulative frequencies based on weights.
    \item Find total frequency \( N \), then find the smallest value for which the cumulative frequency is greater than or equal to \( \frac{N}{2} \).
\end{itemize}

\textbf{Example}: Consider the following table containing the values, frequencies and cumulative frequencies.

\begin{center}
\begin{tabular}{c|c|c}
\hline
Value & Frequency & Cumulative Frequency\\
\hline
2 & 3 & 3\\ 
4 & 5 & 8\\
6 & 7 & 15\\
8 & 5 & 20\\
\hline
\end{tabular}
\end{center}

\[
N = 3 + 5 + 7 + 5 = 20 \quad \Rightarrow \frac{N}{2} = 10
\]
Since 10 is between 8 and 15, the Median is 6. This works regardless of whether $N$ is odd or even.

\item \textbf{Median in a Grouped Frequency Distribution}

For a grouped frequency distribution, the cumulative frequencies are used to locate the median.

\begin{itemize}
    \item Compute cumulative frequencies.
    \item Find \( N = \sum f_i \), the total number of observations.
    \item Find \( \frac{N}{2} \).
    \item Locate the median class (the class whose cumulative frequency is greater than or equal to \( \frac{N}{2} \)).
    \item Use the formula:
    \begin{textbox}
    \[
    \text{Median} = L + \left( \frac{\frac{N}{2} - F}{f} \right) \cdot h
    \]
    \end{textbox}
    where:
    \begin{itemize}
        \item \( L \): lower boundary of the median class
        \item \( N \): total frequency
        \item \( F \): cumulative frequency before the median class
        \item \( f \): frequency of the median class
        \item \( h \): width of the class interval
    \end{itemize}
\end{itemize}

To arrive at this formula we assume that the cumulative frequency if a linear function of $x$ within the class $L$ and $L+h$. Then
$$\dfrac{\text{Median} - L}{h} = \dfrac{\frac{N}{2}-F}{f} \quad \Rightarrow \text{Median} = L + \left( \frac{\frac{N}{2} - F}{f} \right) \cdot h$$

\begin{center}
\begin{tikzpicture}[scale=1.1]
    % Axes
    \draw[->] (0,0) -- (6,0) node[right] {$x$};
    \draw[->] (0,0) -- (0,4.5) node[above] {Cumulative Frequency};

    % Median class block
    \fill[blue!10] (1,1.2) rectangle (3.7,3);

    % Horizontal lines
    \draw[thick] (1,1.2) -- (3.7,3);

    % Vertical dashed line for N/2
    \draw[dashed] (2.5,0) -- (2.5,2.2);
    \node[below] at (2.5,0) {Median};

    % Horizontal dashed to line
    \draw[dashed] (0,2.2) -- (2.5,2.2);
    \node[left] at (0,2.2) {$\frac{N}{2}$};

    % Horizontal frequency lines
    \draw[dashed] (0,1.2) -- (1,1.2);
    \draw[dashed] (0,3) -- (1,3);
    \node[left] at (0,1.2) {$F$};
    \node[left] at (0,3) {$F + f$};

    % Class boundaries
    \node[below] at (1,0) {$L$};
    \node[below] at (3.7,0) {$L + h$};
    \draw[dashed] (1,0) -- (1,1.2);
    \draw[dashed] (3.7,0) -- (3.7,1.2);

    % Brace for h
    % \draw[decorate,decoration={brace,mirror,amplitude=5pt},yshift=-5pt]
    %     (1,0) -- (4,0) node[midway,below,yshift=-6pt] {$h$};

    % Median label
    % \node[above] at (2.5,2.2) {\textbf{Median}};

\end{tikzpicture}
\end{center}

\textbf{Example}: Consider the following table containing the class values, frequencies and cumulative frequencies.
\begin{center}
\begin{tabular}{c|c|c}
\hline
Class Interval & Frequency & Cumulative Frequency \\
\hline
0--10 & 5 & 5\\
10--20 & 8 & 13\\
20--30 & 12 & 25\\
30--40 & 6 & 31\\
\hline
\end{tabular}
\end{center}


\[
N = 5 + 8 + 12 + 6 = 31,\quad \frac{N}{2} = 15.5
\]

Since $15.5$ is in between 13 and 25, the Median class is 20--30. Thus,
$$L = 20, F = 13, f = 12, h = 10$$

\[
\text{Median} = 20 + \left( \frac{15.5 - 13}{12} \right) \cdot 10 = 20 + \left( \frac{2.5}{12} \right) \cdot 10 = 20 + 2.08 = 22.08
\]
\end{enumerate}

\begin{textbox}
\textbf{Theorem}: Let \( x_1, x_2, \ldots, x_n \) be a set of observations. Define the function:
\[
S(A) = \sum_{i=1}^n |x_i - A|
\]
Then \( S(A) \) is minimized when \( A = \text{Median} \).
\end{textbox}
\textbf{Proof}: Let us arrange the observations \( x_1, x_2, \ldots, x_n \) in increasing order and denote the ordered sequence by \( y_1, y_2, \ldots, y_n \). Since this is just a rearrangement of the original data, we have:
\[
\sum_{i=1}^n |x_i - A| = \sum_{i=1}^n |y_i - A|.
\]

We now analyze the behavior of this sum in two cases:

\begin{itemize}
    \item \textbf{Case 1: \( n \) is odd (say \( n = 2m + 1 \))}

    \begin{align*}
    \sum_{i=1}^{n} |x_i - A| &= \sum_{i=1}^{2m+1} |y_i - A| \\
    &= |y_1 - A| + |y_2 - A| + \cdots + |y_m - A| + |y_{m+1} - A| \\
    &\quad + |y_{m+2} - A| + \cdots + |y_{2m+1} - A|.
    \end{align*}

    There are \( 2m + 1 \) terms in the sum. We consider them in symmetric pairs from both ends:

    \begin{itemize}
        \item The sum \( |y_1 - A| + |y_{2m+1} - A| \) is minimized when \( A \in [y_1, y_{2m+1}] \).
        \item The sum \( |y_2 - A| + |y_{2m} - A| \) is minimized when \( A \in [y_2, y_{2m}] \).
        \item Continuing this way, the sum \( |y_m - A| + |y_{m+2} - A| \) is minimized when \( A \in [y_m, y_{m+2}] \).
    \end{itemize}

    The unpaired central term is \( |y_{m+1} - A| \), which attains its minimum value (zero) when \( A = y_{m+1} \).

    Since all these intervals of minimization overlap at \( y_{m+1} \), we conclude that:
    \[
    \sum_{i=1}^{n} |x_i - A| \text{ is minimized when } A = y_{m+1} = \text{Median}.
    \]

    \item \textbf{Case 2: \( n \) is even (say \( n = 2m \))}

    \begin{align*}
    \sum_{i=1}^{n} |x_i - A| &= \sum_{i=1}^{2m} |y_i - A| \\
    &= |y_1 - A| + |y_2 - A| + \cdots + |y_m - A| + |y_{m+1} - A| + \cdots + |y_{2m} - A|.
    \end{align*}

    Now there are \( 2m \) terms, which can be grouped into \( m \) symmetric pairs:

    \begin{itemize}
        \item \( |y_1 - A| + |y_{2m} - A| \) is minimized when \( A \in [y_1, y_{2m}] \),
        \item \( |y_2 - A| + |y_{2m-1} - A| \) is minimized when \( A \in [y_2, y_{2m-1}] \), and so on.
        \item The final pair \( |y_m - A| + |y_{m+1} - A| \) is minimized when \( A \in [y_m, y_{m+1}] \).
    \end{itemize}

    Thus, the entire sum is minimized when \( A \in [y_m, y_{m+1}] \). A natural choice is:
    \[
    A = \text{Median} = \frac{y_m + y_{m+1}}{2},
    \]
    which lies within the minimizing interval and hence ensures that the sum is minimized.
\end{itemize}

In both cases—odd and even number of observations—the value of \( A \) that minimizes \( \sum_{i=1}^{n} |x_i - A| \) is the \textbf{median} of the dataset.

    \hfill $\blacksquare$

\begin{textbox}
The median is a better measure of central tendency than the mean (AM) in the presence of outliers in the observations.
\end{textbox}

The \textbf{mean} (AM) is sensitive to extreme values or outliers, while the \textbf{median} (the middle value) is more robust and resistant to such anomalies. This makes the median a better measure of central tendency in the presence of outliers or skewed data.

Consider the marks obtained by 5 students:

\[
\text{Scores} = \{10, 70, 75, 80, 90\}
\]

\[\textbf{Mean} = \frac{70 + 75 + 80 + 85 + 90}{5} = \frac{400}{5} = 80; \quad \textbf{Median} = \text{Middle value} = 75
\]

Here, both the mean and the median are equal and representative of the data, as there are no extreme values.

Now suppose one student scored unusually low:
\[
\text{Scores} = \{10, 70, 75, 80, 90\}
\]

\[\textbf{Mean} = \frac{10 + 70 + 75 + 80 + 90}{5} = \frac{325}{5} = 65; \quad \textbf{Median} = \text{Middle value} = 75
\]

The mean drops to 65 due to the outlier (10), even though most students scored 70 or above. The median stays at 75 and gives a better picture of the typical student performance.

\subsection{Mode}
\begin{textbox}
The \textbf{mode} of a given set of observations is the value which occurs with maximum frequency. It represents the highest peak in the frequency distribution. 
    \end{textbox}

The mode is generally denoted by \( M_o \).

\begin{enumerate}

\item \textbf{Mode in a Simple Series (Ungrouped Data)}

To determine the mode:
\begin{itemize}
    \item Count the frequency of each data value.
    \item The mode is the value with the highest frequency.
\end{itemize}

\textbf{Example:} Find the mode of the dataset:
\[
3, 7, 2, 3, 9, 3, 5
\]
The number 3 occurs most frequently (3 times), so:
\[
\text{Mode} = 3
\]

\item \textbf{Mode in a Simple Frequency Distribution}

In a simple frequency distribution, the mode is the data value corresponding to the maximum frequency.

\textbf{Example:} Consider the table:

\begin{center}
\begin{tabular}{c|c}
\hline
Value & Frequency \\
\hline
4 & 3 \\
5 & 7 \\
6 & 5 \\
7 & 2 \\
\hline
\end{tabular}
\end{center}

The highest frequency is 7, corresponding to the value 5. Hence:
\[
\text{Mode} = 5
\]

\item \textbf{Mode in a Grouped Frequency Distribution}

When the data is grouped into intervals, it is very difficult to find the mode accurately. However if all the classes are of equal width, then it is possible to approximately calculate the mode using the formula:
\begin{textbox}
\[
\text{Mode} = L + \left( \frac{f_1 - f_0}{2f_1 - f_0 - f_2} \right) \cdot h
\]
    \end{textbox}

where:
\begin{itemize}
    \item \( L \): lower boundary of the modal class
    \item \( f_1 \): frequency of the modal class
    \item \( f_0 \): frequency of the class preceding the modal class
    \item \( f_2 \): frequency of the class succeeding the modal class
    \item \( h \): class width
\end{itemize}

How do we arrive at the formula for mode? In addition to the modal class frequency $f_1$, mode also depends on $f_0$ (the frequency of the class preceding the modal class) and $f_2$ (the frequency of the class following the modal class). If they are equal, then one would take the midpoint of the modal class $L+ \dfrac{h}{2}$ as the mode. However, if $f_0-f_1$ is greater (smaller) than $f_1-f_2$, then one would suppose that the mode is nearer to (further from) the lower boundary ($L$) of the modal class than the upper boundary ($L+h$). Mathematically, if we assume the proportion is same, then
\[
\frac{d}{f_1 - f_0} = \frac{h - d}{f_1 - f_2}
\]

Cross-multiplying and simplifying:
\[
d\cdot (2f_1 - f_0 - f_2) = (f_1 - f_0)\cdot h
\]

Solving for \( d \):
\[
d = \frac{(f_1 - f_0)\cdot h}{2f_1 - f_0 - f_2}
\]

Hence, the mode is:
\[
\text{Mode} = L + d = L + \left( \frac{f_1 - f_0}{2f_1 - f_0 - f_2} \right) \cdot h
\]

\begin{center}
\begin{tikzpicture}[scale=1.2]

% Axes
\draw[->] (0,0) -- (6,0) node[right] {$x$};
\draw[->] (0,0) -- (0,4.5) node[above] {Frequency};

% Class boundaries
\draw[dashed] (1,0) -- (1,1.5);
\draw[dashed] (2,0) -- (2,3.5);
\draw[dashed] (3,0) -- (3,2.5);

% Frequency bars
\filldraw[fill=blue!10,draw=black] (1,0) rectangle (2,1.5); % f0
\filldraw[fill=blue!25,draw=black] (2,0) rectangle (3,3.5); % f1 modal class
\filldraw[fill=blue!10,draw=black] (3,0) rectangle (4,2.5); % f2

% Labels for class intervals
\node[below] at (1,0) {\small $L - h$};
\node[below] at (2,0) {\small $L$};
\node[below] at (3,0) {\small $L + h$};
\node[below] at (4,0) {\small $L + 2h$};

% Labels for frequencies
\node[left] at (0,1.5) {$f_0$};
\node[left] at (0,3.5) {$f_1$};
\node[left] at (0,2.5) {$f_2$};

% Dashed horizontal lines for f0, f1, f2
\draw[dashed] (0,1.5) -- (1,1.5);
\draw[dashed] (0,3.5) -- (4,3.5);
\draw[dashed] (0,2.5) -- (3,2.5);

% Modal class label
\node at (2.5,3.8) {\textbf{Modal Class}};

% Deltas
\draw[<->] (1.5,1.5) -- (1.5,3.5);
\node[right] at (1,2.7) {$d_1$};

\draw[<->] (3.5,2.5) -- (3.5,3.5);
\node[right] at (3.8,3.0) {$d_2$};
\end{tikzpicture}
\end{center}

\textbf{Example:} Consider the following grouped data:

\begin{center}
\begin{tabular}{c|c}
\hline
Class Interval & Frequency \\
\hline
0--10 & 4 \\
10--20 & 6 \\
20--30 & 10 \\
30--40 & 8 \\
\hline
\end{tabular}
\end{center}

Here, the modal class is 20--30 because it has the highest frequency (\( f_1 = 10 \)). The required values are:
\[
L = 20, \quad f_0 = 6, \quad f_1 = 10, \quad f_2 = 8, \quad h = 10
\]

\[
\text{Mode} = 20 + \left( \frac{10 - 6}{2(10) - 6 - 8} \right) \cdot 10 = 20 + \left( \frac{4}{6} \right) \cdot 10 = 20 + 6.67 = 26.67
\]

\end{enumerate}


\subsection{Comparison and When to Use Each}

\begin{itemize}
    \item \textbf{Mean} is sensitive to outliers and skewed data. It is best used for symmetric, continuous data without extreme values.

    \item \textbf{Median} is more robust to outliers and skewed distributions. It is ideal when the data contain extreme values or are not symmetrically distributed.

    \item \textbf{Mode} is useful for categorical or discrete data, especially when identifying the most frequent category is of interest.

    \item \textbf{Geometric Mean} is appropriate when dealing with ratios, growth rates, or multiplicative processes (e.g., population growth, interest rates).

    \item \textbf{Harmonic Mean} is best for averaging rates, such as speed or price per unit when quantities vary.

\end{itemize}

Each measure gives a different perspective of the `center' of the data. The choice of measure should be guided by the nature and scale of the data, and the specific analysis objective.

\section{Partition Values: Quartiles, Deciles, and Percentiles}

Just as the median divides a data set into two equal parts, there are other statistical measures that partition the data into a fixed number of equal segments — such as 4, 10, or 100 parts when the data is arranged in increasing order of magnitude. These measures are collectively referred to as \textbf{partition values} or \textbf{quantiles}. The most commonly used partition values are the \textbf{quartiles}, \textbf{deciles}, and \textbf{percentiles}, which divide the data into four, ten, and one hundred equal parts, respectively.

Partition values are useful in identifying the spread and concentration of data. For instance, if a student scores at the 90th percentile, they performed better than 90\% of the population.

\subsection{Quartiles}

Quartiles divide a ordered data set into four equal parts. There are three quartiles:

\begin{itemize}
    \item $Q_1$ (First Quartile): 25\% of the data falls below $Q_1$.
    \item $Q_2$ (Second Quartile or Median): 50\% of the data falls below $Q_2$.
    \item $Q_3$ (Third Quartile): 75\% of the data falls below $Q_3$.
\end{itemize}

\begin{textbox}
\[
Q_k = \left( \frac{k(n+1)}{4} \right)\text{th value}, \quad k = 1, 2, 3
\]
\end{textbox}

% \textbf{Formula (for grouped data)}:
% \[
% Q_k = L + \left( \frac{\frac{kN}{4} - F}{f} \right) \cdot h
% \]
% where:
% \begin{itemize}
%     \item $L$ = lower boundary of the quartile class
%     \item $N$ = total frequency
%     \item $F$ = cumulative frequency before the quartile class
%     \item $f$ = frequency of the quartile class
%     \item $h$ = class width
% \end{itemize}

\textbf{Example}: Consider the ordered data: \{5, 7, 8, 12, 13, 15, 16, 20, 21\}.

\begin{itemize}
    \item Number of observations $ n = 9$
    \item $Q_1 = \left( \frac{1(9+1)}{4} \right) = \text{3rd value} = 8$
    \item $Q_2 = \left( \frac{2(9+1)}{4} \right) = \text{5th value} = 13$
    \item $Q_3 = \left( \frac{3(9+1)}{4} \right) = \text{7th value} = 16$
\end{itemize}

\textbf{Interquartile Range (IQR)}: The {Interquartile Range (IQR)} is a measure of statistical dispersion, which describes the spread of the middle 50\% of a data set. It is the difference between the third quartile (\(Q_3\)) and the first quartile (\(Q_1\)).

\begin{textbox}
    \[
    \text{IQR} = Q_3 - Q_1
    \]
\end{textbox}

\subsection{Deciles}

Deciles divide the ordered data into ten equal parts. There are nine deciles ($D_1$ to $D_9$), such that:

\begin{textbox}
\[
D_k = \left( \frac{k(n+1)}{10} \right)\text{th value}, \quad k = 1, 2, \dots, 9
\]
\end{textbox}

% \textbf{Grouped data formula}:
% \[
% D_k = L + \left( \frac{\frac{kN}{10} - F}{f} \right) \cdot h
% \]

\subsection{Percentiles}

Percentiles divide the ordered data into one hundred equal parts. There are 99 percentiles ($P_1$ to $P_{99}$), commonly used to interpret standardized test scores and similar metrics.

\begin{textbox}
\[
P_k = \left( \frac{k(n+1)}{100} \right)\text{th value}, \quad k = 1, 2, \dots, 99
\]
\end{textbox}

% \textbf{Grouped data formula}:
% \[
% P_k = L + \left( \frac{\frac{kN}{100} - F}{f} \right) \cdot h
% \]

\section{Measures of Dispersion}

Measures of dispersion describe the spread or variability within a data set. While measures of central tendency (such as the mean or median) indicate the typical value, measures of dispersion indicate how much the values in the dataset differ from the central value. A small dispersion means the data points are clustered close to the center, while a large dispersion indicates data points are spread out over a wide range.

Consider the following two data sets, each containing five values:
$A = \{4, 5, 5, 5, 6\}$ and $B = \{1, 3, 5, 7, 9\}$.  
Both sets have the same mean, which is 5. For set $A$, the mean is
\[
\frac{4 + 5 + 5 + 5 + 6}{5} = \frac{25}{5} = 5,
\]
and for $B$, the mean is  
\[
\frac{1 + 3 + 5 + 7 + 9}{5} = \frac{25}{5} = 5.
\]
However, their dispersions are quite different. The maximum value of $A$ is $6$ and minimum value is $4$, whereas the maximum value of $B$ is $9$ and minimum value is $1$. This means that although both sets center around the same average value, the values in set $B$ are spread out much more widely around the mean compared to set $A$. Therefore, we say that the dispersion of $B$ is greater than that of $A$.


Measures of dispersion are broadly classified into two types:
\begin{itemize}
    \item \textbf{Absolute Measures of Dispersion}: These express dispersion in the same units as the original data.
    \item \textbf{Relative Measures of Dispersion}: These express dispersion as a ratio or percentage and are unit-free. They are useful for comparing variability between datasets with different units or magnitudes.
\end{itemize}

\begin{center}
    \includegraphics[scale=0.5]{pic/mod.drawio.png}
\end{center}

\subsection{Absolute Measures of Dispersion}

\begin{enumerate}
    \item \textbf{Range}: Difference between the largest and smallest observations.
    \begin{textbox}
        \[
    \text{Range} = L - S
    \]
    \end{textbox}
    where \( L \) is the largest value and \( S \) is the smallest value.

    Consider the data set: \{10, 15, 18, 22, 25\}.  
Here, the largest value \( L = 25 \) and the smallest value \( S = 10 \).  

\[
\text{Range} = 25 - 10 = 15
\]
    \item \textbf{Quartile Deviation (Semi-Interquartile Range)}: Quartile deviation is defined as half the difference between the lower and upper quartiles.
    \begin{textbox}
    \[
    \text{Quartile Deviation} = \frac{Q_3 - Q_1}{2}
    \]
    \end{textbox}
    where \( Q_1 \) and \( Q_3 \) are the first and third quartiles.

    Consider the ordered data set: \{10, 15, 20, 25, 30, 35, 40\}.

Here,
\[
Q_1 = 15, \quad Q_3 = 35
\]

\[
\text{Quartile Deviation} = \frac{35 - 15}{2} = \frac{20}{2} = 10
\]

    \item \textbf{Mean Deviation}: Mean deviation is the arithmetic mean of absolute deviations from mean or any other specified value.
    \begin{textbox}
    \[
    \text{Mean Deviation about }A = \frac{1}{n} \sum_{i=1}^{n} |x_i - A|
    \]
    \end{textbox}
    Generally mean deviation is taken from the arithmetic mean $\overline{x}$.
    \begin{textbox}
    \[
    \text{Mean Deviation about mean} = \frac{1}{n} \sum_{i=1}^{n} |x_i - A|
    \]
    \end{textbox}

    Consider the data set: \{2, 4, 6, 8, 10\}. First we calculate the mean from the data:
\[
\overline{x} = \frac{2 + 4 + 6 + 8 + 10}{5} = \frac{30}{5} = 6
\]

Then we compute the absolute deviations from the mean:
\[
|2 - 6| = 4,\quad |4 - 6| = 2,\quad |6 - 6| = 0,\quad |8 - 6| = 2,\quad |10 - 6| = 4
\]

Finally we calculate the Mean Deviation about the mean:
\[
\text{Mean Deviation about mean} = \frac{4 + 2 + 0 + 2 + 4}{5} = \frac{12}{5} = 2.4
\]

For weighted data, the Mean Deviation about the mean is given by:

\begin{textbox}
\[
\text{Mean Deviation about mean} = \frac{\sum_{i=1}^{n} f_i \left| x_i - \overline{x} \right|}{\sum_{i=1}^{n} f_i}
\]
\end{textbox}

where:
\begin{itemize}
    \item \( x_i \) are the data values,
    \item \( f_i \) are their corresponding frequencies (weights),
    \item \( \overline{x} = \dfrac{\sum_i f_i x_i}{\sum_i f_i} \) is the weighted mean.
\end{itemize}

    \item \textbf{Standard Deviation}: In considering the deviations $x_i-A$ for obtaining a measure of dispersion, we may also get rid of their signs by taking their squares $(x_i-A)^2$, instead of taking their absolute values $|x_i-A|$. The square root of the arithmetic mean of these squares i.e. $\sqrt{\dfrac{1}{n}\sum_{i=1}^n(x_i-A)^2}$ which is called the \textbf{root mean square deviation} about $A$, may be accepted as a measure of dispersion. When $A=\overline{x}$, the measure of dispersion is called the standard deviation.
    \begin{textbox}
    \[
    \text{Standard deviation} = \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (x_i - \overline{x})^2}
    \]
    \end{textbox}
    The square of the standard deviation i.e. $\sigma^2$ is known as \textbf{variance}.

    As an example, consider the data set: \{2, 4, 4, 4, 5, 5, 7, 9\}. First we calculate the mean:
\[
\overline{x} = \frac{2 + 4 + 4 + 4 + 5 + 5 + 7 + 9}{8} = \frac{40}{8} = 5
\]

Then we find the Squared Deviations from the mean:
\[
(2 - 5)^2 = 9,\quad (4 - 5)^2 = 1,\quad (4 - 5)^2 = 1,\quad (4 - 5)^2 = 1,
\]
\[
(5 - 5)^2 = 0,\quad (5 - 5)^2 = 0,\quad (7 - 5)^2 = 4,\quad (9 - 5)^2 = 16
\]

Finally compute the Standard Deviation:
\[
\sigma = \sqrt{\frac{9 + 1 + 1 + 1 + 0 + 0 + 4 + 16}{8}} = \sqrt{\frac{32}{8}} = \sqrt{4} = 2
\]

For weighted data, the standard deviation is calculated as:

\begin{textbox}
\[
\text{Standard deviation} = \sigma = \sqrt{\frac{\sum_{i=1}^n f_i (x_i - \overline{x})^2}{\sum_{i=1}^n f_i}}
\]
\end{textbox}

where,  
\begin{itemize}
    \item \(x_i\) are the data values,  
    \item \(f_i\) are the corresponding frequencies (weights),  
    \item \(\overline{x} = \dfrac{\sum_{i=1}^n f_i x_i}{\sum_{i=1}^n f_i}\) is the weighted mean,  
\end{itemize}

\begin{textbox}
\textbf{Theorem}: If \( x = a \) (a constant), {then } \( \sigma_x = 0 \).
\end{textbox}

\textbf{Proof}: Since all observations are equal to \( a \), the mean is
\[
\overline{x} = a.
\]
The standard deviation is
\begin{align*}
\sigma_x &= \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \overline{x})^2} = \sqrt{\frac{1}{n} \sum_{i=1}^n (a - a)^2} = \sqrt{0} = 0.
\end{align*}

\hfill $\blacksquare$

\begin{textbox}
\textbf{Theorem}: If \( y = a + b x \), {where} \( a, b \) {are constants, then}
\[
\sigma_y = |b| \sigma_x
\]
\end{textbox}

\textbf{Proof}: The mean of \( y \) is
\[
\overline{y} = a + b \overline{x}.
\]
The standard deviation of \( y \) is
\begin{align*}
\sigma_y &= \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \overline{y})^2} = \sqrt{\frac{1}{n} \sum_{i=1}^n (a + b x_i - (a + b \overline{x}))^2} \\
         &= \sqrt{\frac{1}{n} \sum_{i=1}^n \left(b (x_i - \overline{x})\right)^2} = \sqrt{\frac{1}{n} \sum_{i=1}^n b^2 (x_i - \overline{x})^2} \\
         &= |b| \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \overline{x})^2} = |b| \sigma_x
\end{align*}

\hfill $\blacksquare$

\begin{textbox}
\textbf{Theorem}: Let a dataset be composed of two groups:

\begin{itemize}
  \item Group 1: \( n_1 \) observations, mean \( \overline{x}_1 \), standard deviation \( \sigma_1 \),
  \item Group 2: \( n_2 \) observations, mean \( \overline{x}_2 \), standard deviation \( \sigma_2 \).
\end{itemize}

{Then the combined standard deviation \( \sigma \) of the dataset (size \( n = n_1 + n_2 \)) is given by:}

\[
\sigma = \sqrt{
\frac{n_1 \sigma_1^2 + n_2 \sigma_2^2}{n_1 + n_2} + \frac{n_1 (\overline{x}_1 - \overline{x})^2 + n_2 (\overline{x}_2 - \overline{x})^2}{n_1 + n_2}
}
\]
where
\[
\overline{x} = \frac{n_1 \overline{x}_1 + n_2 \overline{x}_2}{n_1 + n_2}
\]
\end{textbox}

\textbf{Proof}: Let us denote $x_{1j}, (j=1,2,\dots, n_1)$ and $x_{2j}, (j=1,2,\dots, n_1)$ the values of the two sets. Then
$$\sigma_1^2 =\sum_{j=1}^{n_1} (x_{1j} - \overline{x}_1), \quad \sigma_2^2 =\sum_{j=1}^{n_1} (x_{2j} - \overline{x}_2)$$


The variance of the combined data set is
\begin{align*}
\sigma^2 &= \frac{1}{n_1 + n_2} \left(\sum_{j=1}^{n_1} (x_{1j} - \overline{x})^2 + \sum_{j=1}^{n_2} (x_{2j} - \overline{x})^2 \right)
\end{align*}

Expanding the first term:
\begin{align*}
\sum_{j=1}^{n_1} (x_{ij} - \overline{x})^2 &= \sum_{j=1}^{n_1} \left[(x_{1j} - \overline{x}_1) + (\overline{x}_1 - \overline{x})\right]^2 \\
&= \underbrace{\sum_{j=1}^{n_1} (x_{1j} - \overline{x}_1)^2}_{n_1\sigma_1^2} + 2(\overline{x}_1 - \overline{x}) \underbrace{\sum_{j=1}^{n_1} (x_{1j} - \overline{x}_1)}_{0} + \sum_{j=1}^{n_1} (\overline{x}_1 - \overline{x})^2 \\
&= n_1 \sigma_1^2 + n_1 (\overline{x}_1 - \overline{x})^2,
\end{align*}
Similarly,
\[
\sum_{j=1}^{n_2} (x_{2j} - \overline{x})^2 = n_2 \sigma_2^2 + n_2 (\overline{x}_2 - \overline{x})^2.
\]

Thus,
\begin{align*}
\sigma^2 &= \frac{n_1 \sigma_1^2 + n_2 \sigma_2^2}{n_1 + n_2} + \frac{n_1 (\overline{x}_1 - \overline{x})^2 + n_2 (\overline{x}_2 - \overline{x})^2}{n_1 + n_2}.
\end{align*}

\hfill $\blacksquare$

\end{enumerate}

\subsection{Relative Measures of Dispersion}

Relative measures of dispersion are defined as ratio of absolute measures of dispersion to the corresponding measure of central tendency. The ratio is expressed in terms of a percentage.

\begin{enumerate}
    \item \textbf{Coefficient of Range}:
    \begin{textbox}
    \[
    \text{Coefficient of Range} = \frac{L - S}{L + S}\times 100\%
    \]
    \end{textbox}
    where \( L \) is the largest value and \( S \) is the smallest value.

    \item \textbf{Coefficient of Quartile Deviation}:
    \begin{textbox}
    \[
    \text{Coefficient of Q.D.} = \frac{Q_3 - Q_1}{Q_3 + Q_1}\times 100\%
    \]
    \end{textbox}

    \item \textbf{Coefficient of Mean Deviation}:
    \begin{textbox}
    \[
    \text{Coefficient of M.D.} = \frac{\text{Mean Deviation}}{\overline{x}}\times 100\%
    \]
    \end{textbox}

    \item \textbf{Coefficient of Variation (CV)}:
    \begin{textbox}
    \[
    \text{CV} = \frac{\sigma}{\overline{x}} \times 100\%
    \]
    \end{textbox}
\end{enumerate}

\section{Moments, Skewness and Kurtosis}

\subsection{Raw Moments and Central Moments}

In descriptive statistics, \textbf{moments} are used to describe various characteristics of a dataset's distribution. Two important types of moments are:

\begin{itemize}
    \item \textbf{Raw moments} (moments about the origin): The $r$-th \textbf{raw moment} of a dataset $x_1, x_2, \dots, x_n$ is given by:
\begin{textbox}
\[
\mu'_r = \frac{1}{n} \sum_{i=1}^{n} x_i^r
\]
\end{textbox}
    \begin{itemize}
        \item First raw moment: $\mu'_1 = \overline{x}$ (sample mean)
        \item Second raw moment: $\mu'_2 = \frac{1}{n} \sum x_i^2$
    \end{itemize}
    \item \textbf{Central moments} (moments about the mean): The $r$-th \textbf{central moment} is the average of the $r$-th powers of deviations from the mean:
\begin{textbox}
\[
\mu_r = \frac{1}{n} \sum_{i=1}^{n} (x_i - \overline{x})^r
\]
\end{textbox}
\begin{itemize}
    \item First central moment: $\mu_1 = 0$ (since the mean deviation is zero)
    \item Second central moment: $\mu_2 = \dfrac{1}{n} \sum_{i=1}^{n} (x_i - \overline{x})^2$ is the {variance}.
\end{itemize}
\end{itemize}

\textbf{Example}: Consider the dataset:
\[
\{2,\ 4,\ 6,\ 8\}
\]
\begin{itemize}
\item{Raw moments:}
\begin{align*}
\mu'_1 &= \frac{1}{4}(2 + 4 + 6 + 8) = 5 \\
\mu'_2 &= \frac{1}{4}(2^2 + 4^2 + 6^2 + 8^2) = \frac{120}{4} = 30
\end{align*}

\item{Central moments:}
\begin{align*}
\mu_1 &= 0\\
\mu_2 &= \frac{1}{4}[(2 - 5)^2 + (4 - 5)^2 + (6 - 5)^2 + (8 - 5)^2] \\
      &= \frac{1}{4}(9 + 1 + 1 + 9) = \frac{20}{4} = 5
% \mu_3 &= \frac{1}{4}[(2 - 5)^3 + (4 - 5)^3 + (6 - 5)^3 + (8 - 5)^3] \\
%       &= \frac{1}{4}[-27 - 1 + 1 + 27] = 0
\end{align*}

\end{itemize}

\subsection{Relationship Between Raw and Central Moments}

The $r$-th central moment $\mu_r$ can be expressed in terms of raw moments $\mu'_k$ and powers of the mean $\overline{x}$:

\begin{align*}
    \mu_r &= \frac{1}{n} \sum_{i=1}^n (x_i - \overline{x})^r = \frac{1}{n}\sum_{i=1}\left[\sum_{k=0}^r \binom{r}{k}\,\overline{x_i}^{\,r-k} \overline{x}^k\right]\\
    &=\frac{1}{n}\sum_{i=1}^n\left[x_i^r - \binom{r}{1} x_i^{r-1}\overline{x} + \binom{r}{2} x_i^{r-2}\overline{x}^2 + \dots - \overline{x}^r\right]\\
    &=\mu'_r - \binom{r}{1} \mu'_{r-1}\overline{x} + \binom{r}{2} \mu'_{r-2}\overline{x}^2 + \dots - n\overline{x}^r
\end{align*}

Since $\mu'_1 = \overline{x}$, we can rewrite the above expression as:
\begin{textbox}
$$\mu_r = \mu'_r - \binom{r}{1} \mu'_{r-1}\mu'_1 + \binom{r}{2} \mu'_{r-2}{\mu'_1}^2 + \dots - n{\mu'_1}^r$$
\end{textbox}
% Now putting $r = 1,2,3,4$, we get

\begin{itemize}
  \item \(r=1:\)
    \begin{align*}
      \mu_1
      &= \mu'_1 - \binom{1}{1}\,\mu'_0\,\mu'_1 \\
      &= \mu'_1 - \mu'_1 = 0
    \end{align*}
    
  
  \item \(r=2:\)
    \begin{align*}
      \mu_2
      &= \mu'_2 
         - \binom{2}{1}\,\mu'_1\,\mu'_1
         + \binom{2}{2}\,\mu'_0\,(\mu'_1)^2 \\
      &= \mu'_2 - 2(\mu'_1)^2 + (\mu'_1)^2
      = \mu'_2 - (\mu'_1)^2
    \end{align*}
    
  
  \item \(r=3:\)
    \begin{align*}
      \mu_3
      &= \mu'_3
         - \binom{3}{1}\,\mu'_2\,\mu'_1
         + \binom{3}{2}\,\mu'_1\,(\mu'_1)^2
         - \binom{3}{3}\,\mu'_0\,(\mu'_1)^3 \\
      &= \mu'_3 - 3\,\mu'_2\,\mu'_1 + 3(\mu'_1)^3 - (\mu'_1)^3
      = \mu'_3 - 3\,\mu'_2\,\mu'_1 + 2(\mu'_1)^3
    \end{align*}
    
  
  \item \(r=4:\)
    \begin{align*}
      \mu_4
      &= \mu'_4
         - \binom{4}{1}\,\mu'_3\,\mu'_1
         + \binom{4}{2}\,\mu'_2\,(\mu'_1)^2
         - \binom{4}{3}\,\mu'_1\,(\mu'_1)^3
         + \binom{4}{4}\,\mu'_0\,(\mu'_1)^4 \\
      &= \mu'_4 - 4\,\mu'_3\,\mu'_1 + 6\,\mu'_2\,(\mu'_1)^2 - 4(\mu'_1)^4 + (\mu'_1)^4 \\
      &= \mu'_4 - 4\,\mu'_3\,\mu'_1 + 6\,\mu'_2\,(\mu'_1)^2 - 3(\mu'_1)^4
    \end{align*}
    
\end{itemize}

Now let's derive the inverse relationship. Using the binomial expansion on \(x_i = (x_i - \overline{x}) + \overline{x}\), the \(r\)-th raw moment can be written as
\begin{align*}
\mu'_r
&= \frac{1}{n}\sum_{i=1}^n \bigl[\overline{x}+ (x_i - \overline{x})\bigr]^r
= \frac{1}{n}\sum_{i=1}^n\left[\sum_{k=0}^r \binom{r}{k}\,\overline{x}^{\,r-k} (x_i - \overline{x})^k\right]\\
&= \frac{1}{n}\sum_{i=1}^n\left[\overline{x}^r\
+ \binom{r}{1}\,\overline{x}^{\,r-1}\,(x_i - \overline{x})
+ \binom{r}{2}\,\overline{x}^{\,r-2}\,(x_i - \overline{x})^2
+ \cdots
+ (x_i - \overline{x})^r\right]\\
&= \overline{x}^r\
+ \binom{r}{1}\,\overline{x}^{\,r-1}\,\mu_1
+ \binom{r}{2}\,\overline{x}^{\,r-2}\,\mu_2
+ \cdots
+ \mu_r
\end{align*}
where by convention \(\mu_1 = 0\).

\begin{textbox}
    \begin{align*}
        \mu'_r = \overline{x}^r\
+ \binom{r}{1}\,\overline{x}^{\,r-1}\,\mu_1
+ \binom{r}{2}\,\overline{x}^{\,r-2}\,\mu_2
+ \cdots
+ \mu_r
    \end{align*}
\end{textbox}

\begin{itemize}
  \item \(r=1:\)
    \begin{align*}
      \mu'_1
      &= \overline{x}^1\ + \binom{1}{1}\,\overline{x}^0\,\mu_1 \\
      &= \overline{x} + 0
      = \overline{x}
    \end{align*}
  
  \item \(r=2:\)
    \begin{align*}
      \mu'_2
      &= \overline{x}^2\
         + \binom{2}{1}\,\overline{x}^1\,\mu_1
         + \binom{2}{2}\,\overline{x}^0\,\mu_2 \\
      &= \overline{x}^2 + 0 + \mu_2
      = \mu_2 + \overline{x}^2
    \end{align*}
  
  \item \(r=3:\)
    \begin{align*}
      \mu'_3
      &= \overline{x}^3\
         + \binom{3}{1}\,\overline{x}^2\,\mu_1
         + \binom{3}{2}\,\overline{x}^1\,\mu_2
         + \binom{3}{3}\,\overline{x}^0\,\mu_3 \\
      &= \overline{x}^3 + 0 + 3\,\overline{x}\,\mu_2 + \mu_3
      = \mu_3 + 3\,\overline{x}\,\mu_2 + \overline{x}^3
    \end{align*}
  
  \item \(r=4:\)
    
    \begin{align*}
      \mu'_4
      &= \overline{x}^4\
         + \binom{4}{1}\,\overline{x}^3\,\mu_1
         + \binom{4}{2}\,\overline{x}^2\,\mu_2
         + \binom{4}{3}\,\overline{x}^1\,\mu_3
         + \binom{4}{4}\,\overline{x}^0\,\mu_4 \\
      &= \overline{x}^4 + 0 + 6\,\overline{x}^2\,\mu_2 + 4\,\overline{x}\,\mu_3 + \mu_4 \\
      &= \mu_4 + 4\,\overline{x}\,\mu_3 + 6\,\overline{x}^2\,\mu_2 + \overline{x}^4
    \end{align*}
\end{itemize}

\subsection{Skewness}

\textbf{Skewness} is a measure of the asymmetry of a frequency distribution about its mean. The frequency distribution of a dataset is called symmetrical about the value $x_0$ if the frequency of $x_0-h$ is same as the frequency of $x_0+h$, whatever $h$ may be.


The sample skewness is defined as:
\begin{textbox}
\[
\text{Skewness} (\gamma_1) = \frac{1}{n} \sum_{i=1}^n \left( \frac{x_i - \overline{x}}{\sigma} \right)^3 = \frac{\mu_3}{\sigma^3}
\]
\end{textbox}
where \(\mu_3 = \dfrac{1}{n} \sum_{i=1}^n (x_i - \overline{x})^3\) is the third central moment.

The value of skewness determines the shape of the frequency curve:
\begin{itemize}
    \item If skewness \( = 0 \), the distribution is \textbf{symmetric}.
    \item If skewness \( > 0 \), the distribution is \textbf{positively skewed} (long right tail).
    \item If skewness \( < 0 \), the distribution is \textbf{negatively skewed} (long left tail).
\end{itemize}

\textbf{How to interpret the formula?}

Skewness uses cubed deviations $(x_i - \overline{x})^3$. Cubing serves two purposes: it preserves the sign of the deviation — meaning values greater than the mean contribute positively and those less than the mean contribute negatively — and it exaggerates the impact of larger deviations, making the measure sensitive to extreme values in the tails. This helps identify whether the data are stretched more to the right or left. 

Dividing by the cube of the standard deviation $\sigma^3$ standardizes the measure, removing units and allowing for meaningful comparisons across datasets with different scales. The result is a dimensionless quantity: positive skewness indicates a long right tail, negative skewness signals a long left tail, and zero skewness implies symmetry around the mean.

\begin{center}
\begin{tikzpicture}
  \begin{axis}[
    width=12cm, height=6cm,
    axis lines=middle,
    ymin=0, ymax=0.5,
    xlabel={$x$}, ylabel={$f(x)$},
    domain=-8:8, samples=200,
    every axis plot post/.append style={very thick},
    clip=false            % allow arrows/nodes outside the plot area
  ]
    % Symmetric (Normal)
    \addplot[blue, very thick] {1/sqrt(2*pi)*exp(-x^2/2)};
    % Node and arrow for symmetric
    \node[black, font=\large] (sym) at (axis cs:4.2,0.35) {Symmetric};
    \draw[->, black] (sym.west) to[bend right=20] (axis cs:0.9,0.3);

    % Positive skew (Gamma shape)
    \addplot[red, thick, domain=0:8] {x^2*exp(-x)/2};
    % Node and arrow for positive skew
    \node[black, font=\large, right] (pos) at (axis cs:5,0.2) {Positive skew};
    \draw[->, black] (pos.west) to[bend right=15] (axis cs:3.6,0.18);

    % Negative skew (Reflected Gamma)
    \addplot[green!60!black, very thick, domain=-8:0] {(-x)^2*exp(x)/2};
    % Node and arrow for negative skew
    \node[black, font=\large, left] (neg) at (axis cs:-5,0.2) {Negative skew};
    \draw[->, black] (neg.east) to[bend left=15] (axis cs:-3.6,0.18);
  \end{axis}
\end{tikzpicture}
\end{center}


\textbf{Example}: Given data: \(x = \{2, 3, 4, 5, 8\}\)

\begin{itemize}
    \item Mean: \(\overline{x} = \dfrac{2+3+4+5+8}{5} = 4.4\)
    \item Standard deviation: \(s = \sqrt{\dfrac{1}{5}\sum_i (x_i - \overline{x})^2} \approx 2.058\)
    \item Third central moment:
    \[
    \mu_3 = \dfrac{1}{5} \left[(-2.4)^3 + (-1.4)^3 + (-0.4)^3 + 0.6^3 + 3.6^3\right] \approx 3.232
    \]
    \item Skewness:
    \[
    \gamma_1 = \frac{3.232}{(2.058)^3} \approx 0.37
    \]
\end{itemize}

Since skewness \(> 0\), the distribution is \textbf{positively skewed}.


In most unimodal distributions\footnote{A dataset is said to have a \textbf{unimodal distribution} if its values tend to cluster around a single (not multiple) central peak when plotted as a histogram or a frequency curve.}, the following ``rule of thumb'' holds regarding the ordering of Mean, Median, and Mode under skewness:

\begin{itemize}
  \item \textbf{Positive skew (right‐tailed):}
    \[
      \text{Mode} \;<\; \text{Median} \;<\; \text{Mean}.
    \]
    \\
    Extreme values on the right pull the mean farther out than the median, while the mode remains at the peak of the bulk of the data.
  
  \item \textbf{Negative skew (left‐tailed):}
    \[
      \text{Mean} \;<\; \text{Median} \;<\; \text{Mode}.
    \]
    \\
    Extreme values on the left drag the mean below the median, and the mode stays at the highest‐density point on the right.
\end{itemize}

\subsection{Kurtosis}

\textbf{Kurtosis} measures the degree of `peakedness' of a frequency distribution curve. Two frequency distributions may have the same mean, dispersion, and skewness, yet differ in how concentrated the values are around the mode. One distribution may have a sharper peak due to a higher concentration of values near the center, while the other appears flatter. This characteristic of a frequency distribution is known as kurtosis. It is calculated and reported either as an absolute or as a relative value. The absolute kurtosis is always a positive number.

\begin{textbox}
\[
\text{Absolute Kurtosis} \;=\;\frac{\mu_4}{\sigma^4}
\]
\end{textbox}
where \(\mu_4 = \dfrac{1}{n} \sum_{i=1}^n (x_i - \overline{x})^4\) is the fourth central moment.

The absolute kurtosis of a normal distribution, which we will learn in later chapter, is 3. The value 3 is taken as a datum (reference point) to calculate the relative kurtosis.
\begin{textbox}
\[
\text{Absolute Kurtosis}(\gamma_2) \;=\;\text{Relative Kurtosis} - 3
\]
\end{textbox}

\begin{itemize}
  \item Relative kurtosis \(=0\): \textbf{Mesokurtic} (e.g.\ Normal).
  \item Relative kurtosis \(>0\): \textbf{Leptokurtic} (heavy tails, sharp peak).
  \item Relative kurtosis \(<0\): \textbf{Platykurtic} (light tails, flat top).
\end{itemize}

\begin{center}
\begin{tikzpicture}
  \begin{axis}[
    width=12cm, height=6cm,
    axis lines=middle,
    ymin=0, ymax=0.65,
    xlabel={$x$}, ylabel={$f(x)$},
    domain=-6:6, samples=200,
    clip=false,
    every axis plot post/.append style={very thick},
  ]
    % Platykurtic: wider Gaussian (σ=2)
    \addplot[green!60!black] {1/(2*sqrt(2*pi)) * exp(-x^2/(2*2^2))};
    \node[black,font=\large] (platy) at (axis cs:4,0.25) {Platykurtic};
    \draw[->, black] (platy.west) to[bend right=15] (axis cs:2,0.14);

    % Mesokurtic: standard normal (σ=1)
    \addplot[blue] {1/sqrt(2*pi) * exp(-x^2/2)};
    \node[black,font=\large] (meso) at (axis cs:4,0.35) {Mesokurtic};
    \draw[->, black] (meso.west) to[bend right=15] (axis cs:1.2,0.22);

    % Leptokurtic: narrower Gaussian (σ=0.7)
    \addplot[red] {1/(0.7*sqrt(2*pi)) * exp(-x^2/(2*0.7^2))};
    \node[black,font=\large] (lepto) at (axis cs:4,0.45) {Leptokurtic};
    \draw[->, black] (lepto.west) to[bend right=20] (axis cs:0.6,0.5);
  \end{axis}
\end{tikzpicture}
\end{center}


\textbf{How to interpret the formula?}

Kurtosis raises deviations from the mean to the fourth power. This has a distinct purpose: it emphasizes extreme values far from the mean far more than values closer to it. Unlike cubing (used in skewness), which preserves the sign of deviations to detect asymmetry, raising to the fourth power removes the sign, treating all deviations equally, but magnifying larger ones disproportionately.

Before applying the fourth power, each deviation is \textbf{first divided by the standard deviation} $\sigma$. This step is crucial: it standardizes the scale of deviations, ensuring that the measure reflects the \textit{relative extremity} of values, not just their raw magnitude. Even if two distributions seem to have similar tail weights, the distribution with a \textit{smaller standard deviation} (i.e., a tighter central cluster) will yield \textit{larger standardized deviations}, which get exaggerated further by the fourth power.

Also, dividing the fourth central moment by $\sigma^4$ makes kurtosis a \textbf{dimensionless} and \textbf{scale-invariant} quantity, allowing meaningful comparisons across datasets.



\textbf{Example}: Using the same data \(x = \{2,3,4,5,8\}\):
\begin{itemize}
  \item Mean \(\overline{x}=4.4\), \quad Standard deviation \(\sigma\approx2.058\).
  \item Fourth central moment:
    \[
    \mu_4 = \frac{1}{5}\bigl[(-2.4)^4 + (-1.4)^4 + (-0.4)^4 + 0.6^4 + 3.6^4\bigr]
           \approx 41.03.
    \]
  \item \(\displaystyle \text{Kurtosis} (\gamma_2) = \frac{41.03}{(2.058)^4}\approx 2.29,\)
        \(\text{Relative Kurtosis}\approx -0.71\).  
        This dataset is \textbf{platykurtic}.
\end{itemize}


\chapter{Theory of Probability}
\section{Some Notation and Terminology}
\subsection{Random Experiment}

An \textbf{experiment} is generally defined as one or more actions that result in a specific outcome. 

\begin{textbox}
An experiment $E$ is called a \textbf{random experiment} if it satisfies the following conditions:

\begin{itemize}
    \item All possible outcomes of $E$ are known in advance.
    \item It is not possible to predict with certainty which specific outcome will occur in any given trial\footnote{A \textbf{trial} is a single performance or execution of an experiment. Tossing a coin once is a trial of the coin-tossing experiment.} of $E$.
    \item The experiment $E$ can be repeated, at least conceptually, under identical conditions an infinite number of times.
\end{itemize}
\end{textbox}

A common example of a random experiment is the tossing of a coin. The possible outcomes—`Head' and `Tail'—are known in advance, but it is impossible to determine with certainty which of the two outcomes will occur on any single toss.

\subsection{Event Space (a.k.a Sample Space)}

\begin{textbox}
    The set of all possible outcomes of a random experiment $E$ is called the \textbf{sample space} or \textbf{event space}, and it is denoted by $S$.
\end{textbox}

Each outcome, also known as an \textbf{elementary event point}, is an element of $S$.

For example, in the experiment of tossing a coin, the sample space is  
\[
S = \{H, T\}
\]  
where $H$ represents `Head’ and $T$ represents `Tail’.

If $E$ is the experiment of rolling a pair of dice, the sample space consists of all ordered pairs of numbers from 1 to 6:
\[
S = \{(1,1), (1,2), (1,3), \dots, (6,6)\}
\]
This sample space contains 36 distinct outcomes, as each die can show any of 6 faces independently.

\begin{textbox}
A sample space is \textbf{discrete} if it consists of a ﬁnite or countable inﬁnite set of outcomes.

A sample space is \textbf{continuous} if it contains an interval (either ﬁnite or inﬁnite) of real
numbers.
\end{textbox}
The sample space $S = \mathbb{R}^+$ is an example of a continuous sample space, whereas $S = \{H, T\}$ is a discrete sample space.

\subsection{Events}
We often focus on groups of related outcomes from a random experiment, which are represented as subsets of the sample space.
\begin{textbox}
    A subset of a sample space is called an \textbf{event}.
\end{textbox}

Consider the random experiment of rolling a die. The sample space is
\[
S = \{1, 2, 3, 4, 5, 6\}
\]
Let
\[
A = \{2, 4, 6\}
\]
be an event, which can be described as ``an even number appears when the die is rolled.''

There are various types of events:
\begin{itemize}
    \item \textbf{Impossible Event:}  
    An event that contains no outcomes from the sample space is called an impossible event. For example, $A = \emptyset$ is an impossible event.

    \item \textbf{Certain Event:}  
    An event that contains all outcomes of the sample space is called a certain or sure event. For example, $A = S$ is an impossible event.

    \item \textbf{Simple (Elementary) Event:}  
    An event consisting of exactly one outcome of the sample space. For example, $A = \{4\}$ is a simple event when rolling a die.

    \item \textbf{Composite (Compound) Event:}  
    An event that consists of more than one outcome of the sample space. For example, $A = \{2, 4, 6\}$ is a composite event when rolling a die.

    \item \textbf{Dependent and Independent Events:}  
    Two events are considered dependent if the occurrence of one event influences the probability of the other event occurring. Conversely, they are independent if the occurrence of one event does not affect the probability of the other event.
\end{itemize}

    \subsection{Mutually Exclusive Events}
    Two events are said to be \textbf{mutually exclusive} if they cannot occur at the simultaneously. Mathematically, if events $A_1$ and $A_2$ are exhaustive, then:
    \[
    A_1 \cap A_2 = \emptyset
    \]
    When tossing a coin, the events `Head' and `Tail' are mutually exclusive because both cannot occur at the same time. If we get a head, we cannot get a tail in that toss.
    
    \subsection{Exhaustive Set of Events}
    A set of events is said to be \textbf{exhaustive} at least one of the events in the set must occur. The union of all the events in the set equals the entire sample space $S$. Mathematically, if events $A_1, A_2, \dots, A_n$ are exhaustive, then:
    \[
    A_1 \cup A_2 \cup \dots \cup A_n = S
    \]
    When rolling a die, the events \{$1$\}, \{$2$\}, \{$3$\}, \{$4$\}, \{$5$\}, and \{$6$\} form an exhaustive set because they cover all possible outcomes of the die roll. One of these events must occur when the die is thrown.

\section{Definition of Probability}

\subsection{A Priori Probability}
    \textbf{A priori probability}, also known as \textbf{classical probability}, is the probability that is determined before an experiment is conducted. It is based on the knowledge of the system or experiment and is calculated using the total number of equally likely outcomes. 
    
    \begin{textbox}
        If there are $n$ mutually exclusive, exhaustive and equally likely\footnote{By the phrase `\textbf{equally likely}' it is meant that none of the outcomes is expected to occur in preference to other in any trial of the given random experiment.} outcomes of a random experiment and out of them $m$ outcomes are favorable to an event $A$, then the probability of the event $A$ is defined as $$P(A) = \dfrac{m}{n}$$
    \end{textbox}
    For example, the probability of getting a head in a fair coin toss is $$P(\text{Head}) = \frac{1}{2}$$ based on the assumption of equal likelihood of heads and tails.

    \subsection{A Posteriori Probability}
    \textbf{A posteriori probability}, also known as \textbf{empirical probability}, is the probability that is determined after an experiment is conducted. It is based on observed data or information obtained from the experiment. 

    \begin{textbox}
        Let $A$ be an event of a given random experiment. Let event $A$ occurs $N(A)$ number of times when the random experiment is repeated $N$ times under identical conditions. The probability of the event $A$ is defined as $$P(A) = \lim_{N\to \infty}\dfrac{N(A)}{N}$$
    \end{textbox}
    
    A posteriori probability can be updated as new evidence becomes available. For example, after observing several rolls of a die, you may update the probability of rolling a particular number based on the outcomes observed.

\section{Axioms of Probability}
The subject of probability is based on three commonsense rules, known as axioms. They are:

\begin{textbox}
    \begin{enumerate}
        \item $P(S) = 1$ where $S$ is the sample space.
        \item $0 \leq P(E) \leq 1$ for any event $E$.
        \item For two mutually exclusive events $E_1$ and $E_2$, $$P(E_1 \cup E_2) = P(E_1) + P(E_2)$$
        More generally, if $E_1, E_2, \dots E_n$ are mutually exclusive events,
        $$P(E_1 \cup E_2 \cup \dots E_n) = P(E_1) + P(E_2) + \dots + E_n$$
    \end{enumerate}
\end{textbox}

The first axiom states that the probability of the entire sample space $S$, which represents all possible outcomes of an experiment, is 1. It reflects the certainty that something in the sample space will occur. For example, when flipping a fair coin, the sample space is $S = \{\text{Head}, \text{Tail}\}$, and the probability that the outcome is either `Head' or `Tail' is 1.

The second axiom ensures that probabilities are valid numerical values between 0 and 1. A probability of 0 means the event is impossible (e.g., rolling a 7 on a standard six-sided die), while a probability of 1 means the event is certain to happen. All other events fall somewhere in between these two extremes.

This axiom applies when two events $E_1$ and $E_2$ are mutually exclusive—they cannot both happen at the same time. In such cases, the probability that either event occurs is the sum of their individual probabilities. For instance, when rolling a die, the probability of getting a $2$ or a $5$ is $P(2)+P(5)$, since a single die roll cannot result in both values.

These axioms imply the following theorems.
\begin{textbox}
\textbf{Theorem}: $P(\overline{E}) = 1 - P(E)$ for any event $E$
\end{textbox}

\textbf{Proof}: Let $S$ be a sample space and let $E$ be an event. Then $E$ and $\overline{E}$ are mutually exclusive. So by axiom 3,
$$P(E \cup \overline{E}) = P(E) + P(\overline{E})$$
But $E \cup \overline{E} = S$, and by axiom 1, $P(S) = 1$. Therefore,
$$P(E) + P(\overline{E}) = 1$$
which implies
$$P(\overline{E}) = 1 - P(E)$$
\hfill\(\blacksquare\)

\begin{textbox}
\textbf{Theorem}: $P(\emptyset) = 0$ where $\emptyset$ denotes the empty set.
\end{textbox}

\textbf{Proof}: Let $S$ be a sample space. Then $\emptyset = \overline{S}$. Therefore
$$P(\emptyset) = 1-P(S) = 1-1 = 0$$
\hfill\(\blacksquare\)

\begin{textbox}
\textbf{Theorem}: For any two events $A$ and $B$ (not necessarily mutually exclusive), $$P(A \cup B) = P(A) + P(B) - P(A \cap B)$$
\end{textbox}

\textbf{Proof}: From the Venn diagram, we can see that the event $A \cup B$ consists of three mutually exclusive events (subsets) $A \cap \overline{B}$, $A \cap B$ and $\overline{A} \cap B$.
\begin{center}
\begin{tikzpicture}
    % Draw set A
    \begin{scope}
        \draw[fill=blue!30, opacity=0.6] (2,2) circle (1.2);
    \end{scope}
    
    % Draw set B
    \begin{scope}
        \draw[fill=red!30, opacity=0.6] (3.4,2) circle (1.2);
    \end{scope}
    
    % Labels
    \node at (2,0.4) {$A$};
    \node at (3.5,0.4) {$B$};
    \node at (1.4,2) {$A \cap \overline{B}$};
    \node at (3.9,2) {$\overline{A} \cap B$};
    \node at (2.7,2) {$A \cap B$};
\end{tikzpicture}
\end{center}


The event $A$ consists of two mutually exclusive events $A \cap \overline{B}$ and $A \cap B$. Therefore
$$P(A) = P(A \cap \overline{B})+P(A \cap B)$$
Similarly,
$$P(B) = P(\overline{A} \cap B)+P(A \cap B)$$
Now,
\begin{align*}
    P(A \cup B) &= P(A \cap \overline{B})+P(A \cap B)+P(\overline{A} \cap B) \\
    &= \left[P(A) - P(A \cap B)\right] + P(A \cap B) + \left[P(B) - P(A \cap B)\right] \\
    &=P(A) + P(B) - P(A \cap B)
\end{align*}
\hfill\(\blacksquare\)

\textbf{Example}: Consider a fair six-sided die, and define two events:
\begin{itemize}
    \item $A$: The event that the die shows an odd number (i.e., $A = \{1, 3, 5\}$)
    \item $B$: The event that the die shows a number greater than or equal to 4 (i.e.,  $A = \{4,5,6\}$)
\end{itemize}


The union of \( A \) and \( B \) is the event that either event \( A \) or event \( B \) occurs (or both). The union of \( A \) and \( B \) is denoted by:

\[
A \cup B = \{1, 3, 5, 4, 6\} = \{1, 3, 4, 5, 6\}
\]

To find the probability of the union \( P(A \cup B) \), we use the formula:

\[
P(A \cup B) = P(A) + P(B) - P(A \cap B)
\]

\begin{itemize}
    \item \( P(A) = \frac{3}{6} = 0.5 \) (since there are 3 odd numbers: 1, 3, 5)
    \item \( P(B) = \frac{3}{6} = 0.5 \) (since there are 3 numbers \( \geq 4 \): 4, 5, 6)
    \item \( P(A \cap B) = \frac{1}{6} = \frac{1}{3} \) (since 5 is the only number that is both odd and \( \geq 4 \))
\end{itemize}

So, the probability of \( A \cup B \) is:

\[
P(A \cup B) = 0.5 + 0.5 - \frac{1}{3} = 1 - \frac{1}{3} = \frac{2}{3}
\]

Thus, the probability of rolling a die and getting either an odd number or a number greater than or equal to 4 is \( \frac{2}{3} \).


\begin{textbox}
\textbf{Theorem}: For any three events $A$, $B$ and $C$ (not necessarily mutually exclusive), 
\begin{align*}
    P(A \cup B \cup C) = &P(A) + P(B) +P(C) - P(A \cap B) - P(B \cap C) \\
    &- P(A \cap C)  + P(A \cap B \cap C)
\end{align*}
\end{textbox}

\textbf{Proof}: We begin by applying the two-event formula to $A \cup (B \cup C)$:

$$P(A \cup B \cup C) = P(A) + P(B \cup C) - P(A \cap (B \cup C))$$

Now, apply the two-event formula to $P(B \cup C)$:

$$P(B \cup C) = P(B) + P(C) - P(B \cap C)$$

Also, apply distributivity to expand \( P(A \cap (B \cup C)) \):

\begin{align*}
P(A \cap (B \cup C)) &= P((A \cap B) \cup (A \cap C)) \\
&= P(A \cap B) + P(A \cap C) - P(A \cap B \cap C)
\end{align*}

Substituting back into the original expression:

\begin{align*}
P(A \cup B \cup C) &= P(A) + \big[ P(B) + P(C) - P(B \cap C) \big] \\
&\quad - \big[ P(A \cap B) + P(A \cap C) - P(A \cap B \cap C) \big] \\
&= P(A) + P(B) + P(C) - P(B \cap C) \\
&\quad - P(A \cap B) - P(A \cap C) + P(A \cap B \cap C)
\end{align*}
\hfill\(\blacksquare\)

\begin{textbox}
\textbf{Theorem}: Let \( A_1, A_2, \ldots, A_n \) be $n$ number of events of a random experiment. Then the probability of their union is given by:

\begin{align*}
P\left( \bigcup_{i=1}^n A_i \right)
= &\sum_{i=1}^{n} P(A_i)
- \sum_{1 \le i < j \le n} P(A_i \cap A_j) \\
&+ \sum_{1 \le i < j < k \le n} P(A_i \cap A_j \cap A_k)
- \cdots \\
&+ (-1)^{n+1} P(A_1 \cap A_2 \cap \cdots \cap A_n)
\end{align*}

\end{textbox}
The proof of this theorem is left as an exercise.

\begin{textbox}
    \textbf{Theorem}: If $A$ and $B$ are two events of a random experiment, then the probability that exactly one of them occurs is given by
    $$P(\text{exactly one of } A \text{ or } B) = P(A) + P(B) - 2P(A \cap B)$$
\end{textbox}
\textbf{Proof}: The event ``exactly one of $A$ or $B$ occurs'' means either $A$ happens and $B$ doesn't, or $B$  happens and $A$ doesn't. That means the event:
\[
(A \cap \overline{B}) \cup (\overline{A} \cap B)
\]

% Since the events $(A \cap \overline{B})$ and $(\overline{A} \cap B)$ are disjoint, so:
% \[
% P((A \cap \overline{B}) \cup (\overline{A} \cap B)) = P(A \cap \overline{B}) + P(\overline{A} \cap B)
% \]

% Now,
% \[
% P(A \cap \overline{B}) = P(A) - P(A \cap B)
% \]
% \[
% P(\overline{A} \cap B) = P(B) - P(A \cap B)
% \]

% Therefore,
% \[
% P(\text{exactly one of } A \text{ or } B) = P(A) + P(B) - 2P(A \cap B)
% \]

\begin{center}
\begin{tikzpicture}
    % Draw set A
    \begin{scope}
        \draw[fill=blue!30, opacity=0.6] (2,2) circle (1.2);
    \end{scope}
    
    % Draw set B
    \begin{scope}
        \draw[fill=red!30, opacity=0.6] (3.4,2) circle (1.2);
    \end{scope}
    
    % Labels
    \node at (2,0.4) {$A$};
    \node at (3.5,0.4) {$B$};
    \node at (1.4,2) {$A \cap \overline{B}$};
    \node at (3.9,2) {$\overline{A} \cap B$};
    \node at (2.7,2) {$A \cap B$};
\end{tikzpicture}
\end{center}

We can see it from the Venn diagram:
\begin{align*}
    P((A \cap \overline{B}) \cup (\overline{A} \cap B)) &= P(A \cup B) - P(A \cap B) \\
    &= (P(A) + P(B) - P(A \cap B)) - P(A \cap B) \\
    &= P(A) + P(B) - 2P(A \cap B)
\end{align*}

Therefore,
\[
P(\text{exactly one of } A \text{ or } B) = P(A) + P(B) - 2P(A \cap B)
\]
\hfill\(\blacksquare\)

\begin{textbox}
\textbf{Boole's Inequality}: Let \( A_1, A_2, \ldots, A_n \) be $n$ events of a random experiment. Then:

\[
P\left( \bigcup_{i=1}^{n} A_i \right) \leq \sum_{i=1}^{n} P(A_i)
\]
\end{textbox}

\textbf{Proof}: We prove the inequality by induction on \( n \).

\underline{Base Case:} For \( n = 1 \),
\[
P(A_1) = P(A_1)
\]
so the inequality holds with equality.

\underline{Inductive Step:} Assume the inequality holds for \( n = k \), i.e.,
\[
P\left( \bigcup_{i=1}^{k} A_i \right) \leq \sum_{i=1}^{k} P(A_i)
\]

Now consider \( n = k+1 \). Let \( B = \bigcup_{i=1}^{k} A_i \). Then:
\[
P\left( \bigcup_{i=1}^{k+1} A_i \right) = P(B \cup A_{k+1})
\]

Using the formula for the union of two events:
\[
P(B \cup A_{k+1}) = P(B) + P(A_{k+1}) - P(B \cap A_{k+1}) \leq P(B) + P(A_{k+1})
\]

Applying the induction hypothesis to \( P(B) \):
\[
P(B \cup A_{k+1}) \leq \sum_{i=1}^{k} P(A_i) + P(A_{k+1}) = \sum_{i=1}^{k+1} P(A_i)
\]

Thus, the inequality holds for \( n = k+1 \). By the principle of mathematical induction, the inequality holds for all \( n \in \mathbb{N} \).
\hfill\(\blacksquare\)


Boole's inequality provides a simple and conservative upper bound for the probability of the union of multiple events. This is important because, without detailed knowledge of the relationships between the events (e.g., how much they overlap), we can still estimate the probability that at least one of the events occurs by adding their individual probabilities.

\textbf{Example}: If you have three events with probabilities:
\[
P(A_1) = 0.3, \quad P(A_2) = 0.5, \quad P(A_3) = 0.7,
\]
but you don’t know the intersections between them, Boole’s inequality will tell you that the probability of at least one occurring is at most:

\[
P(A_1 \cup A_2 \cup A_3) \leq 0.3 + 0.5 + 0.7 = 1.5
\]

Since probabilities cannot exceed 1, this shows that the bound is very loose, but it is still useful for getting a rough estimate.


\begin{textbox}
\textbf{Bonferroni's inequality}: Let \( A_1, A_2, \ldots, A_n \) be events of a random experiment. Then:

\[
P\left( \bigcap_{i=1}^n A_i \right) \geq \sum_{i=1}^n P(A_i) - (n - 1)
\]
\end{textbox}

\textbf{Proof:} We proceed by induction on \( n \).

\underline{Base case:} For \( n = 2 \),
we begin with the identity:
\[
P(A_1 \cup A_2) = P(A_1) + P(A_2) - P(A_1 \cap A_2)
\]

Using the axiom that \( P(A_1 \cup A_2) \leq 1 \), we substitute:
\[
P(A_1) + P(A_2) - P(A_1 \cap A_2) \leq 1
\]

Rearranging:
\[
 P(A_1 \cap A_2) \geq P(A_1) + P(A_2) - 1
\]

So the inequality holds for $n = 2$.

\underline{Inductive step:} Assume the result holds for \( n = k \), i.e.,
\[
P\left( \bigcap_{i=1}^{k} A_i \right) \geq \sum_{i=1}^{k} P(A_i) - (k - 1)
\]

Let \( B = \bigcap_{i=1}^{k} A_i \). Then:
\[
P\left( \bigcap_{i=1}^{k+1} A_i \right) = P(B \cap A_{k+1}) \geq P(B) + P(A_{k+1}) - 1
\]

Using the induction hypothesis:
\[
P(B \cap A_{k+1}) \geq \left( \sum_{i=1}^{k} P(A_i) - (k - 1) \right) + P(A_{k+1}) - 1 = \sum_{i=1}^{k+1} P(A_i) - k
\]

Therefore, the inequality holds for \( n = k + 1 \). By induction, it holds for all \( n \in \mathbb{N} \). \

The Bonferroni inequality for intersections provides a lower bound for the probability of the intersection of multiple events. 
\hfill\(\blacksquare\)

\textbf{Example}: Consider three events \( A_1 \), \( A_2 \), and \( A_3 \) with probabilities:

\[
P(A_1) = 0.6, \quad P(A_2) = 0.5, \quad P(A_3) = 0.7
\]

Using Bonferroni’s inequality, the lower bound for the probability that all three events occur is:

\[
P(A_1 \cap A_2 \cap A_3) \geq 0.6 + 0.5 + 0.7 - 2 = 0.8
\]

Thus, the probability that all three events occur simultaneously is at least \( 0.8 \).


\section{Conditional Probability}

Conditional probability is the probability of an event occurring given that another event has already occurred.

\begin{textbox}
    Let $A$ and $B$ be two events of a random experiment. The \textbf{conditional probability} of event \( A \) given that event \( B \) has already occurred is defined as:

\[
P(A \mid B) = \frac{P(A \cap B)}{P(B)}, \quad \text{provided} \, P(B) \neq 0
\]
\end{textbox}

This formula tells us how likely event \( A \) is, given that we know event \( B \) has happened. The idea is that we restrict our sample space to the outcomes where \( B \) occurs, and then we compute the probability of \( A \) within this restricted sample space.

\textbf{Example}: Let's define two events when rolling a fair six-sided die:

\begin{itemize}
    \item \( A \): The event that the die shows an \textit{even face}, i.e., \( A = \{2, 4, 6\} \).
    \item \( B \): The event that the die shows a \textit{multiple of 3}, i.e., \( B = \{3, 6\} \).
\end{itemize}
\begin{align*}
    P(A) &= P(\{2, 4, 6\})= \frac{3}{6} = \frac{1}{2} \\
    P(B) &= P(\{3, 6\})=  \frac{2}{6} = \frac{1}{3} \\
    P(A \cap B) &= P(\{6\}) = \frac{1}{6}
\end{align*}

The conditional probability of \( A \) given \( B \) is:

\[
P(A \mid B) = \frac{P(A \cap B)}{P(B)} = \dfrac{\frac{1}{6}}{\frac{1}{3}}  = \frac{1}{2}
\]

The conditional probability of \( B \) given \( A \) is:

\[
P(B \mid A) = \frac{P(A \cap B)}{P(A)} =\frac{\frac{1}{6}}{\frac{1}{2}} = \frac{1}{3}
\]

\begin{textbox}
\textbf{Multiplication Rule of Probabilities}: If \( A \) and \( B \) are any events in the sample space \( S \), then:
\begin{align*}
    P(A \cap B) &= P(A) \cdot P(B \mid A), \quad \text{if } P(A) \neq 0 \\
 &= P(B) \cdot P(A \mid B), \quad \text{if } P(B) \neq 0
\end{align*}
\end{textbox}
The second rule follows directly from the definition of conditional probability by multiplying both sides by \( P(B) \).  
The first rule is obtained from the second by simply switching the roles of \( A \) and \( B \).

\section{Rule of Total Probability}

The Rule of Total Probability allows us to compute the probability of an event based on a partition of the sample space.

\subsection{For Two Events}
\begin{textbox}
    If \( B \) and its complement \( \overline{B} \) form a partition of the sample space (i.e., mutually exclusive and collectively exhaustive events), then for any event \( A \):

\[
P(A) = P(A \mid B)P(B) + P(A \mid \overline{B})P(\overline{B})
\]
\end{textbox}
\textbf{Proof}: Let \( B \) and \( \overline{B} \) form a partition (i.e., mutually exclusive and exhaustive events) of the sample space. Then any event \( A \) can be expressed as:

\[
A = (A \cap B) \cup (A \cap \overline{B})
\]

Since the sets \( A \cap B \) and \( A \cap \overline{B} \) are disjoint, the two parts are mutually exclusive. So:

\[
P(A) = P(A \cap B) + P(A \cap \overline{B})
\]

Using the definition of conditional probability:

\[
P(A \cap B) = P(A \mid B)P(B), \quad P(A \cap \overline{B}) = P(A \mid \overline{B})P(\overline{B})
\]

Substituting:

\[
P(A) = P(A \mid B)P(B) + P(A \mid \overline{B})P(\overline{B})
\]
\hfill\(\blacksquare\)

\subsection{For Multiple Events}

\begin{textbox}

Let \( B_1, B_2, \dots, B_n \) be a partition of the sample space (i.e., mutually exclusive and collectively exhaustive events). Then for any event \( A \):

\[
P(A) = \sum_{i=1}^{n} P(A \mid B_i)P(B_i)
\]
\end{textbox}

\textbf{Proof}: Let \( B_1, B_2, \dots, B_n \) be a partition of the sample space, i.e.,

\begin{itemize}
    \item The events \( B_i \) are mutually exclusive: \( B_i \cap B_j = \emptyset \) for \( i \ne j \)
    \item The events \( B_i \) are collectively exhaustive: \( \bigcup_{i=1}^n B_i = S \)
\end{itemize}

Then for any event \( A \subseteq S \):

\[
A = A \cap S = A \cap \left( \bigcup_{i=1}^n B_i \right) = \bigcup_{i=1}^n (A \cap B_i)
\]

Since the \( B_i \) are disjoint, so are the \( A \cap B_i \), so:

\[
P(A) = \sum_{i=1}^n P(A \cap B_i)
\]

Using conditional probability:

\[
P(A \cap B_i) = P(A \mid B_i)P(B_i)
\]

Therefore:

\[
P(A) = \sum_{i=1}^n P(A \mid B_i)P(B_i)
\]
\hfill\(\blacksquare\)

\textbf{Example}: Suppose a factory has three machines:

\begin{itemize}
    \item Machine \( M_1 \) produces 30\% of the items, with a defect rate of 1\%.
    \item Machine \( M_2 \) produces 50\% of the items, with a defect rate of 2\%.
    \item Machine \( M_3 \) produces 20\% of the items, with a defect rate of 3\%.
\end{itemize}

Let \( D \) be the event that an item is defective. We are asked to find \( P(D) \), the total probability that a randomly selected item is defective.

Using the Rule of Total Probability:

\[
P(D) = P(D \mid M_1)P(M_1) + P(D \mid M_2)P(M_2) + P(D \mid M_3)P(M_3)
\]

Substituting the known values:

\begin{align*}
    P(D) &= (0.01 \times 0.30) + (0.02 \times 0.50) + (0.03 \times 0.20) \\
    &= 0.003 + 0.010 + 0.006 = 0.019
\end{align*}

The probability that a randomly chosen item is defective is $0.019$ or $1.9$\%.


\section{Bayes' Theorem}
Bayes' Theorem is a fundamental result in probability theory that arises directly from the definition of conditional probability and the Rule of Total Probability. 
\begin{textbox}
    \textbf{Bayes' Theorem}: Let \( B_1, B_2, \ldots, B_n \) be a partition of the sample space (i.e., mutually exclusive and collectively exhaustive events) and none of which has zero probability i.e. \( P(B_i) > 0 \) for all \( i \), then for any event \( A \) with \( P(A) > 0 \), the probability of \( B_r \) given \( A \) is:
\[
P(B_r \mid A) = \frac{P(B_r) \cdot P(A \mid B_r)}{\sum_{i=1}^{n} P(B_i) \cdot P(A \mid B_i)}
\]

for \( r = 1, 2, \ldots, n \).
\end{textbox}
\textbf{Proof}: Let \( B_1, B_2, \ldots, B_n \) be a partition of the sample space \( S \) such that:
\begin{itemize}
    \item The events \( B_i \) are mutually exclusive: \( B_i \cap B_j = \emptyset \) for \( i \neq j \),
    \item The union of the \( B_i \)'s covers the whole sample space: \( \bigcup_{i=1}^n B_i = S \),
    \item \( P(B_i) > 0 \) for all \( i \).
\end{itemize}

Let \( A \) be any event with \( P(A) > 0 \). By the definition of conditional probability:

\[
P(B_r \mid A) = \frac{P(B_r \cap A)}{P(A)}
\]

We apply the Multiplication Rule of Probabilities:

\[
P(B_r \cap A) = P(B_r) \cdot P(A \mid B_r)
\]

So:

\[
P(B_r \mid A) = \frac{P(B_r) \cdot P(A \mid B_r)}{P(A)}
\]

Now, using the Rule of Total Probability:

\[
P(A) = \sum_{i=1}^n P(B_i) \cdot P(A \mid B_i)
\]

Substitute this into the denominator:

\[
P(B_r \mid A) = \frac{P(B_r) \cdot P(A \mid B_r)}{\sum_{i=1}^{n} P(B_i) \cdot P(A \mid B_i)}
\]
\hfill\(\blacksquare\)

\textbf{Example}: Suppose in a dataset of 1000 emails, 200 are identified as spam and 800 as non-spam. Among the spam emails, 80 contain the word `discount', while 80 of the non-spam emails also contain this word. We need to calculate the probability that an email is spam given that it contains the word `discount'.
\begin{itemize}
    \item \( P(S) = \dfrac{200}{1000} = 0.2 \): Probability that an email is spam.
    \item \( P(\overline{S}) = \dfrac{800}{1000} = 0.8 \): Probability that an email is not spam.
    \item \( P(D \mid S) =\dfrac{80}{200} =  0.4 \): Probability that the word ``discount'' appears in a spam email.
    \item \( P(D \mid \overline{S})=\dfrac{80}{800} = 0.1 \): Probability that ``discount'' appears in a non-spam email.
\end{itemize}

We want to find the probability that an email is spam given that it contains the word ``discount'', i.e., \( P(S \mid D) \).

Using Bayes' Theorem:
\[
P(S \mid D) = \frac{P(S) \cdot P(D \mid S)}{P(S) \cdot P(D \mid S) + P(\overline{S}) \cdot P(D \mid \overline{S})}
\]

Substituting the values:
\[
P(S \mid D) = \frac{0.2 \times 0.4}{0.2 \cdot 0.4 + 0.8 \cdot 0.1}
= \frac{0.08}{0.08 + 0.08}
= \frac{0.08}{0.16} = 0.5
\]

So, the probability that the email is spam given it contains the word ``discount'' is \( 50\% \). Even though only \(20\%\) of all emails are spam, once we see the word ``discount'' the chance the email is spam rises to \(50\%\), because that word is much more common in spam than in legitimate messages.

\subsection{Importance of Bayes' Theorem and Updating Probability}

Bayes’ Theorem is important because it provides a mathematical framework for updating probabilities when new information becomes available. In real-world terms, it helps us refine our beliefs or predictions as we gather more data.

Suppose we want to determine the probability of an event \( A \), such as an email being spam. Initially, we rely on prior knowledge, which is represented by the prior probability \( P(A) \). Now, imagine we observe some new evidence \( B \), such as the presence of a specific word like ``discount'' in the email.

Bayes' Theorem helps us compute the updated probability \( P(A \mid B) \), known as the posterior probability, using the following formula:

\[
P(A \mid B) = \frac{P(A) \cdot P(B \mid A)}{P(B)}
\]

Here:
\begin{itemize}
    \item \( P(A) \) is the \textbf{prior probability} — our initial belief (prediction) about the event \( A \).
    \item \( P(B \mid A) \) is the \textbf{likelihood} — the probability of observing evidence \( B \) given that \( A \) is true.
    \item \( P(B) \) is the \textbf{marginal probability} of observing evidence \( B \) under all possible conditions.
    \item \( P(A \mid B) \) is the \textbf{posterior probability} — our updated belief (prediction)  about \( A \) after observing \( B \).
\end{itemize}

This formula enables us to revise our estimate of the probability of \( A \) whenever new information \( B \) becomes available. Depending on the relationship between \( A \) and \( B \), the posterior probability may be higher or lower than the prior, reflecting the impact of the new evidence.

\section{Statistical Independence of Events}

If $A$ and $B$ are any two events in a sample space $S$, we say that ``$A$ is independent of $B$'' if:

$$
P(A \mid B) = P(A)
$$

This means that knowing whether or not $B$ has occurred ``does not change'' the probability of $A$ occurring.

From the definition of conditional probability:

$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)},
$$

if we substitute and rearrange the condition $P(A \mid B) = P(A)$, we get:

$$
\frac{P(A \cap B)}{P(B)} = P(A) \quad \Rightarrow \quad P(A \cap B) = P(A) \cdot P(B)
$$

Thus, another equivalent definition of independence is:

$$
P(A \cap B) = P(A) \cdot P(B)
$$

Now, to check whether $B$ is independent of $A$, we look at:

$$
P(B \mid A) = \frac{P(B \cap A)}{P(A)} = \frac{P(A \cap B)}{P(A)}
$$

Since we just showed that $P(A \cap B) = P(A) \cdot P(B)$, substitute:

$$
P(B \mid A) = \frac{P(A) \cdot P(B)}{P(A)} = P(B)
$$

Thus, $B$ is also independent of $A$.

\begin{textbox}
If \( A \) is independent of \( B \), then \( B \) is also independent of \( A \). Therefore, we say that \( A \) and \( B \) are \textbf{mutually independent}.
\end{textbox}

\begin{textbox}
\textbf{Multiplication Rule for Independent Events}: Two events $A$ and $B$ are (mutually) independent events if and only if
$$P( A \cap B ) = P( A ) \cdot P( B )$$
\end{textbox}

\textbf{Example}: Consider the experiment of rolling two fair six-sided dice, and consider the following events:
\begin{itemize}
    \item \( A \): The first die shows a 1.  
    \[ A = \{(1,1), (1,2), (1,3), (1,4), (1,5), (1,6)\} \]
    \item \( B \): The second die shows a 2.  
    \[ B = \{(1,2), (2,2), (3,2), (4,2), (5,2), (6,2)\} \]
\end{itemize}

The total number of outcomes in the sample space is \( 6 \times 6 = 36 \).

We compute:
\[
P(A) = \frac{6}{36} = \frac{1}{6}, \quad P(B) = \frac{6}{36} = \frac{1}{6}
\]
\[
A \cap B = \{(1,2)\} \quad \Rightarrow \quad P(A \cap B) = \frac{1}{36}
\]

Since
\[
P(A \cap B) = P(A) \cdot P(B) = \frac{1}{6} \cdot \frac{1}{6} = \frac{1}{36},
\]
we conclude that the events \( A \) and \( B \) are \textbf{independent}.

\begin{textbox}
\textbf{Theorem:}  
If the events \( A \) and \( B \) are independent, then the following pairs of events are also independent:
\[
\text{(1) } A \text{ and } \overline{B}, \quad \text{(2) } \overline{A} \text{ and } B, \quad \text{(3) } \overline{A} \text{ and } \overline{B}
\]
\end{textbox}
\textbf{Proof:}

\begin{itemize}
  \item[1.] Since \( A \) and \( B \) are independent, we have:
  \[
  P(A \cap B) = P(A)\cdot P(B)
  \]
  Then,
  \[
  P(A \cap \overline{B}) = P(A) - P(A \cap B) = P(A) - P(A)\cdot P(B) = P(A)(1 - P(B)) = P(A)\cdot P(\overline{B})
  \]
  So, \( A \) and \( \overline{B} \) are independent.

  \item[2.] Similarly,
  \[
  P(\overline{A} \cap B)  = P(B) - P(A \cap B) = P(B) - P(A)\cdot P(B) = P(B)(1 - P(A)) = P(\overline{A})\cdot P(B)
  \]
  So, \( \overline{A} \) and \( B \) are independent.

  \item[3.] Finally,
  \[
  P(\overline{A} \cap \overline{B}) = P(\overline{A \cup B}) = 1 - P(A \cup B) = 1 - [P(A) + P(B) - P(A \cap B)]
  \]
  \[
  = 1 - [P(A) + P(B) - P(A)\cdot P(B)] = (1 - P(A))(1 - P(B)) = P(\overline{A})\cdot P(\overline{B})
  \]
  So, \( \overline{A} \) and \( \overline{B} \) are also independent.
\end{itemize}
\hfill\(\blacksquare\)

\begin{textbox}
    \textbf{Theorem}: If A and B are independent events, then:

\[
P(A \cup B) = 1 - P(\overline{A})\cdot P(\overline{B})
\]
\end{textbox}

\textbf{Proof}: Using the formula for the union of two events:

\[
P(A \cup B) = P(A) + P(B) - P(A \cap B)
\]

Since \( A \) and \( B \) are independent, \( P(A \cap B) = P(A)\cdot P(B) \), so:

\begin{align*}
    P(A \cup B) &= P(A) + P(B) - P(A)\cdot P(B) \\
    &= 1 - \left(1 - P(A) - P(B) + P(A)\cdot P(B)\right) \\
    &= 1- (1-P(A))(1-P(B)) \\
    &= 1 - P(\overline{A})P(\overline{B})
\end{align*}
\hfill\(\blacksquare\)

\subsection{Pairwise vs. Mutual Independence of Multiple Events}

Let \( A \), \( B \), and \( C \) be three events in a sample space \( S \). The events \( A \), \( B \), and \( C \) are said to be \textbf{pairwise independent} if:
\[
\begin{aligned}
P(A \cap B) &= P(A) \cdot P(B), \\
P(A \cap C) &= P(A) \cdot P(C), \\
P(B \cap C) &= P(B) \cdot P(C)
\end{aligned}
\]

The events \( A \), \( B \), and \( C \) are said to be \textbf{mutually independent} if:
\begin{itemize}
    \item They are pairwise independent, and
    \item The joint probability satisfies:
    \[
    P(A \cap B \cap C) = P(A) \cdot P(B) \cdot P(C)
    \]
\end{itemize}

\textbf{Note:} Mutual independence \emph{implies} pairwise independence, but the converse is not necessarily true.

\subsection{Mutually Exclusive and Independent Events}

Let \( A \) and \( B \) be two events in a sample space.

\begin{itemize}
    \item If \( A \) and \( B \) are \textbf{mutually exclusive}, then:
    \[
    A \cap B = \emptyset \quad \Rightarrow \quad P(A \cap B) = 0
    \]
    
    \item If \( A \) and \( B \) are \textbf{independent}, then:
    \[
    P(A \cap B) = P(A) \cdot P(B)
    \]
\end{itemize}

If both conditions are true, then:
\[
P(A) \cdot P(B) = 0
\]
This implies that either \( P(A) = 0 \), \( P(B) = 0 \), or both.

\begin{textbox}
Two events \( A \) and \( B \) cannot be both mutually exclusive and independent unless at least one of them has probability zero.
\end{textbox}


In terms of a Venn diagram, the independence of events implies that the overlap between sets \( A \) and \( B \) (i.e., \( A \cap B \)) should be such that its area (probability) equals the product of the areas (probabilities) of each individual circle. 

\begin{center}
\begin{tikzpicture}
  % Draw event A
  \draw[fill=blue!30, opacity=0.5] (2,2) circle (1.2) node[left=20pt, above=20pt] {\(A\)};

  % Draw event B
  \draw[fill=red!30, opacity=0.5] (3.5,2) circle (1.2) node[right=20pt, above=20pt] {\(B\)};
\end{tikzpicture}
\end{center}

This is different from mutually exclusive events, where the sets do not overlap at all. Both the condition will be satisfied if the area of at least one of the circle is zero.

\subsection{Reliability Analysis using Statistical Independence}

Reliability analysis is the branch of engineering concerned with estimating the failure
rates of systems. If a machine has a reliability of $0.95$ over $1$ year, it means there is a $95\%$ chance that it will work without failure for the entire year. In many systems, components are arranged either in \textit{series} or in \textit{parallel}, and the system's reliability depends on the configuration.

\begin{itemize}
    
\item \textbf{System with Components in Series}: 

Consider a system with two components, \( A \) and \( B \), connected in \textbf{series}. In this setup, the system will work only if \textbf{both} components function properly.

\begin{center}
\begin{tikzpicture}[thick]
  % Draw lines before and after the blocks
  \draw (0,0) -- (1,0);
  \draw (2,0) -- (3,0);
  \draw (4,0) -- (5,0);

  % Draw component A
  \draw (1, -0.5) rectangle (2, 0.5);
  \node at (1.5, 0) {\textbf{A}};

  % Draw component B
  \draw (3, -0.5) rectangle (4, 0.5);
  \node at (3.5, 0) {\textbf{B}};
\end{tikzpicture}
\end{center}

Suppose the probability that $A$ functions is given by $P(A) = 0.96$, and the probability that $B$ functions is given by
$P(B) = 0.92$. Assuming that the components function independently, the probability that the system works is:

\[
\begin{aligned}
P(\text{System functions}) &= P(A \cap B) \\
&= P(A) \cdot P(B) \\
&= 0.96\times 0.92 = 0.8832
\end{aligned}
\]

Since both components must function, the system's reliability is lower than that of either component individually. The more components in series, the more chances for failure.

\item \textbf{System with Components in Parallel}:

Now consider a system with two components, \( C \) and \( D \), connected in \textbf{parallel}. In this case, the system will function as long as \textbf{at least one} component functions.

\begin{center}
\begin{tikzpicture}[thick]
  % Input and output lines
  \draw (-2,0) -- (-1,0);
  \draw (1,0) -- (2,0);
  
  % Top branch with C
  \draw (-1,0) -- (0,0.9);
  \draw (0,0.9) -- (1,0);
  \draw (0,0.5) node[draw, fill=white, minimum size=8mm] {\textbf{C}};
  
  % Bottom branch with D
  \draw (-1,0) -- (0,-0.9);
  \draw (0,-0.9) -- (1,0);
  \draw (0,-0.5) node[draw, fill=white, minimum size=8mm] {\textbf{D}};
\end{tikzpicture}
\end{center}

Suppose the probabilities that the components function are:
\[
P(C) = 0.88, \quad P(D) = 0.85
\]

Assuming independence, the probability that the system functions is given by:

\[
\begin{aligned}
P(\text{System functions}) &= P(C \cup D) \\
&= P(C) + P(D) - P(C \cap D) \\
&= P(C) + P(D) - P(C).P(D) \\
&= 0.88 + 0.85 - (0.88 \times 0.85) \\
&= 1.73 - 0.748 = 0.982
\end{aligned}
\]

In parallel systems, the system is more reliable than the individual components. This configuration adds redundancy, improving fault tolerance.
\end{itemize}

\chapter{Random Variables and Probability Distributions}
\section{What is a Random Variable?}
In most cases, we can associate a real number with each elementary event in a sample space. For example, in a coin toss, we may assign the number \(1\) to the outcome `Head' and \(0\) to the outcome `Tail'. Similarly, when a die is thrown, the outcomes correspond to the numbers \(1, 2, 3, \dots, 6\), depending on which face appears on top.

This assignment of numerical values to outcomes allows us to define a function on the sample space. A real-valued function defined on the sample space is called a \textbf{random variable} (also referred to as a \textbf{stochastic variable}).

\begin{textbox}
    Let \( S \) be a sample space of a random experiment. A \textbf{random variable} is a function  
\[
X : S \rightarrow \mathbb{R}
\]
where each outcome \( s \in S \) is mapped to a real number \( X(s) \).

\end{textbox}
\textbf{Note}: A random variable is denoted by an uppercase letter such as $X$ and $Y$. After experiment is conducted, the measured value of the random variable is denoted by a lowercase letter such as $x$
and $y$.

\subsection{Random Variable Types}

There are two main types:

\begin{enumerate}
    \item \textbf{Discrete Random Variable:} \\
    A discrete random variable takes on a countable\footnote{This means the values can be finite (like a die roll) or countably infinite (like the number of coin tosses until the first head).} number of distinct values. Let \( X \) be the number of heads obtained when a fair coin is tossed three times. 
    The possible values of \( X \) are \( 0, 1, 2, 3 \). Since these values are countable and finite, \( X \) is a discrete random variable.

    \item \textbf{Continuous Random Variable:} \\
    A continuous random variable takes any value within a certain range of real numbers. The possible values are uncountable and include fractions and decimals. Let \( Y \) be the amount of time (in minutes) a customer waits in a queue at a bank. 
    The variable \( Y \) can take any real value within a range, such as \( 0 \leq Y \leq 30 \), including fractions like \( 3.5 \) or \( 12.75 \). Hence, \( Y \) is a continuous random variable.
\end{enumerate}

\section{Probability Distribution}

To each value of a random variable \( X \), there corresponds a definite probability.  
Let \( x_1, x_2, \dots, x_n \) be the possible values of \( X \), and let \( p_1, p_2, \dots, p_n \) be the corresponding probabilities such that:
\[
P(X = x_i) = p_i \quad \text{for } i = 1, 2, \dots, n
\]

A statement of these values along with their associated probabilities defines the {probability distribution} of the random variable \( X \).

\subsection{Probability Mass Function (PMF)}

The {Probability Mass Function (PMF)} is used for \textbf{discrete random variables}. It gives the probability that a discrete random variable \( X \) takes a specific value \( x_k \). The PMF is defined as:
\begin{textbox}
\[
p_X(x_k) = P(X = x_k)
\]
\end{textbox}
where \( x_k \) is a specific value of the random variable \( X \). The PMF satisfies the following properties:

\begin{enumerate}
    \item \( 0 \leq p_X(x_k) \leq 1 \) for all \( k \)
    \item \( \sum_{k} p_X(x_k) = 1 \)
\end{enumerate}

\textbf{Example}: Consider a discrete random variable \( X \) with the following distribution:
\[
p_X(x) = P(X = x) = 
\begin{cases}
\frac{1}{4}, & \text{if } x = 1 \\
\frac{1}{2}, & \text{if } x = 2 \\
\frac{1}{4}, & \text{if } x = 3 \\
0, & \text{otherwise}
\end{cases}
\]

The PMF is visualized as follows:

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=10cm,
    height=5cm,
    ybar,
    bar width=10pt,
    % axis x line=middle,
    % axis y line=middle,
    axis lines=left,
    xlabel={$x$},
    ylabel={$p_X(x)$},
    xtick={1,2,3},
    ytick={0,0.25,0.5},
    ymin=0.1, ymax=0.6,
    xmin=0.5, xmax=3.5,
    % ymajorgrids=true,
    enlargelimits=0.1,
    domain=1:3,
    samples=3,
    % every axis plot/.append style={
    %     ycomb,
    %     mark=*,
    %     line width=1pt,
    %     blue
    % }
]
\addplot+[] coordinates {(1,0.25) (2,0.5) (3,0.25)};
\end{axis}
\end{tikzpicture}
\end{center}

\subsection{Probability Density Function (PDF)}

The {Probability Density Function (PDF)} is used for \textbf{continuous random variables}. It is defined as a function $f_X$ such that the probability that a continuous random variable \( X \) lies within an interval \( [a, b] \) is given by the integral of $f_X$ over that interval:
\begin{textbox}
\[
P(a \leq X \leq b) = \int_a^b f_X(x) \, dx
\]
\end{textbox}
where \( f_X(x) \) is the PDF of \( X \). The PDF satisfies the following properties:

\begin{enumerate}
    \item \( f_X(x) \geq 0 \) for all \( x \)
    \item \( \int_{-\infty}^{\infty} f_X(x) \, dx = 1 \)
\end{enumerate}

\textbf{Example}: Consider a continuous random variable with the following distribution:
\[
f_X(x) = 
\begin{cases}
1, & 0 \leq x \leq 1 \\
0, & \text{otherwise}
\end{cases}
\]
The PDF can be visualised as follows:


\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=10cm,
    height=5cm,
    axis lines=left,
    xlabel={$x$},
    ylabel={$f_X(x)$},
    xtick={0, 1},
    ytick={0, 0.5, 1},
    xmin=-0.2, xmax=1.2,
    ymin=0, ymax=1.2,
    % grid=major,
    % ymajorgrids=true,
    enlargelimits=0.05
]

\addplot[
    blue,
    very thick
] coordinates {
    (-1,0)
    (0,0)
};
\addplot[
    blue,
    dotted
] coordinates {
    (0,0)
    (0,1)
};
\addplot[
    blue,
    very thick
] coordinates {
    (0,1)
    (1,1)
};
\addplot[
    blue,
    dotted
] coordinates {
    (1,1)
    (1,0)
};
\addplot[
    blue,
    very thick
] coordinates {
    (1,0)
    (2,0)
};
\end{axis}
\end{tikzpicture}
\end{center}

\subsection{Cumulative Distribution}

The cumulative distribution gives the probability that a random variable takes a value less than or equal to a specified value. Mathematically \textbf{Cumulative Distribution Function} (CDF) of a random variable \( X \) is defined as:
\begin{textbox}
    \[
F_X(x) = P(X \leq x)
\]
\end{textbox}
This function gives the probability that \( X \) takes a value less than or equal to \( x \).

\textbf{CDF for Discrete Random Variables}

For a discrete random variable \( X \), the CDF is given by the sum of the probabilities for all values less than or equal to \( x \). If \( X \) takes the values \( x_1, x_2, \dots, x_n \), the CDF is:
\begin{textbox}
\[
F_X(x) = \sum_{x_k \leq x} P(X = x_k)
\]
\end{textbox}
This sum includes all the probabilities up to and including \( x \).

\textbf{Example:} Consider the random variable \( X \) representing the outcome of a fair six-sided die roll. The CDF for \( X \) is:
\[
F_X(x) = 
\begin{cases} 
0, & \text{if } x < 1 \\
\frac{1}{6}, & \text{if } 1 \leq x < 2 \\
\frac{2}{6}, & \text{if } 2 \leq x < 3 \\
\frac{3}{6}, & \text{if } 3 \leq x < 4 \\
\frac{4}{6}, & \text{if } 4 \leq x < 5 \\
\frac{5}{6}, & \text{if } 5 \leq x < 6 \\
1, & \text{if } x \geq 6
\end{cases}
\]

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=10cm,
    height=5cm,
    axis lines=left,
    xlabel={$x$},
    ylabel={$F_X(x)$},
    xtick={0,1,2,3,4,5,6,7},
    ytick={0,1/6,2/6,3/6,4/6,5/6,1},
    xmin=0, xmax=7,
    ymin=0, ymax=1.1,
    % grid=major,
]

\addplot[
    blue,
    very thick
] coordinates {
    (0,0)
    (1,0)
};
\addplot[
    blue,
    dotted
] coordinates {
    (1,0)
    (1,1/6)
};
\addplot[
    blue,
    very thick
] coordinates {
    (1,1/6)
    (2,1/6)
};
\addplot[
    blue,
    dotted
] coordinates {
    (2,1/6)
    (2,2/6)
};
\addplot[
    blue,
    very thick
] coordinates {
    (2,2/6)
    (3,2/6)
};
\addplot[
    blue,
    dotted
] coordinates {
    (3,2/6)
    (3,3/6)
};
\addplot[
    blue,
    very thick
] coordinates {
    (3,3/6)
    (4,3/6)
};
\addplot[
    blue,
    dotted
] coordinates {
    (4,3/6)
    (4,4/6)
};
\addplot[
    blue,
    very thick
] coordinates {
    (4,4/6)
    (5,4/6)
};
\addplot[
    blue,
    dotted
] coordinates {
    (5,4/6)
    (5,5/6)
};
\addplot[
    blue,
    very thick
] coordinates {
    (5,5/6)
    (6,5/6)
};
\addplot[
    blue,
    dotted
] coordinates {
    (6,5/6)
    (6,1)
};
\addplot[
    blue,
    very thick
] coordinates {
    (6,1)
    (7,1)
};
\end{axis}
\end{tikzpicture}
\end{center}


\textbf{CDF for Continuous Random Variables}

For a continuous random variable \( X \), the CDF is obtained by integrating the probability density function (PDF) up to \( x \):
\begin{textbox}
\[
F_X(x) = \int_{-\infty}^{x} f_X(t) \, dt
\]
\end{textbox}
This represents the area under the PDF curve from \( -\infty \) to \( x \), giving the cumulative probability up to \( x \).

\textbf{Example:} Consider a continuous random variable \( X \) with a probability density function (PDF) \( f_X(x) = 1 \) for \( 0 \leq x \leq 1 \) (uniform distribution). The CDF is given by:
\[
F_X(x) =
\begin{cases}
0, & \text{if } x < 0 \\
x, & \text{if } 0 \leq x \leq 1 \\
1, & \text{if } x > 1
\end{cases}
\]
This is obtained by integrating the PDF:
\[
F_X(x) = \int_0^x 1 \,\cdot dt = x \quad \text{for} \quad 0 \leq x \leq 1
\]

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=10cm,
    height=5cm,
    axis lines=left,
    xlabel={$x$},
    ylabel={$F_X(x)$},
    xtick={-1, 0, 0.5, 1, 2},
    ytick={0, 0.5, 1},
    xmin=-1, xmax=2,
    ymin=0, ymax=1.2,
    domain=-1:2,
    samples=200
]

% F(x) = 0 for x < 0
\addplot[
    blue,
    very thick,
    domain=-1:0
] {0};

% F(x) = x for 0 ≤ x ≤ 1
\addplot[
    blue,
    very thick,
    domain=0:1
] {x};

% F(x) = 1 for x > 1
\addplot[
    blue,
    very thick,
    domain=1:2
] {1};

\end{axis}
\end{tikzpicture}
\end{center}

\textbf{Properties of the CDF}
\begin{enumerate}
    \item The CDF \( F_X(x) \) is a non-decreasing function, meaning:
   \[
   F_X(x_1) \leq F_X(x_2) \quad \text{for} \quad x_1 \leq x_2
   \]
    \item The CDF is bounded between 0 and 1:
   \[
   0 \leq F_X(x) \leq 1 \quad \text{for all } x
   \]
    \item The CDF approaches 1 as \( x \to \infty \) and 0 as \( x \to -\infty \):
   \[
   \lim_{x \to -\infty} F_X(x) = 0, \quad \lim_{x \to \infty} F_X(x) = 1
   \]
    \item For a continuous random variable, the CDF is continuous, while for a discrete random variable, the CDF has jumps at the values taken by the random variable.
    \item For continuous random variable, the derivative of the CDF gives the PDF (if the derivative exists): \[ f_X(x) = \frac{d}{dx}F_X(x) \]
\end{enumerate}

\section{Mean and Variance of a Random Variable}

The mean and variance are important measures that describe the central tendency and spread of a random variable, respectively.

\subsection{Mean of a Random Variable}

The \textbf{mean} or \textbf{expected value} of a random variable \( X \), denoted as \( \mathbb{E}(X) \), provides the long-run average of the outcomes of the random variable. It is defined as the weighted sum of all possible values of \( X \), weighted by their probabilities.
\begin{enumerate}

\item \textbf{Discrete Random Variable}: For a discrete random variable \( X \) with possible values \( x_1, x_2, \dots, x_n \) and corresponding probabilities \( p_X(x_1), p_X(x_2), \dots, p_X(x_n) \), the expected value (mean) is denoted by is given by:
\[
\mu=\mathbb{E}(X) = \sum_{i=1}^{n} x_i \cdot p_X(x_i)
\]

\textbf{Example:} Suppose \( X \) is the outcome of a roll of a fair die. The possible values of \( X \) are \( 1, 2, 3, 4, 5, 6 \), and each value has a probability of \( \frac{1}{6} \). The expected value is:
\[
\mathbb{E}(X) = \sum_{i=1}^{6} x_i \cdot \frac{1}{6} = \frac{1}{6} \cdot (1 + 2 + 3 + 4 + 5 + 6) = \frac{21}{6} = 3.5
\]

\item \textbf{Continuous Random Variable}: For a continuous random variable \( X \) with probability density function \( f_X(x) \), the expected value is given by the integral of \( x \) weighted by the probability density function:
\[
\mathbb{E}(X) = \int_{-\infty}^{\infty} x \cdot f_X(x) \, dx
\]
% This gives the mean or the center of the distribution of the continuous random variable.

\textbf{Example:} Suppose \( X \) is a continuous random variable with a uniform distribution between \( 0 \) and \( 1 \). The probability density function is:
\[
f_X(x) = 1 \quad \text{for } 0 \leq x \leq 1
\]
The expected value is:
\[
\mathbb{E}(X) = \int_0^1 x \cdot 1 \, dx = \left[ \frac{x^2}{2} \right]_0^1 = \frac{1}{2}
\]
\end{enumerate}

\begin{textbox}
\textbf{Theorem} If \( X = a \), where \( a \in \mathbb{R} \) is a constant, then  
\[
\mathbb{E}(X) = a
\]
\end{textbox}

\textbf{Proof.}  
Since \( X \) is always equal to \( a \),  
\begin{itemize}
  \item In the discrete case:
  \[
  \mathbb{E}(X) = \sum_{x} x \cdot P(X = x) = a \cdot P(X = a) = a
  \]
  \item In the continuous case:
  \[
  \mathbb{E}(X) = \int_{-\infty}^{\infty} x f_X(x) \, dx = \int_{-\infty}^{\infty} a \cdot \delta(x - a) \, dx = a
  \]
\end{itemize}
\hfill\(\blacksquare\)

\vspace{1em}

\begin{textbox}
\textbf{Theorem}: If \( Y = bX \), where \( b \in \mathbb{R} \), then  
\[
\mathbb{E}(Y) = b \cdot \mathbb{E}(X)
\]
\end{textbox}

\textbf{Proof.}  
\begin{itemize}
  \item Discrete case:
  \[
  \mathbb{E}(bX) = \sum_{x} b x \cdot P(X = x) = b \sum_{x} x \cdot P(X = x) = b \cdot \mathbb{E}(X)
  \]
  \item Continuous case:
  \[
  \mathbb{E}(bX) = \int_{-\infty}^{\infty} b x \cdot f_X(x) \, dx = b \int_{-\infty}^{\infty} x f_X(x) \, dx = b \cdot \mathbb{E}(X)
  \]
\end{itemize}
\hfill\(\blacksquare\)


\subsection{Variance of a Random Variable}

The \textbf{variance} of a random variable \( X \), denoted as $\sigma_X^2$ or \( \text{Var}(X) \), measures the spread or dispersion of the random variable around its mean. It is defined as the expected squared deviation from the mean:
\begin{align*}
\text{Var}(X) &= \mathbb{E}[(X - \mathbb{E}(X))^2] \\
&=\mathbb{E}\left[ X^2 - 2X\mathbb{E}(X) + (\mathbb{E}(X))^2\right]  \\
&=\mathbb{E}(X^2)- 2(\mathbb{E}(X)^2 + (\mathbb{E}(X))^2 \\
&= \mathbb{E}(X^2) - (\mathbb{E}(X))^2
\end{align*}

\begin{enumerate}

\item \textbf{Discrete Random Variable}: For a discrete random variable \( X \) with possible values \( x_1, x_2, \dots, x_n \) and corresponding probabilities \( p_X(x_1), p_X(x_2), \dots, p_X(x_n) \), the variance is given by:
\[
\text{Var}(X) = \sum_{i=1}^{n} (x_i - \mathbb{E}(X))^2 \cdot p_X(x_i)
\]
Alternatively, it can be computed as:
\[
\text{Var}(X) = \sum_{i=1}^{n} x_i^2 \cdot p_X(x_i) - (\mathbb{E}(X))^2
\]

\textbf{Example:} For the fair die roll example where \( \mathbb{E}(X) = 3.5 \), the variance is:
\[
\text{Var}(X) = \sum_{i=1}^{6} (x_i - 3.5)^2 \cdot \frac{1}{6} = \frac{1}{6} \left( (1-3.5)^2 + (2-3.5)^2 + \cdots + (6-3.5)^2 \right)
\]
\[
= \frac{1}{6} \cdot (6.25 + 2.25 + 0.25 + 0.25 + 2.25 + 6.25) = \frac{17.5}{6} \approx 2.92
\]

\item \textbf{Continuous Random Variable}: For a continuous random variable \( X \) with probability density function \( f_X(x) \), the variance is given by:
\[
\text{Var}(X) = \int_{-\infty}^{\infty} (x - \mathbb{E}(X))^2 \cdot f_X(x) \, dx
\]
Alternatively, it can be computed as:
\[
\text{Var}(X) = \int_{-\infty}^{\infty} x^2 \cdot f_X(x) \, dx - (\mathbb{E}(X))^2
\]

\textbf{Example:} For the continuous uniform random variable \( X \) between 0 and 1, $\mathbb{E}(X) = \frac{1}{2}$, the variance is:
\[
\text{Var}(X) = \int_0^1 x^2 \cdot 1 \, dx - \left(\frac{1}{2}\right)^2 = \left[ \frac{x^3}{3} \right]_0^1 - \frac{1}{4} = \frac{1}{3} - \frac{1}{4} = \frac{1}{12}
\]
\end{enumerate}

\begin{textbox}
\textbf{Theorem}: If \( X = a \), where \( a \in \mathbb{R} \) is constant, then  
\[
\mathrm{Var}(X) = 0
\]
\end{textbox}

\textbf{Proof.}  
\[
\mathrm{Var}(X) = \mathbb{E}[(X - \mathbb{E}(X))^2] = \mathbb{E}[(a - a)^2] = \mathbb{E}[0] = 0
\]
\hfill\(\blacksquare\)

\vspace{1em}

\begin{textbox}
\textbf{Theorem}: If \( Y = bX \), where \( b \in \mathbb{R} \), then  
\[
\mathrm{Var}(Y) = b^2 \cdot \mathrm{Var}(X)
\]
\end{textbox}

\textbf{Proof.}  
\begin{align*}
    \mathrm{Var}(Y) &= \mathrm{Var}(bX) = \mathbb{E}[(bX - \mathbb{E}(bX))^2]\\
&= \mathbb{E}[(bX - b\mathbb{E}(X))^2]
= \mathbb{E}[b^2 (X - \mathbb{E}(X))^2]\\
&= b^2 \cdot \mathrm{Var}(X)
\end{align*}
\hfill\(\blacksquare\)


\section{Joint Distribution of Two random Variables}
Let \( X \) and \( Y \) be two random variables defined on the same probability space. The joint distribution of \( X \) and \( Y \) describes the probability behavior of the pair \( (X, Y) \). It can be either discrete or continuous depending on the nature of \( X \) and \( Y \).

\begin{itemize}

\item \textbf{Discrete Case}:

If \( X \) and \( Y \) are discrete random variables, then their joint distribution is defined by the \textbf{joint probability mass function (PMF)}:
\[
p_{X,Y}(x, y) = P(X = x, Y = y)
\]
which gives the probability that \( X = x \) and \( Y = y \) simultaneously.

The PMF must satisfy:
\begin{itemize}
  \item \( p_{X,Y}(x, y) \geq 0 \) for all \( x, y \)
  \item \( \sum_{x} \sum_{y} p_{X,Y}(x, y) = 1 \)
\end{itemize}

The \textbf{marginal distributions} can be obtained by summing out the other variable:
\[
p_X(x) = \sum_{y} p_{X,Y}(x, y), \qquad
p_Y(y) = \sum_{x} p_{X,Y}(x, y)
\]
The value of $p_X(x)$ gives the probability $P(X=x)$ irrespective of $Y$. Similarly, $p_Y(y)$ gives the probability $P(Y=y)$ irrespective of $X$.

Suppose the possible values of $X$ are $x_1, x_2, \dots, x_m$ and possible values of $Y$ are $y_1, y_2, \dots, y_n$. The joint distribution can be depicted in a table format as shown Table \ref{table:joint_distribution}.

\vspace{3mm}
\begin{table}[h!]
\centering
\renewcommand{\arraystretch}{1.5}  % Increases row height
\setlength{\tabcolsep}{10pt}       % Increases column width
\begin{tabular}{c|*{4}{c}|c}
\hline
\textbf{Y \textbackslash X} & \(x_1\) & \(x_2\) & \(\cdots\) & \(x_m\) & \(p_Y(y_j)\) \\
\hline
\(y_1\)     & \(p_{X,Y}({x_1, y_1})\) & \(p_{X,Y}({x_2, y_1})\) & \(\cdots\) & \(p_{X,Y}({x_m, y_1})\) & \(p_Y({y_1})\) \\
\(y_2\)     & \(p_{X,Y}({x_1, y_2})\) & \(p_{X,Y}({x_2, y_2})\) & \(\cdots\) & \(p_{X,Y}({x_m, y_2})\) & \(p_Y({y_2})\) \\
\(\vdots\)  & \(\vdots\) & \(\vdots\) & \(\ddots\) & \(\vdots\) & \(\vdots\)     \\
\(y_n\)     & \(p_{X,Y}({x_1, y_n})\) & \(p_{X,Y}({x_2, y_n})\) & \(\cdots\) & \(p_{X,Y}({x_n, y_m})\) & \(p_Y({y_n})\) \\
\hline
\(p_X(x_i)\) & \(p_X({x_1})\) & \(p_X({x_2})\) & \(\cdots\) & \(p_X({x_m})\) & 1 \\
\hline
\end{tabular}
\caption{\textit{Joint probability distribution of discrete random variables \(X\) and \(Y\).}}
\label{table:joint_distribution}
\end{table}

The \textbf{joint cumulative probability distribution function (CDF)} can be obtained from joint probability mass function:
\[
F_{X,Y}(x, y) = P(X \leq x, Y \leq y) = \sum_{x_i \leq x} \sum_{y_j \leq y} p_{X,Y}(x_i, y_j)
\]

It sums over all values $(x_i,y_j)$ such that $x_i \leq x$ and $y_j \leq y$. This gives the total probability that the random pair \( (X, Y) \) falls within the region \( X \leq x, Y \leq y \).

\item \textbf{Continuous Case}:

If \( X \) and \( Y \) are continuous random variables, then their joint distribution is described by the \textbf{joint probability density function}:
\[
f_{X,Y}(x, y)
\]
which satisfies:
\[
P((X, Y) \in A) = \iint_{A} f_{X,Y}(x, y) \, dx \, dy,
\]
for any region \( A \subset \mathbb{R}^2 \).

The joint PDF must satisfy:
\begin{itemize}
  \item \( f_{X,Y}(x, y) \geq 0 \) for all \( x, y \)
  \item \( \iint_{\mathbb{R}^2} f_{X,Y}(x, y) \, dx \, dy = 1 \)
\end{itemize}

The \textbf{marginal PDFs} are obtained by integrating out the other variable:
\[
f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x, y) \, dy, \qquad
f_Y(y) = \int_{-\infty}^{\infty} f_{X,Y}(x, y) \, dx
\]

The term $f_X(x)$ gives the PDF of $X$ irrespective of $Y$. Similarly, $f_Y(y)$ gives the PDF of $Y$ irrespective of $X$.

The \textbf{joint cumulative distribution function (CDF)} is defined as:

\[
F_{X,Y}(x, y) = P(X \leq x, Y \leq y) = \int_{-\infty}^{x} \int_{-\infty}^{y} f_{X,Y}(u, v) \, dv \, du
\]

This function gives the probability that the random vector \( (X, Y) \) falls within the region defined by \( X \leq x, Y \leq y \).
\end{itemize}

\begin{textbox}
\textbf{Theorem}: If \( Z = X + Y \), then  
\[
\mathbb{E}(Z) = \mathbb{E}(X) + \mathbb{E}(Y)
\]
\end{textbox}

\textbf{Proof.}  
\begin{itemize}
  \item Discrete case:
  \begin{align*}
  \mathbb{E}(X + Y) &= \sum_{x, y} (x + y) \cdot p_{X,Y}(x,y)\\
  &= \sum_{x, y} x \cdot p_{X,Y}(x,y) + \sum_{x, y} y \cdot p_{X,Y}(x,y)\\
  &= \sum_{x} x \cdot p_X(x) + \sum_{y} y \cdot p_Y(y)\\
  &= \mathbb{E}(X) + \mathbb{E}(Y)
  \end{align*}

  \item Continuous case:
  \begin{align*}
    \mathbb{E}(X + Y) &= \int_{\infty}^{\infty}\int_{\infty}^{\infty} (x + y) f_{X,Y}(x, y) \, dx \, dy \\
  &= \int_{\infty}^{\infty}\int_{\infty}^{\infty} x f_{X,Y}(x, y) \, dx \, dy + \int_{\infty}^{\infty}\int_{\infty}^{\infty} y f_{X,Y}(x, y) \, dx \, dy \\
  &= \int_{\infty}^{\infty} x f_X(x) \, dx + \int_{\infty}^{\infty} y f_Y(y) \, dy = \mathbb{E}(X) + \mathbb{E}(Y)
  \end{align*}
\end{itemize}
\hfill\(\blacksquare\)

\subsection{Independence of Two Random Variables}

Two random variables \( X \) and \( Y \) are \textbf{independent} if and only if:
\begin{itemize}
  \item In the discrete case: $$p_{X,Y}(x, y) = p_X(x) \cdot p_Y(y) \text{ for all } ( x, y )$$
  \item In the continuous case: $$f_{X,Y}(x, y) = f_X(x) \cdot f_Y(y) \text{ for all } ( x, y )$$
\end{itemize}

\begin{textbox}
\textbf{Theorem}: If \( X \) and \( Y \) are independent random variables, then
\[
\mathbb{E}(XY) = \mathbb{E}(X) \cdot \mathbb{E}(Y)
\]
\end{textbox}

\textbf{Proof}:

\begin{itemize}

\item{Discrete Case}:

\begin{align*}
    \mathbb{E}(XY) &= \sum_{x} \sum_{y} xy \cdot p_{X,Y}(x, y)\\
    &=\sum_{x} \sum_{y} xy \cdot p_{X}(x)\cdot p_{Y}(y)\\
    &= \sum_{x} x p_X(x) \cdot  \sum_{y} y p_Y(y) \\
    &= \mathbb{E}(X) \cdot \mathbb{E}(Y)
\end{align*}

\item{Continuous Case}:

\begin{align*}
    \mathbb{E}(XY) &= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} xy \cdot f_{X,Y}(x, y) \, dy \, dx\\
    &= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} xy \cdot f_X(x)\cdot f_Y(y) \, dy \, dx\\
    &= \int_{-\infty}^{\infty} x f_X(x) \, dx\cdot  \int_{-\infty}^{\infty} y f_Y(y) \, dy \\
    &= \mathbb{E}(X) \cdot \mathbb{E}(Y)
\end{align*}

\end{itemize}
\vspace{1em}


\subsection{Covariance of Two Random Variables}

One important feature of the joint distribution of $X$ and $Y$ is their covariance, which is used to measure the degree of association between $X$ and $Y$. The \textbf{covariance} of two random variables \( X \) and \( Y \), denoted by \( \mathrm{Cov}(X, Y) \) is defined as:
\begin{textbox}
    \[
\mathrm{Cov}(X, Y) = \mathbb{E}\big[(X - \mathbb{E}(X))\cdot (Y - \mathbb{E}(Y))\big]
\]
\end{textbox}

Now, 
\begin{align*}
\mathrm{Cov}(X, Y) 
&= \mathbb{E}\big[(X - \mathbb{E}(X))\cdot(Y - \mathbb{E}(Y))\big] \\
&= \mathbb{E}\big[XY - X\cdot \mathbb{E}(Y) - \mathbb{E}(X)\cdot Y + \mathbb{E}(X)\cdot \mathbb{E}(Y)\big] \\
&= \mathbb{E}(XY) - \mathbb{E}(X)\cdot \mathbb{E}(Y) - \mathbb{E}(X)\cdot \mathbb{E}(Y) + \mathbb{E}(X)\cdot \mathbb{E}(Y) \\
&= \mathbb{E}(XY) - \mathbb{E}(X)\cdot \mathbb{E}(Y)
\end{align*}

Thus we get an alternative shortcut formula for covariance:

\begin{textbox}
\[
\mathrm{Cov}(X, Y) = \mathbb{E}(XY) - \mathbb{E}(X) \cdot \mathbb{E}(Y)
\]
\end{textbox}

\textbf{Interpretation}:

\begin{itemize}
  \item \( \mathrm{Cov}(X, Y) > 0 \): \( X \) and \( Y \) tend to increase (or decrease) together.
  \item \( \mathrm{Cov}(X, Y) < 0 \): \( X \) increases as \( Y \) decreases (or vice versa).
  \item \( \mathrm{Cov}(X, Y) = 0 \): No linear relationship between \( X \) and \( Y \).
\end{itemize}

\begin{textbox}
\textbf{Theorem}: If $X$ and $Y$ are random variables, then
\[
\operatorname{Cov}(X, Y) = \operatorname{Cov}(Y, X)
\]
\end{textbox}


\textbf{Proof}: By definition of covariance,
\begin{align*}
\operatorname{Cov}(X, Y) &= \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])]
\end{align*}

Using the commutative property of multiplication,
\begin{align*}
(X - \mathbb{E}[X])(Y - \mathbb{E}[Y]) &= (Y - \mathbb{E}[Y])(X - \mathbb{E}[X])
\end{align*}

Therefore,
\begin{align*}
\operatorname{Cov}(X, Y) &= \mathbb{E}[(Y - \mathbb{E}[Y])(X - \mathbb{E}[X])] = \operatorname{Cov}(Y, X)
\end{align*}

\hfill $\blacksquare$

\begin{textbox}
\textbf{Theorem}: If \( X \) and \( Y \) are independent random variables, then  
\[
\mathrm{Cov}(X, Y) = 0
\] 
\end{textbox}

\textbf{Proof}: If $X$ and $Y$ are are independent, then
$$\mathbb{E}(XY) = \mathbb{E}(X)\cdot \mathbb{E}(Y)$$
Thus, 
\begin{align*}
\mathrm{Cov}(X, Y) &= \mathbb{E}(XY) - \mathbb{E}(X) \cdot \mathbb{E}(Y)\\
&=\mathbb{E}(X) \cdot \mathbb{E}(Y) - \mathbb{E}(X) \cdot \mathbb{E}(Y)\\
&=0
\end{align*}
\hfill\(\blacksquare\)

\textbf{Note}: The converse is not necessarily true. Two random variables may have \( \mathrm{Cov}(X, Y) = 0 \) and yet not be independent.

\begin{textbox}
\textbf{Theorem}: For any random variable \( X \),
\[
\mathrm{Cov}(X, X) = \mathrm{Var}(X)
\]
\end{textbox}

\textbf{Proof}: 
\begin{align*}
\mathrm{Cov}(X, X) &= \mathbb{E}(X \cdot X) - \mathbb{E}(X)\cdot \mathbb{E}(X) \\
&= \mathbb{E}(X^2) - (\mathbb{E}(X))^2 \\
&= \mathrm{Var}(X)
\end{align*}
\hfill\(\blacksquare\)

\begin{textbox}
\textbf{Theorem}: Let \( a, b \in \mathbb{R} \) are constants. Then for any random variables \( X \) and \( Y \),
\[
\mathrm{Cov}(aX, bY) = ab \cdot \mathrm{Cov}(X, Y)
\]
\end{textbox}

\textbf{Proof.}  
\begin{align*}
\mathrm{Cov}(aX, bY) &= \mathbb{E}(aX \cdot bY) - \mathbb{E}(aX)\cdot \mathbb{E}(bY) \\
&= ab \cdot \mathbb{E}(XY) - ab \cdot \mathbb{E}(X)\cdot \mathbb{E}(Y) \\
&= ab \cdot \left( \mathbb{E}(XY) - \mathbb{E}(X)\cdot \mathbb{E}(Y) \right) \\
&= ab \cdot \mathrm{Cov}(X, Y)
\end{align*}
\hfill\(\blacksquare\)

\begin{textbox}
\textbf{Theorem}: If $X$, $Y$ are two random variables, then  
\[
\mathrm{Var}(X+Y) = \mathrm{Var}(X) + \mathrm{Var}(Y) + 2 \cdot \mathrm{Cov}(X, Y)
\]
\end{textbox}

\textbf{Proof.}  
\[
\mathrm{Var}(X + Y) = \mathbb{E}[(X + Y - \mathbb{E}(X + Y))^2]
\]
By linearity of expectation, \( \mathbb{E}(X + Y) = \mathbb{E}(X) + \mathbb{E}(Y) \), so:
\[
= \mathbb{E}[(X - \mathbb{E}(X) + Y - \mathbb{E}(Y))^2]
\]
Expanding the square:
\[
= \mathbb{E}[(X - \mathbb{E}(X))^2 + (Y - \mathbb{E}(Y))^2 + 2(X - \mathbb{E}(X))(Y - \mathbb{E}(Y))]
\]
Using linearity of expectation:
\[
= \mathbb{E}[(X - \mathbb{E}(X))^2] + \mathbb{E}[(Y - \mathbb{E}(Y))^2] + 2 \cdot \mathbb{E}[(X - \mathbb{E}(X))(Y - \mathbb{E}(Y))]
\]
\[
= \mathrm{Var}(X) + \mathrm{Var}(Y) + 2 \cdot \mathrm{Cov}(X, Y)
\]
\hfill\(\blacksquare\)

\begin{textbox}
\textbf{Theorem}: For random variables $X_1, X_2, \dots, X_n$,
$$\mathrm{Var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \mathrm{Var}(X_i) + 2 \sum_{1 \leq i < j \leq n} \mathrm{Cov}(X_i, X_j)$$
\end{textbox}

\textbf{Proof}: Start with the definition of variance:
\[
\mathrm{Var}(Y) = \mathbb{E}\left[(Y - \mathbb{E}[Y])^2\right]
\]
Let
\[
Y = \sum_{i=1}^n X_i
\]
Then
\[
\mathrm{Var}\left(\sum_{i=1}^n X_i\right) = \mathbb{E}\left[\left(\sum_{i=1}^n X_i - \mathbb{E}\left[\sum_{i=1}^n X_i\right]\right)^2\right]
\]

Since expectation is linear,
\[
\mathbb{E}\left[\sum_{i=1}^n X_i\right] = \sum_{i=1}^n \mathbb{E}[X_i]
\]
So,
\[
\mathrm{Var}\left(\sum_{i=1}^n X_i\right) = \mathbb{E}\left[\left(\sum_{i=1}^n (X_i - \mathbb{E}[X_i])\right)^2\right]
\]

Expanding the square,
\[
= \mathbb{E}\left[ \sum_{i=1}^n (X_i - \mathbb{E}[X_i]) \sum_{j=1}^n (X_j - \mathbb{E}[X_j]) \right]
= \mathbb{E}\left[ \sum_{i=1}^n \sum_{j=1}^n (X_i - \mathbb{E}[X_i])(X_j - \mathbb{E}[X_j]) \right]
\]

By linearity of expectation,
\[
= \sum_{i=1}^n \sum_{j=1}^n \mathbb{E}\left[(X_i - \mathbb{E}[X_i])(X_j - \mathbb{E}[X_j])\right]
\]

Recall the definition of covariance:
\[
\mathrm{Cov}(X_i, X_j) = \mathbb{E}[(X_i - \mathbb{E}[X_i])(X_j - \mathbb{E}[X_j])]
\]

Thus,
\[
\mathrm{Var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \sum_{j=1}^n \mathrm{Cov}(X_i, X_j)
\]

Split the double sum into terms where \( i = j \) and \( i \neq j \):
\[
= \sum_{i=1}^n \mathrm{Var}(X_i) + \sum_{i=1}^n \sum_{\substack{j=1 \\ j \neq i}}^n \mathrm{Cov}(X_i, X_j).
\]

Since the covariance terms are symmetric, the sum over \( i \neq j \) counts each pair twice, so
\[
\sum_{i=1}^n \sum_{\substack{j=1 \\ j \neq i}}^n \mathrm{Cov}(X_i, X_j) = 2 \sum_{1 \leq i < j \leq n} \mathrm{Cov}(X_i, X_j)
\]

Hence,
\[
\mathrm{Var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \mathrm{Var}(X_i) + 2 \sum_{1 \leq i < j \leq n} \mathrm{Cov}(X_i, X_j).
\]

\hfill $\blacksquare$

\section{Conditional Probability Distribution}

When working with two random variables \( X \) and \( Y \), it is often important to understand the distribution and expected value of one variable given the other. This is captured by \textbf{conditional probability distributions}.

\subsection{Conditional Probability Mass Function}

If \( X \) and \( Y \) are discrete random variables with joint PMF \( p_{X,Y}(x, y) \), the conditional PMF of \( Y \) given \( X = x \) is:
    \[
    p_{Y\mid X}(y\mid x) = P(Y = y \mid X = x) = \frac{p_{X,Y}(x, y)}{p_X(x)}, \quad \text{for } p_X(x) > 0
    \]

If \( X \) and \( Y \) are \textbf{independent}, then the joint PMF factorizes as:
\[
p_{X,Y}(x, y) = p_X(x) \cdot p_Y(y)
\]
and the conditional PMF reduces to the marginal PMF of \( Y \):
\[
p_{Y\mid X}(y\mid x) = p_Y(y)
\]
In other words, knowing \( X = x \) does not change the probability distribution of \( Y \).

\subsection{Conditional Probability Density Function}

If \( X \) and \( Y \) are continuous random variables with joint PDF \( f_{X,Y}(x,y) \), the conditional PDF of \( Y \) given \( X = x \) is:
    \[
    f_{Y|X}(y|x) = \frac{f_{X,Y}(x,y)}{f_X(x)}, \quad \text{for } f_X(x) > 0
    \]

If \( X \) and \( Y \) are \textbf{independent}, then the joint PDF factorizes as:
\[
f_{X,Y}(x,y) = f_X(x) \cdot f_Y(y)
\]
and the conditional PDF reduces to the marginal PDF of \( Y \):
\[
f_{Y|X}(y|x) = f_Y(y)
\]
Thus, knowing \( X = x \) does not affect the distribution of \( Y \).


\subsection{Conditional Expectation}

The \textbf{conditional expectation} of \( Y \) given \( X = x \), denoted \( \mathbb{E}[Y \mid X = x] \), is the expected value of \( Y \) calculated using the conditional distribution of \( Y \) given \( X = x \). It provides the average or mean value of \( Y \) when \( X \) is known.

\begin{itemize}
    \item \textbf{Discrete case:}
    \[
    \mathbb{E}[Y \mid X = x] = \sum_y y \cdot P(Y = y \mid X = x)
    \]

    \item \textbf{Continuous case:}
    \[
    \mathbb{E}[Y \mid X = x] = \int_{-\infty}^{\infty} y \cdot f_{Y|X}(y|x) \, dy
    \]
\end{itemize}

The conditional expectation is a function of \( x \) and can be viewed as the ``best guess'' of \( Y \) given the value of \( X \).

\begin{textbox}
\textbf{Law of Total Expectation}: Let \(X\) and \(Y\) be random variables (discrete or continuous). Then
\[
\mathbb{E}[X] = \mathbb{E}\big[\mathbb{E}[X \mid Y]\big]
\]
\end{textbox}
This means that the overall expectation of \(X\) can be obtained by first computing the conditional expectation of \(X\) given \(Y\), and then taking the expectation of that conditional expectation over the distribution of \(Y\).

\textbf{Proof}:

\begin{itemize}
    \item \textbf{Discrete case}: Assume \(X\) and \(Y\) are discrete random variables with joint PMF \(p_{X,Y}(x,y)\):

\begin{align*}
\mathbb{E}[X] &= \sum_x x \, p_X(x) = \sum_x x \sum_y p_{X,Y}(x,y) \\
&= \sum_y \sum_x x \, p_{X,Y}(x,y) = \sum_y \left( \sum_x x \, p_{X|Y}(x|y) \right) p_Y(y) \\
&= \sum_y \mathbb{E}[X \mid Y = y] \, p_Y(y) = \mathbb{E}\big[\mathbb{E}[X \mid Y]\big]
\end{align*}
    \item \textbf{Continuous case}: If \(X, Y\) are continuous with joint PDF \(f_{X,Y}(x,y)\):

\begin{align*}
\mathbb{E}[X] &= \int_{-\infty}^{\infty} x \, f_X(x) \, dx = \int_{-\infty}^{\infty} x \int_{-\infty}^{\infty} f_{X,Y}(x,y) \, dy \, dx \\
&= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x \, f_{X|Y}(x|y) f_Y(y) \, dx \, dy \\
&= \int_{-\infty}^{\infty} \left( \int_{-\infty}^{\infty} x \, f_{X|Y}(x|y) \, dx \right) f_Y(y) \, dy \\
&= \int_{-\infty}^{\infty} \mathbb{E}[X \mid Y = y] \, f_Y(y) \, dy = \mathbb{E}\big[\mathbb{E}[X \mid Y]\big]
\end{align*}
\end{itemize}
\hfill $\blacksquare$

\textbf{Example}: Suppose two factories supply light bulbs to the market.

\begin{itemize}
    \item Factory \( X \) produces bulbs that last on average \( 5500 \) hours.
    \item Factory \( Y \) produces bulbs that last on average \( 4200 \) hours.
    \item Factory \( X \) supplies 70\% of all bulbs, and factory \( Y \) supplies 30\%.
\end{itemize}

What is the expected lifetime of a randomly chosen bulb?

Let the random variable \( L \) denote the lifetime of a randomly chosen bulb. Let \( F \in \{X, Y\} \) be the factory that produced the bulb. 

We are asked to find the expected lifetime \( \mathbb{E}[L] \).

Given,

$$\mathbb{E}[L \mid F = X] = 2000$$
$$\mathbb{E}[L \mid F = Y] = 3000$$
$$P(F=X) = \dfrac{70}{100} = 0.7$$
$$P(F=X) = \dfrac{30}{100} = 0.3$$

Using the \textbf{Law of Total Expectation}:
\[
\mathbb{E}[L] = \mathbb{E}[\mathbb{E}[L \mid F]]
\]

We compute:
\begin{align*}
\mathbb{E}[L] 
&= P(F = X) \cdot \mathbb{E}[L \mid F = X] + P(F = Y) \cdot \mathbb{E}[L \mid F = Y] \\
&= 0.7 \times 2000 + 0.3 \times 3000 \\
&= 1400 + 900 = 2300
\end{align*}

So, the expected lifetime of a randomly chosen bulb is $2300$ hours.

% \vspace{3mm}
% \textbf{Example}: Let \(Y\) be a continuous random variable with PDF \(f_Y(y)\) uniform on \([0,1]\), and given \(Y=y\), let \(X\) be uniformly distributed on \([0, y]\).

% Find \(\mathbb{E}[X]\).

% \emph{Solution:}

% First, find the conditional expectation:
% \[
% \mathbb{E}[X \mid Y=y] = \frac{0 + y}{2} = \frac{y}{2}
% \]

% Since \(Y \sim \text{Uniform}(0,1)\), its PDF is \(f_Y(y) = 1\) for \(0 \leq y \leq 1\).

% Using the law of total expectation:
% \[
% \mathbb{E}[X] = \mathbb{E}\big[\mathbb{E}[X \mid Y]\big] = \int_0^1 \frac{y}{2} \cdot 1 \, dy = \frac{1}{2} \int_0^1 y \, dy = \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4}
% \]

% Thus, the expected value of \(X\) is \(\frac{1}{4}\).


\section{Functions of a Random Variable}

In many practical scenarios, we are interested not just in a random variable $X$, but in some transformation or {function} of $X$, such as $Y = g(X)$. $Y$ is also a random variable. Understanding how the distribution of $X$ affects the distribution of $Y$ is a key part of probability theory.

\subsection{Discrete Case}

If $X$ is a discrete random variable with known probability mass function (PMF) $p_X(x) = P(X=x)$, and $Y = g(X)$, then the PMF of $Y$ is computed as:

\begin{textbox}
\[
p_Y(y) = P(Y = y) = \sum_{\{x \,\mid \, g(x) = y\}} p_X(x)
\]
\end{textbox}

That is, for each possible value $y$ of $Y$, sum the probabilities of all values $x$ of $X$ that are mapped to $y$ by the function $g$. This summation holds for any function $g$: whether it is one-to-one or many-to-one.

\vspace{2mm}

\textbf{Example:} Let $X$ be the outcome of a fair six-sided die, so $X \in \{1, 2, 3, 4, 5, 6\}$ with $P(X = x) = \frac{1}{6}$. Let $Y = X \bmod 2$ (i.e., $Y$ is the parity of $X$).

Then $Y$ takes values in $\{0, 1\}$, where:
\[
f_Y(0) = P(Y = 0) = P(X \in \{2, 4, 6\}) = \frac{3}{6} = 0.5
\]
\[
f_Y(1) = P(Y = 1) = P(X \in \{1, 3, 5\}) = \frac{3}{6} = 0.5
\]

\subsection{Continuous Case}

If $X$ is a continuous random variable with probability density function (PDF) $f_X(x)$, and $Y = g(X)$ is a function of $X$, then the PDF of $Y$ depends on whether $g$ is monotonic\footnote{A function $g(x)$ is called \textbf{monotonic} if it never ``switches direction'' as $x$ moves along its domain. In plain english it is either strictly increasing or strictly decreasing function. If $g$ is strictly increasing or decreasing, then it’s \textbf{one-to-one and onto}, so there is a well-defined inverse function $g^{-1}$  that `undoes' g i.e.
  $$g^{-1}(g(x)) = x$$} or not.

\subsubsection*{Monotonic Transformation}

\begin{textbox}
\textbf{Theorem}: If $g$ is a strictly monotonic and differentiable function, and $Y = g(X)$, then the PDF of $Y$ is:
\[
f_Y(y) = f_X\big(g^{-1}(y)\big) \cdot \left| \frac{d}{dy}g^{-1}(y) \right|
\]
\end{textbox}

Or equivalently:

\begin{textbox}
\textbf{Theorem.} If $g$ is a strictly monotonic and differentiable function, and $Y = g(X)$, then the CDF of $Y$ given by:

\begin{itemize}
  \item If \( g \) is strictly increasing, then
  \[
  F_Y(y) = F_X\left(g^{-1}(y)\right)
  \]
  
  \item If \( g \) is strictly decreasing, then
  \[
  F_Y(y) = 1 - F_X\left(g^{-1}(y)\right)
  \]
\end{itemize}
\end{textbox}

This formula ensures that the total probability is preserved under the transformation.

\textbf{Proof}: We treat separately the cases when $g$ is strictly increasing and strictly decreasing.

\begin{itemize}
\item  \textbf{Case 1: $g$ is strictly increasing.}

    Since $g$ is strictly increasing, it has a well-defined inverse
    \[
      x = g^{-1}(y)
    \]

    Let $F_X(x)$ and $F_Y(y)$ be the CDFs of $X$ and $Y$.  Then
    \[
      F_Y(y)
      = P\bigl(Y \le y\bigr)
      = P\bigl(g(X)\le y\bigr)
    \]
    Because $g$ is increasing, 
    \[
      g(X)\le y 
      \quad\Longleftrightarrow\quad
      X \le g^{-1}(y)
    \]
    Hence
    \[
      F_Y(y)
      = P\bigl(X \le g^{-1}(y)\bigr)
      = F_X\bigl(g^{-1}(y)\bigr)
    \]
  Now differentiate both sides using the chain rule:,
    \[
      f_Y(y)
      = \frac{d}{dy}F_Y(y)
      = \frac{d}{dy}\;F_X\bigl(g^{-1}(y)\bigr)
      = f_X\bigl(g^{-1}(y)\bigr)\;\frac{d}{dy}\,g^{-1}(y)
    \]
    Since $g^{-1}$ is increasing, its derivative is positive i.e. $\dfrac{d}{dy}\,g^{-1}(y) > 0$, and so
    \[
      f_Y(y) 
      = f_X\bigl(g^{-1}(y)\bigr)\;\Bigl|\tfrac{d}{dy}\,g^{-1}(y)\Bigr|
    \]


\medskip
\item \textbf{Case 2: $g$ is strictly decreasing.}

 
    Again $g^{-1}$ exists, but now $g^{-1}$ is decreasing.
    For a decreasing $g$,
    \[
      g(X)\le y 
      \quad\Longleftrightarrow\quad
      X \ge g^{-1}(y)
    \]
    Thus
    \[
      F_Y(y)
      = P\bigl(Y \le y\bigr)
      = P\bigl(X \ge g^{-1}(y)\bigr)
      = 1 - P\bigl(X < g^{-1}(y)\bigr)
      = 1 - F_X\bigl(g^{-1}(y)\bigr)
    \]
  Differentiate to get the PDF:
    \[
      f_Y(y)
      = \frac{d}{dy}F_Y(y)
      = \frac{d}{dy}\Bigl[\,1 - F_X\bigl(g^{-1}(y)\bigr)\Bigr]
      = -f_X\bigl(g^{-1}(y)\bigr)\;\frac{d}{dy}\,g^{-1}(y)
    \]
    Since $g^{-1}$ is decreasing, $\tfrac{d}{dy}\,g^{-1}(y)<0$, so the two negatives cancel:
    \[
      f_Y(y)
      = f_X\bigl(g^{-1}(y)\bigr)\;\Bigl|\tfrac{d}{dy}\,g^{-1}(y)\Bigr|
    \]
\end{itemize}
\medskip
\noindent In both cases we arrive at the same formula:
\[
  f_Y(y)
  = f_X\bigl(g^{-1}(y)\bigr)\;\Bigl|\tfrac{d}{dy}\,g^{-1}(y)\Bigr|
\]
\hfill\(\blacksquare\)

\vspace{2mm}

\textbf{Example:} Let $X$ has the following PDF:
\[
f_X(x) =
\begin{cases}
1, & 0 \le x \le 1 \\
0, & \text{otherwise}
\end{cases}
\]
and define $Y = -\log(X)$.

To calculate the PDF of $Y$, note that $g(x) = -\log(x)$ is strictly decreasing on $(0,1)$. The inverse function is $$g^{-1}(y) = e^{-y}$$
The absolute value of the derivative is:
\[
\left| \frac{d}{dy} e^{-y} \right| = e^{-y}
\]

The PDF of $X$ is $f_X(x) = 1$ for $x \in (0,1)$, so:
\[
f_Y(y) = f_X(e^{-y}) \cdot e^{-y} = 1 \cdot e^{-y} = e^{-y}, \quad y > 0
\]

\subsubsection*{Non-Monotonic Transformation}

If $g$ is not monotonic, the formula for $f_Y(y)$ generalizes to:
\begin{textbox}
\[
f_Y(y) = \sum_{x \in g^{-1}(y)} \frac{f_X(x)}{\left| g'(x) \right|}
\]
\end{textbox}

Here, the sum runs over all $x$ values such that $g(x) = y$ (as $g$ can be a many-to-one function such that multiple values of $x$ can be mapped to same $y$). The proof is omitted as it is beyond the scope of this text.

\vspace{2mm}

\textbf{Example:} Let the random variable $X$ follows a standard normal distribution\footnote{The discussion on standard normal distribution will be coming in a later section.} i.e. $X \sim \mathcal{N}(0,1)$ and define $Y = X^2$. The function $g(x) = x^2$ is not one-to-one, but has two inverse branches: $x = \sqrt{y}$ and $x = -\sqrt{y}$.

Then:
\[
f_Y(y) = \frac{1}{\sqrt{2\pi}} \left( \frac{1}{\sqrt{y}} \exp\left( -\frac{y}{2} \right) + \frac{1}{\sqrt{y}} \exp\left( -\frac{y}{2} \right) \right) = \frac{1}{\sqrt{2\pi y}} \exp\left( -\frac{y}{2} \right), \quad y > 0
\]

This is the PDF of a chi-squared distribution with 1 degree of freedom.

\section{Standardized Random Variable}

Let \(X\) be a random variable with mean \(\mu = \mathbb{E}(X)\) and variance \(\sigma^2 = \mathrm{Var}(X)\), where $\sigma = \sqrt{\mathrm{Var}(X)}$ must satisfy \(\sigma > 0\). The \textbf{standardized random variable} \(X^*\) is defined by
\[
  X^* \;=\; \frac{X - \mu}{\sigma}
\]

By construction, \(X^*\) has
\[
  \text{Mean} = \mathbb{E}[X^*]
  = \mathbb{E}\!\biggl[\frac{X - \mu}{\sigma}\biggr]
  = \frac{\mathbb{E}(X) - \mu}{\sigma}
  = 0,
\]
and
\[
  \text{Variance} = \mathrm{Var}(X^*)
  = \mathrm{Var}\!\biggl(\frac{X - \mu}{\sigma}\biggr)
  = \frac{1}{\sigma^2}\,\mathrm{Var}(X)
  = 1
\]

\section{Chebyshev's Inequality}
Chebyshev's Inequality is a fundamental result in probability theory that provides an upper bound on the probability that the value of a random variable deviates from its mean by more than a certain number of standard deviations. It is particularly useful when the distribution of the random variable is unknown.


\begin{textbox}
\textbf{Chebyshev's Inequality}: Let $X$ be a random variable with finite expected value $\mu = \mathbb{E}(X)$ and finite variance $\sigma^2 = \operatorname{Var}(X)$. Then for any $k > 0$,
\[
P(|X - \mu| \geq k\sigma) \leq \frac{1}{k^2}
\]
\end{textbox}


\textbf{Proof}\footnote{An equivalent version of Chebyshev's Inequality states that the probability that $X$ lies within $k\sigma$ is bounded by the inequality:
\[
P(|X - \mu| < k\sigma) \geq 1 - \frac{1}{k^2}
\]}: 
\begin{itemize}
    \item \textbf{Discrete Random Variables}

Assume $X$ takes values in a countable set (sample space) $S \subset \mathbb{R}$ with probability mass function $p_X(x) = P(X = x)$. The variance of $X$ is given by:
\[
\sigma^2 = \sum_{x \in S} (x - \mu)^2 p_X(x)
\]

Let $A = \{x \in S : |x - \mu| \geq k\sigma \}$ and $\overline{A} = S \setminus A = \{x : |x - \mu| < k\sigma \}$. Then,
\[
\sigma^2 = \sum_{x \in A} (x - \mu)^2 p_X(x) + \sum_{x \in \overline{A}} (x - \mu)^2 p_X(x)
\]

On the set $A$, we have $(x - \mu)^2 \geq k^2 \sigma^2$, hence
\[
\sum_{x \in A} (x - \mu)^2 p_X(x) \geq k^2 \sigma^2 \sum_{x \in A} p(x) = k^2 \sigma^2 P(|X - \mu| \geq k\sigma)
\]

Therefore,
\[
\sigma^2 \geq k^2 \sigma^2 P(|X - \mu| \geq k\sigma)
\]

Dividing both sides by $k^2 \sigma^2$ gives:
\[
P(|X - \mu| \geq k\sigma) \leq \frac{1}{k^2}
\]

\item \textbf{Continuous Random Variables}

Suppose $X$ is a continuous random variable with probability density function $f_X(x)$. The variance is:
\[
\sigma^2 = \int_{-\infty}^{\infty} (x - \mu)^2 f_X(x) \, dx
\]

Let $B = \{x \in \mathbb{R} : |x - \mu| \geq k\sigma \}$ and $\overline{B}= \{x : |x - \mu| < k\sigma \}$. Then,
\[
\sigma^2 = \int_{B} (x - \mu)^2 f_X(x) \, dx + \int_{\overline{B}} (x - \mu)^2 f_X(x) \, dx
\]

On $B$, we have $(x - \mu)^2 \geq k^2 \sigma^2$, so
\[
\int_{B} (x - \mu)^2 f_X(x) \, dx \geq k^2 \sigma^2 \int_{B} f_X(x) \, dx = k^2 \sigma^2 P(|X - \mu| \geq k\sigma)
\]

Thus,
\[
\sigma^2 \geq k^2 \sigma^2 P(|X - \mu| \geq k\sigma),
\]

and dividing both sides by $k^2 \sigma^2$ yields:
\[
P(|X - \mu| \geq k\sigma) \leq \frac{1}{k^2}
\]
\end{itemize}
\hfill\(\blacksquare\)


\textbf{Properties}:

\begin{itemize}
    \item Chebyshev's Inequality holds for any distribution with finite mean and variance, regardless of its shape.
    \item The bound provided by the inequality is not always tight; in many cases, the actual probability is much smaller than the upper bound.
    \item This inequality is particularly useful when the distribution is unknown.
\end{itemize}

\vspace{3mm}

\textbf{Example}: Suppose $X$ is a random variable with mean $\mu = 50$ and standard deviation $\sigma = 5$. Using Chebyshev's Inequality, the probability that $X$ lies outside the interval $[35, 65]$ (which is $\mu \pm 3\sigma$) is bounded by
\[
P(|X - 50| \geq 15) \leq \frac{1}{3^2} = \frac{1}{9} \approx 0.1111.
\]
Thus, we can say that at least $1 - \frac{1}{9} = \frac{8}{9} \approx 88.89\%$ of the probability mass lies within three standard deviations of the mean.

\section{Moments and Moment Generating Function}

Moments are quantitative measures that capture various aspects of the shape of a probability distribution—its central location, spread, asymmetry, and tail heaviness.

\subsection{Raw Moments and Central Moments}

Moments can be calculated about the origin (raw moments) or about the mean (central moments). 

The \textbf{$k$-th raw moment} (also called the moment about the origin) of a random variable $X$ is defined as:
\begin{textbox}
    \[
\mu'_k = \mathbb{E}[X^k]
\]
\end{textbox}


The \textbf{$k$-th central moment} of a random variable $X$ is defined as:
\begin{textbox}
    \[
\mu_k = \mathbb{E}[(X - \mu)^k]
\]
\end{textbox}
where $\mu = \mathbb{E}(X)$ is the mean of the distribution.

Moments provide insight into the shape of a distribution.  In particular:

\begin{itemize}
\item \textbf{Mean}: First raw moment:
    \[
      \mu'_1 \;=\; \mathbb{E}(X) \;=\;\mu
    \]
  \item \textbf{Variance}: The second central moment:
    \[
      \mu_2 \;=\; \mathbb{E}\bigl[(X-\mu)^2\bigr] = \sigma^2
    \]
  \item \textbf{Skewness}:
    Measures the asymmetry of the distribution. The coefficient of skewness as the third central moment of the standardized random variable $X^* \;=\; \dfrac{X - \mu}{\sigma}$:
    \[
      \gamma_1
      \;=\;\mathbb{E}\left[(X^*)^3\right]=
      \frac{\mathbb{E}\bigl[(X-\mu)^3\bigr]}{\sigma^3}
      \;=\;
      \frac{\mu_3}{\sigma^3}
    \]
  \item \textbf{Kurtosis}:
    Measures the `tailedness' or `peakedness' of the distribution. The coefficient of kurtosis is
    defined as the fourth central moment of the standardized random variable $X^* \;=\; \dfrac{X - \mu}{\sigma}$ minus 3:
    \[
      \gamma_2
      \;=\;\mathbb{E}\left[(X^*)^4\right]=
      \frac{\mathbb{E}\bigl[(X-\mu)^4\bigr]}{\sigma^4} - 3
      \;=\;
      \frac{\mu_4}{\sigma^4} - 3
    \]
\end{itemize}

\subsection{Relation Between Raw and Central Moments}

Let \(X\) be a random variable with mean \(\mu = \mathbb{E}(X)\). The $k$-th {central moment} of \(X\) is defined as:
\[
\mu_k = \mathbb{E}[(X - \mu)^k]
\]

To relate this to the raw moments \(\mu'_r = \mathbb{E}[X^r]\), we expand \((X - \mu)^k\) using the binomial theorem:
\[
(X - \mu)^k = \sum_{r=0}^{k} \binom{k}{r} (-\mu)^{k - r} X^r
\]

Taking expectations on both sides:
\[
\mu_k = \mathbb{E}[(X - \mu)^k] 
= \mathbb{E}\left[\sum_{r=0}^{k} \binom{k}{r} (-\mu)^{k - r} X^r\right]
= \sum_{r=0}^{k} (-1)^{k - r}\binom{k}{r} \mu^{k - r} \mathbb{E}[X^r]
\]

Hence, the central moment is:
\begin{textbox}
    \[
\mu_k = \sum_{r=0}^{k} (-1)^{k - r} \binom{k}{r} \mu^{k - r} \mu'_r
\]
\end{textbox}

This formula expresses the $k$-th central moment \(\mu_k\) as a linear combination of raw moments \(\mu'_r = \mathbb{E}[X^r]\) for \(r = 0, 1, \ldots, k\).

\begin{itemize}
\item \textbf{First central moment}:
$$\mu_1 = \mu'_1$$
  \item \textbf{Second central moment\footnote{An easier way to calculate the second central moment: \[
  \mu_2 = \mathbb{E}[(X - \mu)^2] 
  = \mathbb{E}[X^2 - 2\mu X + \mu^2]
  = \mathbb{E}[X^2] - 2\mu \mathbb{E}(X) + \mu^2
  = \mu'_2 - \mu^2
  \]}:}
  \[
  \mu_2 = \mu'_2 - \mu^2
  \]
  

  \item \textbf{Third central moment:}
  \[
  \mu_3 = \mu'_3 - 3\mu \mu'_2 + 3\mu^2 \mu'_1 - \mu^3
  \]

  \item \textbf{Fourth central moment:}
  \[
  \mu_4 = \mu'_4 - 4\mu \mu'_3 + 6\mu^2 \mu'_2 - 4\mu^3 \mu'_1 + \mu^4
  \]
\end{itemize}


Now to get the the expression of the raw moment \(\mu'_k\) in terms of central moments \(\mu_r\), we expand \(X^k = (\mu + (X - \mu))^k\) as:
\[
X^k = \sum_{r=0}^{k} \binom{k}{r} \mu^{k - r} (X - \mu)^r
\]

Taking expectation on both sides:
\[
\mu'_k = \mathbb{E}[X^k] = \sum_{r=0}^{k} \binom{k}{r} \mu^{k - r} \mathbb{E}[(X - \mu)^r]
= \sum_{r=0}^{k} \binom{k}{r} \mu^{k - r} \mu_r
\]
\begin{textbox}
    \[
\mu'_k = \sum_{r=0}^{k} \binom{k}{r} \mu^{k - r} \mu_r
\]
\end{textbox}

This gives the expression of the raw moment \(\mu'_k\) in terms of central moments \(\mu_r\) for \(r = 0, 1, \ldots, k\), where:
\[
\mu_r = \mathbb{E}[(X - \mu)^r], \quad \mu_0 = 1
\]

\begin{itemize}
  \item \textbf{First raw moment:}
  \[
  \mu'_1 = \mu
  \]

  \item \textbf{Second raw moment:}
  \[
  \mu'_2 = \mu^2 + \mu_2
  \]

  \item \textbf{Third raw moment:}
  \[
  \mu'_3 = \mu^3 + 3\mu \mu_2 + \mu_3
  \]

  \item \textbf{Fourth raw moment:}
  \[
  \mu'_4 = \mu^4 + 6\mu^2 \mu_2 + 4\mu \mu_3 + \mu_4
  \]
\end{itemize}

\subsection{Moment Generating Function}

There is a
clever way of organizing all the moments into one
mathematical object, and that object is called the
moment generating function.
\begin{textbox}
The \textbf{moment generating function} (MGF) of a random variable $X$ is a function $M_X:\mathbb{R} \to [0, \infty)$ given by
    \[
      M_X(t) \;=\; \mathbb{E}\bigl[e^{tX}\bigr]
    \]
provided the expectation exists in an open neighborhood\footnote{An \textbf{open neighborhood} of \( t = 0 \) is an open interval around 0, say \( (-\varepsilon, \varepsilon) \) for some \( \varepsilon > 0 \). The condition says that the expectation \( \mathbb{E}[e^{tX}] \) must \emph{converge} (i.e., be finite) for all values of \( t \) in some interval around 0.} of $t=0$.
\end{textbox}

More explicitly, the moment generating function (MGF) of a random variable \(X\) can be written as:

\begin{itemize}
    \item If \(X\) is a \textbf{discrete random variable} with probability mass function \(p_X(x_i)=P(X=x_i)\), then
    \[
    M_X(t) = \sum_{x_i} e^{tx_i} p_X(x_i)
    \]
    \item If \(X\) is a \textbf{continuous random variable} with probability density function \(f_X(x)\), then
    \[
    M_X(t) = \int_{-\infty}^{\infty} e^{tx} f_X(x) \, dx
    \]
\end{itemize}

The method to generate moments is given in the following theorem.

\begin{textbox}
\textbf{Theorem}: Let \( M_X(t) \) be the moment generating function (MGF) of a random variable \( X \). Then the \( k \)th raw moment \( \mu'_k \) of \( X \) is given by the \( k \)th derivative of \( M_X(t) \) evaluated at \( t = 0 \), i.e.,
\[
\mu'_k = M_X^{(k)}(0) = \left. \frac{d^k}{dt^k} M_X(t) \right|_{t=0}
\]
\end{textbox}

\textbf{Proof}: Let us start by expanding \( e^{tX} \) using its Taylor series about \( t = 0 \):
\[
e^{tX} = \sum_{n=0}^{\infty} \frac{(tX)^n}{n!} = \sum_{n=0}^{\infty} \frac{t^n X^n}{n!}
\]

Taking expectation on both sides:
\[
M_X(t) = \mathbb{E}[e^{tX}] = \mathbb{E} \left[ \sum_{n=0}^{\infty} \frac{t^n X^n}{n!} \right]
\]

We can interchange summation and expectation\footnote{Provided the series converges absolutely which it does in some neighborhood around \( t = 0 \) due to the MGF assumption.}:
\begin{align*}
    M_X(t) &= \sum_{n=0}^{\infty} \frac{t^n}{n!} \mathbb{E}[X^n] = \sum_{n=0}^{\infty} \frac{t^n}{n!} \mu'_n\\
&=1+ \frac{t}{1}\mu'_1 + \frac{t^2}{2!}\mu'_2+ \frac{t^3}{3!}\mu'_3 + \dots + \frac{t^k}{k!}\mu'_k +\frac{t^{k+1}}{(k+1)!}\mu'_{k+1} + \dots 
\end{align*}

This is the Taylor expansion of \( M_X(t) \), and by definition of the derivative:
\begin{align*}
    \frac{d^k}{dt^k} M_X(t) = \mu'_k + t\mu'_{k+1} + \text{terms with higher orders of }t \dots
\end{align*}
Thus,
\begin{align*}
    \mu'_k = \left. \frac{d^k}{dt^k} M_X(t) \right|_{t=0}
\end{align*}
\hfill\(\blacksquare\)

\section{Bernoulli Distribution}

A \textbf{Bernoulli trial} is a random experiment that has exactly two possible outcomes:
\begin{enumerate}
    \item \textbf{Success}, with probability $p$,
    \item \textbf{Failure}, with probability $1 - p$.
\end{enumerate}

For any Bernoulli trial, we define a random variable $X$ such that if the experiment results in success, then $X = 1$. Otherwise, $X = 0$. It follows that $X$ is a discrete random
variable, with probability mass function $p_X(x)$ defined by

\begin{textbox}
    \[
p_X(x) = P(X = x) = 
\begin{cases}
p, & \text{if } x = 1 \\
1 - p, & \text{if } x = 0 \\
0, & \text{otherwise}
\end{cases}
\]
\end{textbox}

This can be compactly written as:
\begin{textbox}
    \[
p_X(x) = p^x (1 - p)^{1 - x}, \quad \text{for } x \in \{0, 1\}
\]
\end{textbox}

The random variable $X$ is said to follow a \textbf{Bernoulli distribution} with parameter $p$, written as:
\[
X \sim \text{Bernoulli}(p)
\]
\textbf{Example}: In a fair coin toss, the outcomes can be either `Head' or `Tail'. If we define a success as getting `Head', then $p = 0.5$. The PMF of the distribution is then given by
\[
f_X(x) = P(X = x) = 
\begin{cases}
0.5, & \text{if } x = 1 \\
0.5, & \text{if } x = 0 \\
0, & \text{otherwise}
\end{cases}
\]

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=10cm,
    height=5cm,
    ybar,
    bar width=10pt,
    ymin=0,
    ymax=1.1,
    xmin=-0.5,
    xmax=1.5,
    xtick={0,1},
    xticklabels={$x=0$, $x=1$},
    xlabel={$x$},
    ylabel={$f_X(x)$},
    title={Bernoulli Distribution: $p = 0.5$},
    % ymajorgrids=true,
    % grid style=dashed
]
\addplot+[blue, fill=blue!30] coordinates {(0,0.5) (1,0.5)};
\end{axis}
\end{tikzpicture}
\end{center}

\subsection{Mean and Variance of the Bernoulli Distribution}

Let $X \sim \text{Bernoulli}(p)$.
\begin{itemize}
    \item \textbf{Mean}: 
\[
\mathbb{E}(X) = \sum_{x} x \cdot P(X = x) = 0 \cdot (1 - p) + 1 \cdot p = p
\]
\begin{textbox}
    \[
\mathbb{E}(X) = p
\]
\end{textbox}

The mean of a Bernoulli distribution is simply the probability of success, $p$.


\item \textbf{Variance}: 
\[
\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}(X))^2
\]

Note that for a Bernoulli variable, $X^2 = X$ (since $X$ is either 0 or 1), so:
\[
\mathbb{E}[X^2] = \mathbb{E}(X) = p
\]
\[
\text{Var}(X) = p - p^2 = p(1 - p)
\]
\begin{textbox}
    \[
\text{Var}(X) = p(1 - p)
\]
\end{textbox}

The variance of a Bernoulli distribution depends on both the probability of success and failure. It is maximum when $p = 0.5$.
\end{itemize}

\section{Binomial Distribution}

The {Binomial distribution} arises from repeating a Bernoulli trial independently $n$ number of times, where each trial has the same probability of success $p$.


Let $X$ denote the number of successes in $n$ independent Bernoulli trials, where each trial has two outcomes: {success} (with probability $p$) and {failure} (with probability $1 - p$).
Then the discrete random variable $X$ follows a \textbf{Binomial distribution} with parameters $n$ and $p$, written as:
\[
X \sim \text{Binomial}(n, p)
\]

The probability mass function (PMF) of $X$ is given by:
\begin{textbox}
\[
p_X(x) = P(X = x) = 
\begin{cases}
\binom{n}{x} p^x (1 - p)^{n - x}, & \text{for } x = 0, 1, 2, \ldots, n \\
0, & \text{otherwise}
\end{cases}
\]

\end{textbox}

To derive this PMF, consider the following:

\begin{itemize}
    \item We want the probability of getting exactly $x$ successes (and hence $n - x$ failures) in $n$ trials.
    \item Each specific sequence of outcomes with $x$ successes and $n - x$ failures has probability:
    \[
    p^x (1 - p)^{n - x}
    \]
    because of the independence of trials.
    \item However, there are multiple ways (distinct sequences) to arrange $x$ successes among $n$ trials. The number of such arrangements is given by the binomial coefficient:
    \[
    \binom{n}{x} = \frac{n!}{x!(n - x)!}
    \]
\end{itemize}

Thus, the total probability of getting exactly $x$ successes is:
\[
P(X = x) = \binom{n}{x} p^x (1 - p)^{n - x}
\]

This expression defines the PMF of the binomial distribution.

\begin{textbox}
    A Binomial random variable is the sum of independent Bernoulli random variables i.e. if $$X=\sum_{i=1}^{n} X_i, \text{ with } X_i\sim \text{Bernoulli}(p)$$ for all $i = 1,2,\dots, n$,
    then, $$X\sim \text{Binomial}(n, p)$$
\end{textbox}

\vspace{2mm}

\textbf{Example}: Suppose a fair coin (with $p = 0.5$) is tossed 4 times. Let $X$ be the number of heads observed. Then $X \sim \text{Binomial}(4, 0.5)$. The PMF is:

\[
p_X(x) = \binom{4}{x} \times (0.5)^x \times (0.5)^{4 - x}, \quad x = 0, 1, 2, 3, 4
\]

Evaluating:
\[
\begin{aligned}
p_X(0) &= \binom{4}{0} \times (0.5)^0 \times (0.5)^4 = 1 \times 1 \times 0.0625 = 0.0625 \\
p_X(1) &= \binom{4}{1} \times (0.5)^1 \times (0.5)^3 = 4 \times 0.5 \times 0.125 = 0.25 \\
p_X(2) &= \binom{4}{2} \times (0.5)^2 \times (0.5)^2 = 6 \times 0.25 \times 0.25 = 0.375 \\
p_X(3) &= \binom{4}{3} \times (0.5)^3 \times (0.5)^1 = 4 \times 0.125 \times 0.5 = 0.25 \\
p_X(4) &= \binom{4}{4} \times (0.5)^4 \times (0.5)^0 = 1 \times 0.0625 \times 1 = 0.0625
\end{aligned}
\]


\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=10cm,
    height=5cm,
    ybar,
    bar width=10pt,
    ymin=0,
    ymax=0.4,
    xmin=-0.5,
    xmax=4.5,
    xtick={0,1,2,3,4},
    xlabel={$x$ (Number of successes)},
    ylabel={$f_X(x)$},
    title={Binomial Distribution: $n = 4$, $p = 0.5$},
    % ymajorgrids=true,
    % grid style=dashed
]
\addplot+[blue, fill=blue!30] coordinates {
    (0,0.0625)
    (1,0.25)
    (2,0.375)
    (3,0.25)
    (4,0.0625)
};
\end{axis}
\end{tikzpicture}
\end{center}

\textbf{Example:} A fair six-sided die is rolled 8 times. What is the probability that the number 3 or 4 appears exactly 3 times?

Let a `success' be defined as getting either a 3 or a 4 in a single roll. The probability of success on one roll is:

\[
p = P(3 \text{ or } 4) = \frac{1}{6} + \frac{1}{6} = \frac{2}{6} = \frac{1}{3}
\]

Let $X$ be the number of successes (i.e., times 3 or 4 occurs) in $n = 8$ independent die rolls. Then $X$ follows a binomial distribution:

\[
X \sim \text{Binomial}\left(n =8, p = \frac{1}{3}\right)
\]

We want to find the probability three successes i.e. $X = 3$:

\[
P(X = 3) = \binom{8}{3} \times \left( \frac{1}{3} \right)^3 \times \left( \frac{2}{3} \right)^5
\]

Now, compute the values:

\[
\binom{8}{3} = 56, \quad \left( \frac{1}{3} \right)^3 = \frac{1}{27}, \quad \left( \frac{2}{3} \right)^5 = \frac{32}{243}
\]

\[
P(X = 3) = 56 \times \frac{1}{27} \times \frac{32}{243} = \frac{1792}{6561} \approx 0.273
\]

\subsection{Mean and Variance of the Binomial Distribution}

Let $X \sim \text{Binomial}(n, p)$.

\begin{itemize}
    \item \textbf{Mean}:

    Consider $X$ as the sum of $n$ independent Bernoulli random variables:
    \[
    X = X_1 + X_2 + \cdots + X_n, \quad \text{where } X_i \sim \text{Bernoulli}(p)
    \]

    Since expectation is linear:
    \[
    \mathbb{E}(X) = \mathbb{E}[X_1 + X_2 + \cdots + X_n] = \mathbb{E}[X_1] + \mathbb{E}[X_2] + \cdots + \mathbb{E}[X_n]
    \]

    Each $X_i$ has expected value $p$, so:
    \begin{textbox}
        \[
    \mathbb{E}(X) = n \cdot p
    \]
    \end{textbox}

    Thus on average, we can expect $n \cdot p$ successes in $n$ trials.

    \item \textbf{Variance}:

    Since the $X_i$'s are independent:
    \[
    \text{Var}(X) = \text{Var}(X_1 + X_2 + \cdots + X_n) = \text{Var}(X_1) + \text{Var}(X_2) + \cdots + \text{Var}(X_n)
    \]

    Each $X_i$ is Bernoulli with variance $p(1 - p)$, so:
    \begin{textbox}
        \[
    \text{Var}(X) = n \cdot p(1 - p)
    \]
    \end{textbox}

    The variance increases with the number of trials and depends on both the probability of success and failure.
\end{itemize}

\section{Poisson Distribution}

The {Poisson distribution} is commonly used to model the number of occurrences of an event in a fixed interval of time or space, under the following assumptions:
\begin{itemize}
    \item Events occur independently.
    \item The average rate ($\lambda$) of occurrence is constant over the interval.
    \item Two events cannot occur at exactly the same instant.
\end{itemize}

Let $X$ denote the number of such events occurring in a fixed interval with an average value $\lambda$, then we say that the discrete random variable $X$ follows a \textbf{Poisson distribution} with parameter $\lambda > 0$, and write:
\[
X \sim \text{Poisson}(\lambda)
\]

The probability mass function (PMF) of $X$ is given by:
\begin{textbox}
\[
p_X(x) = P(X = x) = 
\begin{cases}
\displaystyle \frac{e^{-\lambda} \lambda^x}{x!}, & \text{for } x = 0, 1, 2, \ldots \\
0, & \text{otherwise}
\end{cases}
\]
\end{textbox}

\textbf{Example:} Suppose a call center receives an average of 4 calls per minute. What is the probability that exactly 2 calls are received in a particular minute?

Let $X$ be the number of calls per minute. Then:
\[
X \sim \text{Poisson}(\lambda = 4)
\]
We want to find $P(X = 2)$:
\[
P(X = 2) = \frac{e^{-4} \cdot 4^2}{2!} = \frac{e^{-4} \cdot 16}{2} = 8e^{-4} \approx 0.1465
\]

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=10cm,
    height=5cm,
    ybar,
    bar width=10pt,
    ymin=0,
    ymax=0.25,
    xmin=-0.5,
    xmax=9.5,
    xtick={0,1,2,3,4,5,6,7,8,9},
    xlabel={$x$ (Number of occurrences)},
    ylabel={$f_X(x)$},
    title={Poisson Distribution: $\lambda = 4$},
]
\addplot+[blue, fill=blue!30] coordinates {
    (0,0.0183)
    (1,0.0733)
    (2,0.1465)
    (3,0.1954)
    (4,0.1954)
    (5,0.1563)
    (6,0.1042)
    (7,0.0595)
    (8,0.0297)
    (9,0.0132)
};
\end{axis}
\end{tikzpicture}
\end{center}

\textbf{Example}: In a football league, the number of goals scored by a team in a match is modeled using a Poisson distribution. Based on historical performance, Team A scores an average of $2.1$ goals per match.

\begin{enumerate}
    \item What is the probability that Team A scores exactly 3 goals in an upcoming match?
    \item What is the probability that Team A scores fewer than 2 goals?
    \item What is the probability that Team A scores at least 2 goals?
    \item What is the expected number of goals Team A will score over their next 5 matches?
\end{enumerate}

The Poisson probability mass function (PMF) is given by:
\[
f_X(x) = P(X=x)= \frac{e^{-\lambda} \lambda^x}{x!}
\quad \text{where } \lambda = 2.1, \quad x = 0, 1, 2, \dots
\]

\begin{enumerate}
    \item {Probability that Team A scores exactly 3 goals:}
    \[
    f_X(3)  = \frac{e^{-2.1} \cdot 2.1^3}{3!}
    = \frac{e^{-2.1} \cdot 9.261}{6}
    \approx \frac{0.1225 \cdot 9.261}{6}
    \approx 0.189
    \]

    \item {Probability that Team A scores fewer than 2 goals:}
    \[
    P(X < 2) = {P}(X = 0) + {P}(X = 1) = f_X(0) + f_X(1)
    \]
    \[
    f_X(0) = e^{-2.1} \approx 0.1225, \quad 
    f_X(1) = \frac{e^{-2.1} \cdot 2.1}{1!} \approx 0.2573
    \]
    \[
    P(X < 2) \approx 0.1225 + 0.2573 = 0.3798
    \]

    \item {Probability that Team A scores at least 2 goals:}
    \[
    P(X \geq 2) = 1 - P(X < 2) = 1 - 0.3798 = 0.6202
    \]

    \item {Expected number of goals over 5 matches:}
    \[
    5 \times \mathbb{E}(X) = 5 \times \lambda = 5 \times 2.1 = 10.5
    \]
\end{enumerate}

\begin{textbox}
\textbf{Theorem}: The Poisson distribution can be obtained as the limiting distribution of the Binomial distribution when the number of trials \( n \to \infty \), the success probability \( p \to 0\), while the expected number of successes \( \lambda = np \) remains constant. Formally,
\[
\text{Binomial}(n, p) \longrightarrow \text{Poisson}(\lambda) \quad \text{as } n \to \infty, p \to 0 \text{ such that } np = \lambda (\text{constant})
\]
\end{textbox}

\textbf{Proof}: Let \( X \sim \text{Binomial}(n, p) \). The probability mass function (PMF) is:
\[
p_X(k) = \binom{n}{k} p^x (1 - p)^{n-x}, \quad x = 0, 1, 2, \ldots, n.
\]

We assume \( n \to \infty \) and \( p \to 0 \) such that the product \( \lambda = np \) remains fixed and finite. We can write the binomial coefficient as:
\begin{align*}
    \binom{n}{x} &= \frac{n (n-1) \cdots (n-x+1)}{x!} \\
    &= \frac{n^k}{x!} \left(1 - \frac{1}{n}\right)\left(1 - \frac{2}{n}\right) \dots \left(1 - \frac{x-1}{n}\right)
\end{align*}

As \( n \to \infty \), each of the product terms approaches 1:
Thus,
\[
\binom{n}{x} \to \frac{n^x}{x!}
\]

Now using this limiting expression of $\binom{n}{x}$ and replacing \( p \) with \( \dfrac{\lambda}{n} \), we get:
\[
p_X(x) \approx \frac{n^x}{x!} \left(\frac{\lambda}{n}\right)^x \left(1 - \frac{\lambda}{n}\right)^{n-x} = \frac{\lambda^x}{x!} \left(1 - \frac{\lambda}{n}\right)^{n-x}
\]

Rewrite the last term as:
\[
\left(1 - \frac{\lambda}{n}\right)^{n-x} = \left(1 - \frac{\lambda}{n}\right)^n \left(1 - \frac{\lambda}{n}\right)^{-x}
\]

As \( n \to \infty \), 
\[
\left(1 - \frac{\lambda}{n}\right)^n \to e^{-\lambda}
\quad \text{and} \quad
\left(1 - \frac{\lambda}{n}\right)^{-x} \to 1,
\]
since \( x \) is fixed.


Therefore in the limit \( n \to \infty \):
\[
\lim_{n \to \infty} p_X(x) = \frac{\lambda^x}{x!} e^{-\lambda} \cdot 1 = \frac{e^{-\lambda} \lambda^x}{x!}
\]

This matches the PMF of the Poisson distribution with parameter \( \lambda \).
\hfill\(\blacksquare\)

\subsection{Mean and Variance of the Poisson Distribution}

Let $X \sim \text{Poisson}(\lambda)$.

\begin{itemize}
    \item \textbf{Mean}:
    % \begin{align*}
    %     \mathbb{E}(X) &= \sum_{x=0}^{\infty} x \cdot P(X = x) = \sum_{x=0}^{\infty} x \cdot \frac{e^{-\lambda} \lambda^x}{x!} \\
    %     &=\frac{e^{-\lambda}\left(0+1\times\frac{\lambda^1}{1}+2\times\frac{\lambda^2}{2}+\dots \right)
    % \end{align*}
    \begin{align*}
\mathbb{E}(X) &= \sum_{x=0}^{\infty} x \cdot P(X = x) = \sum_{x=0}^{\infty} x \cdot \frac{e^{-\lambda} \lambda^x}{x!} \\
&= e^{-\lambda} \sum_{x=1}^{\infty} x \cdot \frac{\lambda^x}{x!} = e^{-\lambda} \sum_{x=1}^{\infty} \frac{\lambda^x}{(x-1)!} \\
&= e^{-\lambda} \cdot \lambda \sum_{x=1}^{\infty} \frac{\lambda^{x-1}}{(x-1)!} \\
&= \lambda \cdot e^{-\lambda} \sum_{k=0}^{\infty} \frac{\lambda^k}{k!} \quad \text{(let } k = x - 1 \text{)} \\
&= \lambda \cdot e^{-\lambda} \cdot e^{\lambda} = \lambda
\end{align*}

    \begin{textbox}
        \[
    \mathbb{E}(X) = \lambda
    \]
    \end{textbox}

    \item \textbf{Variance}:
    \[
    \text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}(X))^2
    \]

    First we evaluate
\[
\mathbb{E}[X^2] = \sum_{x=0}^{\infty} x^2 \cdot \frac{e^{-\lambda} \lambda^x}{x!}
\]

We use the identity \(x^2 = x(x - 1) + x\), giving:
\[
\mathbb{E}[X^2] = \sum_{x=0}^{\infty} \left[x(x - 1) + x\right] \cdot \frac{e^{-\lambda} \lambda^x}{x!}
= e^{-\lambda} \left( \sum_{x=0}^{\infty} \frac{x(x-1) \lambda^x}{x!} + \sum_{x=0}^{\infty} \frac{x \lambda^x}{x!} \right)
\]

We compute each sum:
\[
\sum_{x=0}^{\infty} \frac{x(x-1) \lambda^x}{x!} =\sum_{x=2}^{\infty} \frac{\lambda^x}{(x-2)!}=\lambda^2\sum_{j=0}^{\infty} \frac{\lambda^j}{j!} =\lambda^2 e^{\lambda}
\]

And,
$$\sum_{x=0}^{\infty} \frac{x \lambda^x}{x!} = =\sum_{x=1}^{\infty} \frac{\lambda^x}{(x-1)!}=\lambda\sum_{j=0}^{\infty} \frac{\lambda^j}{j!} =\lambda e^{\lambda}$$

Therefore,
\[
\mathbb{E}[X^2] = e^{-\lambda} \left( \lambda^2 e^{\lambda} + \lambda e^{\lambda} \right) = \lambda^2 + \lambda
\]

  Therefore:
    \[
    \text{Var}(X) = (\lambda + \lambda^2) - \lambda^2 = \lambda
    \]

    \begin{textbox}
        \[
    \text{Var}(X) = \lambda
    \]
    \end{textbox}

    \vspace{3mm}
    
    There is an alternative way of calculating the variance using the moment generating function (MGF). 
    
    The moment generating function (MGF) of \( X \) is defined as:
    \[
M_X(t) = \mathbb{E}[e^{tX}] = \sum_{k=0}^{\infty} e^{t x} \cdot \frac{e^{-\lambda} \lambda^x}{x!}
\]

Factor out the constant \( e^{-\lambda} \):
\[
M_X(t) = e^{-\lambda} \sum_{x=0}^{\infty} \frac{(\lambda e^t)^x}{x!}
\]

This is the exponential series:
\[
\sum_{x=0}^{\infty} \frac{(\lambda e^t)^x}{x!} = e^{\lambda e^t}
\]

Therefore,
\[
M_X(t) = e^{-\lambda} \cdot e^{\lambda e^t} = e^{\lambda(e^t - 1)}
\]

To compute the variance \( \mathrm{Var}(X) \), we use the identity:
\[
\mathrm{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}(X))^2 = \mu_2' - \mu^2 = \mu_2' - (\mu_1')^2
\]

We compute the first and second raw moments using derivatives of the MGF:

\underline{First raw moment (mean):}
\[
M_X'(t) = \frac{d}{dt} \left[ e^{\lambda(e^t - 1)} \right] 
= \lambda e^t \cdot e^{\lambda(e^t - 1)}
\]

Evaluating at \( t = 0 \):
\[
\mu_1' = M_X'(0) = \lambda \cdot 1 \cdot e^{\lambda(1 - 1)} = \lambda
\]

\underline{Second raw moment:}
\[
M_X''(t) = \frac{d}{dt} \left[ \lambda e^t \cdot e^{\lambda(e^t - 1)} \right]
= \lambda e^t \left[ \lambda e^t \cdot e^{\lambda(e^t - 1)} + e^{\lambda(e^t - 1)} \right]
= \lambda e^t e^{\lambda(e^t - 1)} (\lambda e^t + 1)
\]

Evaluating at \( t = 0 \):
\[
\mu_2' = M_X''(0) = \lambda \cdot 1 \cdot 1 \cdot (\lambda \cdot 1 + 1) = \lambda(\lambda + 1) = \lambda^2 + \lambda
\]

\underline{Now compute the variance:}
\[
\mathrm{Var}(X) = \mu_2' - (\mu_1')^2 = (\lambda^2 + \lambda) - \lambda^2 = \lambda
\]
\end{itemize}

% \textbf{Remark:} Because the mean and variance are equal, Poisson models are particularly useful for count data with this characteristic. If variance is significantly greater than the mean, other models (e.g., Negative Binomial) may be more appropriate.

\section{Uniform Distribution}

The Uniform distribution is the simplest continuous probability distribution, where all outcomes in a given interval are equally likely.

Let $X$ be a continuous random variable that is uniformly distributed on the interval $[a, b]$, where $a < b$. This means that $X$ has constant probability density over this interval. We write:

\[
X \sim \text{Uniform}(a, b)
\]

The probability density function (PDF) of $X$ is given by:

\begin{textbox}
\[
f_X(x) =
\begin{cases}
\frac{1}{b - a}, & a \le x \le b \\
0, & \text{otherwise}
\end{cases}
\]
\end{textbox}

That is, the probability density is constant between $a$ and $b$, and zero elsewhere. The total area under the curve is 1, ensuring it satisfies the definition of a probability density function.

A continuous uniform distribution models situations where every outcome in an interval is equally likely—such as the exact time (within an hour) a bus arrives, or the position of a point randomly placed on a stick.

\vspace{2mm}
\textbf{Example:} Suppose that a variable $X$ is uniformly distributed over the interval $[2, 5]$. Then:

\[
f_X(x) =
\begin{cases}
\frac{1}{5 - 2} = \frac{1}{3}, & 2 \le x \le 5 \\
0, & \text{otherwise}
\end{cases}
\]

We can compute probabilities over intervals by integrating the density. For example:

\[
P(3 \le X \le 4) = \int_{3}^{4} \frac{1}{3} dx = \frac{1}{3}(4 - 3) = \frac{1}{3}
\]

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=10cm,
    height=5cm,
    ymin=0, ymax=0.5,
    xmin=1, xmax=6,
    axis lines=left,
    xlabel={$x$},
    ylabel={$f_X(x)$},
    title={Uniform Distribution: $a = 2$, $b = 5$},
    xtick={2,3,4,5},
    ytick={0.33},
    yticklabels={$1/3$},
    domain=2:5,
    samples=2
]
% \addplot+[blue, thick, fill=blue!30, draw=none, domain=3:4] {1/3} \closedcycle;
% \addplot[blue, thick] {1/3};
\addplot[
    blue,
    very thick
] coordinates {
    (0,0)
    (2,0)
};
\addplot[
    blue,
    dotted
] coordinates {
    (2,0)
    (2,1/3)
};
\addplot[
    blue,
    very thick
] coordinates {
    (2,1/3)
    (5,1/3)
};
\addplot[
    blue,
    dotted
] coordinates {
    (5,1/3)
    (5,0)
};
\addplot[
    blue,
    very thick
] coordinates {
    (5,0)
    (6,0)
};
\end{axis}
\end{tikzpicture}
\end{center}

\subsection{Mean and Variance of the Uniform Distribution}

Let $X \sim \text{Uniform}(a, b)$.

\begin{itemize}
    \item \textbf{Mean}:
\begin{align*}
\mathbb{E}(X) &= \int_a^b x \cdot \frac{1}{b - a} \, dx 
= \frac{1}{b - a} \int_a^b x \, dx \\
&= \frac{1}{b - a} \cdot \left[ \frac{x^2}{2} \right]_a^b 
= \frac{1}{b - a} \cdot \left( \frac{b^2 - a^2}{2} \right) \\
&= \frac{1}{b - a} \cdot \frac{(b - a)(b + a)}{2} 
= \frac{a + b}{2}
\end{align*}

    \begin{textbox}
    \[
    \mathbb{E}(X) = \frac{a + b}{2}
    \]
    \end{textbox}

    \item \textbf{Variance}:
    \[
    \text{Var}(X) = \mathbb{E}(X^2) - [\mathbb{E}(X)]^2
    \]
    with:
    \[
    \mathbb{E}(X^2) = \int_a^b x^2 \cdot \frac{1}{b - a} dx = \frac{1}{b - a} \left[\dfrac{x^3}{3}\right]_a^b= \frac{b^3 - a^3}{3(b - a)}
    \]
    \begin{textbox}
    \[
    \text{Var}(X) = \frac{(b - a)^2}{12}
    \]
    \end{textbox}
\end{itemize}

\vspace{2mm}

\textbf{Example:} For $X \sim \text{Uniform}(2, 5)$:

\[
\mathbb{E}(X) = \frac{2 + 5}{2} = 3.5, \quad \text{Var}(X) = \frac{(5 - 2)^2}{12} = \frac{9}{12} = 0.75
\]


\section{Normal Distribution}

The \textbf{Normal distribution}, also known as the \textbf{Gaussian distribution}, is one of the most important continuous probability distributions in statistics. It models many naturally occurring phenomena such as heights, test scores, measurement errors, etc. When a continuous random variable $X$ is said to follow a {Normal distribution} with parameter $\mu$ and $\sigma^2$, we denote it as:
\[
X \sim \mathcal{N}(\mu, \sigma^2)
\]

The probability density function (PDF) of the Normal distribution is given by:
\begin{textbox}
\[
f_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(x - \mu)^2}{2\sigma^2} \right), \quad \text{for } -\infty \leq x \leq \infty 
\]
\end{textbox}

The distribution is completely determined by the parameters $\mu$ and $\sigma^2$. In future, we will show that the mean and variance of the normal distribution are those parameters $\mu$ and $\sigma^2$ respectively.

\textbf{Example}: Let $X \sim \mathcal{N}(2, 1^2)$, i.e., a normal distribution with mean $\mu = 2$ and standard deviation $\sigma = 1$. 
We want to compute the value of the probability density function (PDF) at $x = 1.5$.

The PDF of a normal distribution is:
\[
f_X(x) = \frac{1}{\sigma\sqrt{2\pi }} \exp\left( -\frac{(x - \mu)^2}{2\sigma^2} \right)
\]

Substitute $\mu = 2$, $\sigma = 1$, and $x = 1.5$:
\[
f_X(1.5) = \frac{1}{\sqrt{2\pi}} \exp\left( -\frac{(1.5 - 2)^2}{2} \right)
= \frac{1}{\sqrt{2\pi}} \exp\left( -\frac{0.25}{2} \right)
= \frac{1}{\sqrt{2\pi}} \exp(-0.125)
\]

Now compute numerically:
\[
\frac{1}{\sqrt{2\pi}} \approx 0.3989, \quad \exp(-0.125) \approx 0.8825
\]

\[
f_X(1.5) \approx 0.3989 \times 0.8825 \approx 0.3521
\]

The plot of the PDF of $X \sim \mathcal{N}(2,1)$ is shown in the figure below:

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    no markers, domain=-2:6, samples=100,
    axis lines=left,
    xlabel=$x$, ylabel={$f_X(x)$},
    height=5cm, width=10cm,
    ymin=0, ymax=0.5,
    xmin=-2, xmax=6,
    title={\small Normal Distribution $\mathcal{N}(2,1)$}
]
\addplot [very thick,blue] {1/sqrt(2*pi)*exp(-(x-2)^2/2)};
\end{axis}
\end{tikzpicture}
\end{center}

\subsection{Mean and Variance of the Normal Distribution}

Let $X \sim \mathcal{N}(\mu, \sigma^2)$.

\begin{itemize}
    \item \textbf{Mean}:
    
    \begin{align*}
    \mathbb{E}[X]
    &= \int_{-\infty}^{\infty} x \; f_X(x)\,dx
    = \int_{-\infty}^{\infty} x \;\frac{1}{\sqrt{2\pi}\,\sigma}
    \exp\!\biggl(-\frac{(x-\mu)^2}{2\sigma^2}\biggr)\,dx \\[6pt]
    %
    \text{Let } u &= \frac{x - \mu}{\sigma}
    \quad\Longrightarrow\quad
    x = \sigma u + \mu,
    \quad dx = \sigma\,du, \\[3pt]
    %
    \mathbb{E}[X] &= \int_{-\infty}^{\infty}
    (\sigma u + \mu)\;
    \frac{1}{\sqrt{2\pi}\,\sigma}
    \exp\!\bigl(-\tfrac{u^2}{2}\bigr)\;\sigma\,du \\[6pt]
    %
    &= \int_{-\infty}^{\infty}
    (\sigma u + \mu)\;
    \frac{1}{\sqrt{2\pi}}
    \exp\!\bigl(-\tfrac{u^2}{2}\bigr)\;du \\[6pt]
    %
    &= \underbrace{\int_{-\infty}^{\infty}
    \sigma u \;\frac{1}{\sqrt{2\pi}}
    e^{-u^2/2}\,du}_{=\,0\;\text{(odd integrand)}} 
    \;+\;
    \mu \int_{-\infty}^{\infty}
    \frac{1}{\sqrt{2\pi}}
    e^{-u^2/2}\,du \\[6pt]
    %
    &= 0 \;+\; \mu \cdot 1 
    \;=\; \mu.
    \end{align*}
    
    \begin{textbox}
        \[
        \mathbb{E}(X) = \mu
        \]
        \end{textbox}
    

    \item \textbf{Variance}:
    \begin{align*}
    \operatorname{Var}(X)
    &= \mathbb{E}\bigl[(X - \mu)^2\bigr]
    = \int_{-\infty}^{\infty} (x - \mu)^2 \; f_X(x)\,dx \\
    &= \int_{-\infty}^{\infty} (x - \mu)^2 \;\frac{1}{\sqrt{2\pi}\,\sigma}
    \exp\!\Bigl(-\frac{(x-\mu)^2}{2\sigma^2}\Bigr)\,dx \\[6pt]
    %
    \text{Let } u &= \frac{x - \mu}{\sigma}
    \quad\Longrightarrow\quad
    x - \mu = \sigma u,
    \quad dx = \sigma\,du, \\[3pt]
    %
    \operatorname{Var}(X)&= \int_{-\infty}^{\infty}
    (\sigma u)^2 \;
    \frac{1}{\sqrt{2\pi}\,\sigma}
    \exp\!\bigl(-\tfrac{u^2}{2}\bigr)\;\sigma\,du \\[6pt]
    %
    &= \int_{-\infty}^{\infty}
    \sigma^2 u^2 \;
    \frac{1}{\sqrt{2\pi}}
    \exp\!\bigl(-\tfrac{u^2}{2}\bigr)\;du \\[6pt]
    %
    &= \sigma^2 \underbrace{\int_{-\infty}^{\infty}
            u^2 \;\frac{1}{\sqrt{2\pi}} e^{-u^2/2}\,du}_{\text{We need to prove this equals 1}}\\
    &= \frac{\sigma^2}{\sqrt{2\pi}} \int_{-\infty}^{\infty} u^2\,e^{-u^2/2}\,du\\
    &= \frac{2\sigma^2}{\sqrt{2\pi}} \int_{0}^{\infty} u^2\,e^{-u^2/2}\,du\
    \end{align*}
    
    Now, using the Gamma integral formula\footnote{Gamma integral formula:
    $$\int_{0}^{\infty} x^n e^{-a x^2}dx
         = \tfrac12\,a^{-\frac{n+1}{2}}\Gamma\!\bigl(\tfrac{n+1}{2}\bigr)$$
         $$\Gamma(n+1) = n\Gamma(n), \quad \Gamma(\tfrac12) = \sqrt{\pi}$$
         },
    \begin{align*}
    \int_{0}^{\infty} u^2\,e^{-u^2/2}\,du
    &= \frac{1}{2}\,\Bigl(\tfrac12\Bigr)^{-\frac{3}{2}}
       \,\Gamma\!\Bigl(\tfrac{3}{2}\Bigr)\\
    &= \frac{1}{2}\,\cdot 2^{3/2}\,\cdot \frac{1}{2}\sqrt{\pi}
    &&\bigl((\tfrac12)^{-3/2}=2^{3/2},\ \Gamma(\tfrac32)=\tfrac12\Gamma(\tfrac12) = \tfrac12\sqrt\pi\bigr)\\
    &= \frac{\sqrt{2\pi}}{2}
    \end{align*}
    
    Therefore,
    \[
    \text{Var}(X) = \sigma^2 \frac{2}{\sqrt{2\pi}} \times \frac{\sqrt{2\pi}}{2}
      = \sigma^2
    \]
    
        \begin{textbox}
        \[
        \text{Var}(X) = \sigma^2
        \]
        \end{textbox}   
\end{itemize}


\subsection{Properties of the Normal Distribution}

\begin{enumerate}
  \item The \textbf{support} of a normal random variable \(X \sim N(\mu,\sigma^2)\) is the entire real line:
    \[
	(-\infty \leq X \leq,\,+\infty)
    \]
    This reflects that, however unlikely, arbitrarily large positive or negative values can occur.
    
  \item The probability density function is perfectly \textbf{symmetric} about its mean \(\mu\) since,
    \[
      f_X(\mu + x_0) = f_X(\mu - x_0) =  \frac{1}{\sigma\sqrt{2\pi }} \exp\left( -\frac{x_0^2}{2\sigma^2} \right)
      \quad\forall\,x_0\in\mathbb{R}.
    \]
    As a result, the left and right tails of the distribution mirror each other.
    
  \item Since the distribution is symmetrical about $\mu$, its mean and median coincide.To get the mode, we need to calculate the peak point of the distribution.
  \begin{align*}
  f_X(x) &= \frac{1}{\sigma\sqrt{2\pi}} \exp\left( -\frac{(x-\mu)^2}{2\sigma^2}\right)  \\[6pt]
  \frac{d}{dx}f_X(x)
  &= \frac{1}{\sigma\sqrt{2\pi}} \exp\left( -\frac{(x-\mu)^2}{2\sigma^2}\right)
     \cdot \frac{d}{dx}\left( -\tfrac{(x-\mu)^2}{2\sigma^2}\right)  \\[6pt]
  &= f_X(x)\,\Bigl(-\tfrac{2(x-\mu)}{2\sigma^2}\Bigr)
  = -\frac{x-\mu}{\sigma^2}\,f_X(x)
  \end{align*}
  Setting the derivative to zero for a stationary point:
  \begin{align*}
  -\frac{x-\mu}{\sigma^2}\,f_X(x) = 0
  \quad &\Longrightarrow\quad x - \mu = 0 \\[4pt]
  &\Longrightarrow\quad x = \mu
  \end{align*}
  
  Now, 
  \begin{align*}
  f_X''(x)
  &= -\frac{1}{\sigma^2}\,f_X(x)
     + \Bigl(-\frac{x-\mu}{\sigma^2}\Bigr)\,f_X'(x)
  \\
  &= -\frac{1}{\sigma^2}\,f_X(x)
     + \Bigl(-\frac{x-\mu}{\sigma^2}\Bigr)\Bigl(-\frac{x-\mu}{\sigma^2}f_X(x)\Bigr)
  \\
  &= -\frac{1}{\sigma^2}\,f_X(x)
     + \frac{(x-\mu)^2}{\sigma^4}\,f_X(x)
  \\
  &= \frac{(x-\mu)^2 - \sigma^2}{\sigma^4}\,f_X(x)
  \end{align*}
  Evaluating at the stationary point \(x=\mu\):
  \[
  f_X''(\mu)
  = \frac{(\mu-\mu)^2 - \sigma^2}{\sigma^4}\,f_X(\mu)
  = -\frac{1}{\sigma^2}\,f_X(\mu)
  < 0,
  \]
  
  Hence the peak (mode) of the normal density occurs at \(x=\mu\).  
  \begin{textbox}
  For normal distribution, all measures of central tendency coincide:
      \[
        \text{Mean} = \text{Median} = \text{Mode} = \mu.
      \]
  \end{textbox}
    
    
  \item The normal distribution curve has two \textbf{points of inflection}\footnote{A \textbf{point of inflection} of a function $f(x)$ is a point $x = a$ such that
  \[
  f''(a) = 0,
  \]
  At the point of inflexion, the second derivative $f''(x)$ changes sign as $x$ passes through $a$, meaning the curve switches between concave‐up and concave‐down at $x = a$.} at a distance $\sigma$ on either side of $\mu$ i.e. at
    \[
      x = \mu \pm \sigma.
    \]
    At these points the second derivative of \(f_X(x)\) vanishes, marking the transition between “concave down” near the center and “concave up” in the tails. To show that let's take the second derivative of $f_X(x)$ and equate it to zero:
   \begin{align*}
   f_X''(x) &= \frac{(x-\mu)^2 - \sigma^2}{\sigma^4}\,f_X(x) = 0 \\
   &\Rightarrow (x-\mu)^2 = \sigma^2 \\
   &\Rightarrow x-\mu = \pm\sigma \\
   &\Rightarrow x = \mu \pm\sigma \\
   \end{align*}
    
  \item All odd central moments are zero (due to symmetry), and the even central moments have closed‐form expressions:
    \[
      E\bigl[(X-\mu)^{2n+1}\bigr] = 0,
      \qquad
      E\bigl[(X-\mu)^{2n}\bigr] = \sigma^{2n}\,(2n - 1)!!,
      \quad n = 1,2,\dots
    \]
    In particular, the variance is \(E[(X-\mu)^2]=\sigma^2\), and the fourth central moment is \(3\sigma^4\), etc.
    
   \item The kurtosis of normal distribution is 3. (prove it)
    
  \item A normal distribution \(X\sim N(\mu,\sigma^2)\) satisfies the following empirical rules:

  \begin{textbox}
  \textbf{Empirical Rule (68-95-99.7 Rule)}:
    \begin{itemize}
        \item About 68.27\% of the values lie within $\sigma$ of the mean ($\mu \pm \sigma$).
        \item About 95.45\% of the values lie within $2\sigma$ of the mean ($\mu \pm 2\sigma$).
        \item About 99.73\% of the values lie within $3\sigma$ of mean ($\mu \pm 3\sigma$).
    \end{itemize}
  \end{textbox}
  
  \begin{center}   
    \begin{tikzpicture}
        \begin{axis}[
            no markers, domain=-4:4, samples=100,
            axis lines=center,
            xlabel={$x/\sigma$}, 
            axis y line=none,
            ymin=0, ymax=0.5,
            xmin=-4, xmax=4,
            height=6cm, width=14cm,
            ytick=\empty
          ]
          % PDF curve
          \addplot [very thick, blue] {1/sqrt(2*pi)*exp(-x^2/2)};
          % Shaded right-tail for z>1.5
          
          
          \addplot [draw=none, fill=red!20, domain=-3:3] {1/sqrt(2*pi)*exp(-x^2/2)-0.004} \closedcycle;
          % Vertical guide line
          \draw[dashed] (axis cs:-3,0) -- (axis cs:-3,{1/sqrt(2*pi)*exp(-0.1^2/2)});
          \draw[dashed] (axis cs:3,0) -- (axis cs:3,{1/sqrt(2*pi)*exp(-0.1^2/2)});
                    
          
          \addplot [draw=none, fill=green!20, domain=-2:2] {1/sqrt(2*pi)*exp(-x^2/2)-0.004} \closedcycle;
          % Vertical guide line
          \draw[dashed] (axis cs:-2,0) -- (axis cs:-2,{1/sqrt(2*pi)*exp(-0.1^2/2)});
          \draw[dashed] (axis cs:2,0) -- (axis cs:2,{1/sqrt(2*pi)*exp(-0.1^2/2)});
          
          \addplot [draw=none, fill=blue!20, domain=-1:1] {1/sqrt(2*pi)*exp(-x^2/2)-0.004} \closedcycle;
          % Vertical guide line
          \draw[dashed] (axis cs:-1,0) -- (axis cs:-1,{1/sqrt(2*pi)*exp(-0.1^2/2)});
          \draw[dashed] (axis cs:1,0) -- (axis cs:1,{1/sqrt(2*pi)*exp(-0.1^2/2)});
          
          \node at (axis cs:0,0.3) {\small $68.27\%$};
          \node at (axis cs:0,0.2) {\small $95.45\%$};
          \node at (axis cs:0,0.1) {\small $99.73\%$};
          
          \draw[black] (axis cs:-3,0.07) -- (axis cs:3,0.07);
          \draw[black] (axis cs:-2,0.17) -- (axis cs:2,0.17);
          \draw[black] (axis cs:-1,0.27) -- (axis cs:1,0.27);
        \end{axis}
      \end{tikzpicture}
  \end{center}
  


\end{enumerate}



\subsection{Standard Normal Distribution:}

When $\mu = 0$ and $\sigma^2 = 1$, the Normal distribution is called the \textbf{standard normal distribution}, denoted as:
\[
Z \sim \mathcal{N}(0, 1)
\]

Its PDF becomes:
\begin{textbox}
\[
f_Z(z) = \frac{1}{\sqrt{2\pi}} \exp\left( -\frac{z^2}{2} \right)
\]
\end{textbox}


Cumulative PDF:
\begin{textbox}
$$F_Z(z) = P(Z \leq z) = \int_{-\infty}^z f_Z(t)dt$$
\end{textbox}

\vspace{2mm}

\begin{center}
\begin{tikzpicture}
      \begin{axis}[
          no markers, domain=-5:5, samples=100,
          axis lines=center,
          xlabel={$t$}, ylabel={$f_Z(t)$},
          ymin=0, ymax=0.5,
          xmin=-4, xmax=4,
          height=5cm, width=12cm,
          xtick=\empty, ytick=\empty
        ]
        % PDF curve
        \addplot [very thick, blue] {1/sqrt(2*pi)*exp(-x^2/2)};
        % Shaded right-tail for z>1.5
        \addplot [draw=none, fill=blue!20, domain=-4:1] {1/sqrt(2*pi)*exp(-x^2/2)-0.005} \closedcycle;
        % Vertical guide line
        \draw[dashed] (axis cs:1,0) -- (axis cs:1,{1/sqrt(2*pi)*exp(-1^2/2)});
        \node at (axis cs:-0.3,0.1) {\small $F_Z(z) = P(Z\leq z)$};
      \end{axis}
    \end{tikzpicture}
\end{center}

\begin{textbox}
\textbf{Theorem.} Let \( X \sim N(\mu, \sigma^2) \) be a normally distributed random variable and let \( Z \sim N(0, 1) \) be a standard normal random variable. Then, for any real number \( k \),
\[
F_X(k) = F_Z\left( \frac{k - \mu}{\sigma} \right)
\]
where \( F_X \) and \( F_Z \) denote the cumulative distribution functions of \( X \) and \( Z \), respectively.
\end{textbox}

\textbf{Proof}: Define the function
\[
z = g(x) \;=\; \frac{x - \mu}{\sigma}, 
\]
which is strictly increasing (since \(\sigma>0\)) and differentiable, with inverse
\[
g^{-1}(y) = x \;=\; \sigma z + \mu
\]
Set 
\[
Y \;=\; g(X) \;=\; \frac{X - \mu}{\sigma}
\]
Then \(Y\) has the same distribution as \(Z\), i.e.\ \(Y\sim N(0,1)\).  By the change‐of‐variable theorem for CDFs (strictly increasing case),
\[
F_Z(z)
\;=\;
P\bigl(Z \le z\bigr)
\;=\;
F_X\!\bigl(g^{-1}(z)\bigr)
\]
Hence,
\[
F_Z(z)
\;=\;
F_X\!\bigl(\sigma z + \mu\bigr)
\]
Now replace \(z\) by \(\tfrac{k-\mu}{\sigma}\).  Since
\(\sigma\cdot\tfrac{k-\mu}{\sigma} + \mu = k\), we obtain
\[
F_Z\!\left( \dfrac{k - \mu}{\sigma}\right)  = F_X(k)
\]
as required.


\hfill $\blacksquare$

Any normal random variable $X \sim \mathcal{N}(\mu, \sigma^2)$ can be converted to a \textbf{standard normal variable} using the transformation:
\[
Z = \dfrac{X - \mu}{\sigma}
\]

\begin{textbox}
\textbf{Theorem}: Let \( Z \sim N(0,1) \) be a standard normal random variable with CDF \( F_Z(z) \). Then, for any real number \( k \),
\[
F_Z(-k) = 1 - F_Z(k)
\]
\end{textbox}

Since $f_Z(z)$ is symmetrical about zero, so for any $k$
$$f_Z(-k) = f_Z(k)$$
Now,
\begin{align*}
F_Z(-k)
&= P(Z \le -k) \\
&= \int_{-\infty}^{-k} f_Z(z)dz\\
\intertext{Change variable $t=-z$, so when $z=-\infty\to t=+\infty$, and $z=-k\to t=k$, with $dz=-dt$:}
F_Z(-k) &= \int_{\infty}^{k} f_Z(-t)\,(-dt) \\
&= -\int_{\infty}^{k} f_Z(t)\,dt \\
&= \int_{k}^{\infty} f_Z(t)dt\\
&= P(Z \ge k)\\
&= 1 - P(Z < k)\\
&= 1 - F_Z(k)
\end{align*}

\hfill $\blacksquare$

\subsection{Standard Normal Table}

The \textbf{standard normal table} (or $Z$-table)  shown in Table~\ref{table:Ztable} is used to quickly find cumulative probabilities for the standard normal distribution \(Z\sim\mathcal{N}(0,1)\) without evaluating the integral $$\int_{-\infty}^z \frac{1}{\sqrt{2\pi}}e^{-t^2/2}\,dt$$ by hand.  By converting any normal random variable \(X\sim N(\mu,\sigma^2)\) into the standard form \(Z=(X-\mu)/\sigma\), one can look up probabilities such as \(P(X\le x)\) in a single, universal table, greatly simplifying calculations in statistical inference and hypothesis testing.


\begin{table}[!h]
\centering
\footnotesize
\caption{\small Standard Normal CDF values $F_Z(z)=P(Z\le z)$}
\label{table:Ztable}
\begin{tabular}{l|*{10}{r}}
\toprule
z   & 0       & 0.01    & 0.02    & 0.03    & 0.04    & 0.05    & 0.06    & 0.07    & 0.08    & 0.09    \\
\midrule
0   & 0.5     & 0.50399 & 0.50798 & 0.51197 & 0.51595 & 0.51994 & 0.52392 & 0.5279  & 0.53188 & 0.53586 \\
0.1 & 0.53983 & 0.5438  & 0.54776 & 0.55172 & 0.55567 & 0.55962 & 0.56356 & 0.56749 & 0.57142 & 0.57535 \\
0.2 & 0.57926 & 0.58317 & 0.58706 & 0.59095 & 0.59483 & 0.59871 & 0.60257 & 0.60642 & 0.61026 & 0.61409 \\
0.3 & 0.61791 & 0.62172 & 0.62552 & 0.6293  & 0.63307 & 0.63683 & 0.64058 & 0.64431 & 0.64803 & 0.65173 \\
0.4 & 0.65542 & 0.6591  & 0.66276 & 0.6664  & 0.67003 & 0.67364 & 0.67724 & 0.68082 & 0.68439 & 0.68793 \\
0.5 & 0.69146 & 0.69497 & 0.69847 & 0.70194 & 0.7054  & 0.70884 & 0.71226 & 0.71566 & 0.71904 & 0.7224  \\
0.6 & 0.72575 & 0.72907 & 0.73237 & 0.73565 & 0.73891 & 0.74215 & 0.74537 & 0.74857 & 0.75175 & 0.7549  \\
0.7 & 0.75804 & 0.76115 & 0.76424 & 0.7673  & 0.77035 & 0.77337 & 0.77637 & 0.77935 & 0.7823  & 0.78524 \\
0.8 & 0.78814 & 0.79103 & 0.79389 & 0.79673 & 0.79955 & 0.80234 & 0.80511 & 0.80785 & 0.81057 & 0.81327 \\
0.9 & 0.81594 & 0.81859 & 0.82121 & 0.82381 & 0.82639 & 0.82894 & 0.83147 & 0.83398 & 0.83646 & 0.83891 \\
1   & 0.84134 & 0.84375 & 0.84614 & 0.84849 & 0.85083 & 0.85314 & 0.85543 & 0.85769 & 0.85993 & 0.86214 \\
1.1 & 0.86433 & 0.8665  & 0.86864 & 0.87076 & 0.87286 & 0.87493 & 0.87698 & 0.879   & 0.881   & 0.88298 \\
1.2 & 0.88493 & 0.88686 & 0.88877 & 0.89065 & 0.89251 & 0.89435 & 0.89617 & 0.89796 & 0.89973 & 0.90147 \\
1.3 & 0.9032  & 0.9049  & 0.90658 & 0.90824 & 0.90988 & 0.91149 & 0.91309 & 0.91466 & 0.91621 & 0.91774 \\
1.4 & 0.91924 & 0.92073 & 0.9222  & 0.92364 & 0.92507 & 0.92647 & 0.92785 & 0.92922 & 0.93056 & 0.93189 \\
1.5 & 0.93319 & 0.93448 & 0.93574 & 0.93699 & 0.93822 & 0.93943 & 0.94062 & 0.94179 & 0.94295 & 0.94408 \\
1.6 & 0.9452  & 0.9463  & 0.94738 & 0.94845 & 0.9495  & 0.95053 & 0.95154 & 0.95254 & 0.95352 & 0.95449 \\
1.7 & 0.95543 & 0.95637 & 0.95728 & 0.95818 & 0.95907 & 0.95994 & 0.9608  & 0.96164 & 0.96246 & 0.96327 \\
1.8 & 0.96407 & 0.96485 & 0.96562 & 0.96638 & 0.96712 & 0.96784 & 0.96856 & 0.96926 & 0.96995 & 0.97062 \\
1.9 & 0.97128 & 0.97193 & 0.97257 & 0.9732  & 0.97381 & 0.97441 & 0.975   & 0.97558 & 0.97615 & 0.9767  \\
2   & 0.97725 & 0.97778 & 0.97831 & 0.97882 & 0.97932 & 0.97982 & 0.9803  & 0.98077 & 0.98124 & 0.98169 \\
2.1 & 0.98214 & 0.98257 & 0.983   & 0.98341 & 0.98382 & 0.98422 & 0.98461 & 0.985   & 0.98537 & 0.98574 \\
2.2 & 0.9861  & 0.98645 & 0.98679 & 0.98713 & 0.98745 & 0.98778 & 0.98809 & 0.9884  & 0.9887  & 0.98899 \\
2.3 & 0.98928 & 0.98956 & 0.98983 & 0.9901  & 0.99036 & 0.99061 & 0.99086 & 0.99111 & 0.99134 & 0.99158 \\
2.4 & 0.9918  & 0.99202 & 0.99224 & 0.99245 & 0.99266 & 0.99286 & 0.99305 & 0.99324 & 0.99343 & 0.99361 \\
2.5 & 0.99379 & 0.99396 & 0.99413 & 0.9943  & 0.99446 & 0.99461 & 0.99477 & 0.99492 & 0.99506 & 0.9952  \\
2.6 & 0.99534 & 0.99547 & 0.9956  & 0.99573 & 0.99585 & 0.99598 & 0.99609 & 0.99621 & 0.99632 & 0.99643 \\
2.7 & 0.99653 & 0.99664 & 0.99674 & 0.99683 & 0.99693 & 0.99702 & 0.99711 & 0.9972  & 0.99728 & 0.99736 \\
2.8 & 0.99744 & 0.99752 & 0.9976  & 0.99767 & 0.99774 & 0.99781 & 0.99788 & 0.99795 & 0.99801 & 0.99807 \\
2.9 & 0.99813 & 0.99819 & 0.99825 & 0.99831 & 0.99836 & 0.99841 & 0.99846 & 0.99851 & 0.99856 & 0.99861 \\
3   & 0.99865 & 0.99869 & 0.99874 & 0.99878 & 0.99882 & 0.99886 & 0.99889 & 0.99893 & 0.99896 & 0.999   \\
3.1 & 0.99903 & 0.99906 & 0.9991  & 0.99913 & 0.99916 & 0.99918 & 0.99921 & 0.99924 & 0.99926 & 0.99929 \\
3.2 & 0.99931 & 0.99934 & 0.99936 & 0.99938 & 0.9994  & 0.99942 & 0.99944 & 0.99946 & 0.99948 & 0.9995  \\
3.3 & 0.99952 & 0.99953 & 0.99955 & 0.99957 & 0.99958 & 0.9996  & 0.99961 & 0.99962 & 0.99964 & 0.99965 \\
3.4 & 0.99966 & 0.99968 & 0.99969 & 0.9997  & 0.99971 & 0.99972 & 0.99973 & 0.99974 & 0.99975 & 0.99976 \\
3.5 & 0.99977 & 0.99978 & 0.99978 & 0.99979 & 0.9998  & 0.99981 & 0.99981 & 0.99982 & 0.99983 & 0.99983 \\
3.6 & 0.99984 & 0.99985 & 0.99985 & 0.99986 & 0.99986 & 0.99987 & 0.99987 & 0.99988 & 0.99988 & 0.99989 \\
3.7 & 0.99989 & 0.9999  & 0.9999  & 0.9999  & 0.99991 & 0.99991 & 0.99992 & 0.99992 & 0.99992 & 0.99992 \\
3.8 & 0.99993 & 0.99993 & 0.99993 & 0.99994 & 0.99994 & 0.99994 & 0.99994 & 0.99995 & 0.99995 & 0.99995 \\
3.9 & 0.99995 & 0.99995 & 0.99996 & 0.99996 & 0.99996 & 0.99996 & 0.99996 & 0.99996 & 0.99997 & 0.99997 \\
4   & 0.99997 & 0.99997 & 0.99997 & 0.99997 & 0.99997 & 0.99997 & 0.99998 & 0.99998 & 0.99998 & 0.99998 \\
\addlinespace
\bottomrule
\end{tabular}
\end{table}

To look up \(F_Z(k)\), follow the following steps:

\begin{enumerate}
  \item Write \(k\) to \textbf{two decimal places}, e.g.\ \(k=1.23\).
  \item Split into
    \[
      \text{row part} = 1.2,\quad
      \text{column part} = 0.03
    \]
  \item In Table~\ref{table:Ztable}, go to the row labeled “1.2” and the column
    labeled “0.03”.  The entry at their intersection is
    \[
      F_Z(1.23) = P(Z\le 1.23) \;=\; 0.89065
    \]
  \item For negative \(z\), use symmetry:
    \[
      F_Z(-k) = P(Z\le -k)
      = 1 - P(Z\le k) = 1 - F_Z(k)
    \]
  \item For right‐tail probabilities,
    \[
      P(Z>k) = 1 - F_Z(k)
    \]
  \item For probabilities within a specified interval of $ Z $ values,
  $$P(k_1 \leq Z \leq k_2) = P(Z \leq k_2) - P(Z \leq k_1) = F_Z(k_2) - F_Z(k_1)$$
\end{enumerate}

\textbf{Example:} Suppose the heights of adult males are normally distributed with mean $\mu = 175$ cm and standard deviation $\sigma = 10$ cm. Let $X$ denote the height of a randomly chosen male. Then:
\[
X \sim \mathcal{N}(175, 100)
\]

What is the probability that a randomly chosen male is taller than 190 cm?

We standardize:
\[
Z = \frac{190 - 175}{10} = 1.5
\]

Using the standard normal table:
\[
P(X > 190) = P(Z > 1.5) = 1 - F_Z(1.5) \approx 1 - 0.9332 = 0.0668
\]

Thus, approximately $6.68\%$ of adult males are taller than 190 cm.


% \begin{table}[!h]
%   \centering
%   \footnotesize
%   \caption{Standard Normal CDF values $F_Z(z)=P(Z\le z)$.}
%   \label{tab:Ztable}
%   \begin{tabular}{l|*{10}{r}}
%     \toprule
%     $z$ & 0    & 0.01  & 0.02  & 0.03  & 0.04  & 0.05  & 0.06  & 0.07  & 0.08  & 0.09  \\ 
%     \midrule
%     0.0 & 0.5000 & 0.50399 & 0.50798 & 0.51197 & 0.51595 & 0.51994 & 0.52392 & 0.52790 & 0.53188 & 0.53586 \\
%     0.1 & 0.53983 & 0.54380 & 0.54776 & 0.55172 & 0.55567 & 0.55962 & 0.56356 & 0.56749 & 0.57142 & 0.57535 \\
%     0.2 & 0.57926 & 0.58317 & 0.58706 & 0.59095 & 0.59483 & 0.59871 & 0.60257 & 0.60642 & 0.61026 & 0.61409 \\
%     0.3 & 0.61791 & 0.62172 & 0.62552 & 0.62930 & 0.63307 & 0.63683 & 0.64058 & 0.64431 & 0.64803 & 0.65173 \\
%     0.4 & 0.65542 & 0.65910 & 0.66276 & 0.66640 & 0.67003 & 0.67364 & 0.67724 & 0.68082 & 0.68439 & 0.68793 \\
%     0.5 & 0.69146 & 0.69497 & 0.69847 & 0.70194 & 0.70540 & 0.70884 & 0.71226 & 0.71566 & 0.71904 & 0.72240 \\
%     0.6 & 0.72575 & 0.72907 & 0.73237 & 0.73565 & 0.73891 & 0.74215 & 0.74537 & 0.74857 & 0.75175 & 0.75490 \\
%     0.7 & 0.75804 & 0.76115 & 0.76424 & 0.76730 & 0.77035 & 0.77337 & 0.77637 & 0.77935 & 0.78230 & 0.78524 \\
%     0.8 & 0.78814 & 0.79103 & 0.79389 & 0.79673 & 0.79955 & 0.80234 & 0.80511 & 0.80785 & 0.81057 & 0.81327 \\
%     0.9 & 0.81594 & 0.81859 & 0.82121 & 0.82381 & 0.82639 & 0.82894 & 0.83147 & 0.83398 & 0.83646 & 0.83891 \\
%     1.0 & 0.84134 & 0.84375 & 0.84614 & 0.84849 & 0.85083 & 0.85314 & 0.85543 & 0.85769 & 0.85993 & 0.86214 \\
%     1.1 & 0.86433 & 0.86650 & 0.86864 & 0.87076 & 0.87286 & 0.87493 & 0.87698 & 0.87900 & 0.88100 & 0.88298 \\
%     1.2 & 0.88493 & 0.88686 & 0.88877 & 0.89065 & 0.89251 & 0.89435 & 0.89617 & 0.89796 & 0.89973 & 0.90147 \\
%     1.3 & 0.90320 & 0.90490 & 0.90658 & 0.90824 & 0.90988 & 0.91149 & 0.91309 & 0.91466 & 0.91621 & 0.91774 \\
%     1.4 & 0.91924 & 0.92073 & 0.92220 & 0.92364 & 0.92507 & 0.92647 & 0.92785 & 0.92922 & 0.93056 & 0.93189 \\
%     1.5 & 0.93319 & 0.93448 & 0.93574 & 0.93699 & 0.93822 & 0.93943 & 0.94062 & 0.94179 & 0.94295 & 0.94408 \\
%     \addlinespace
%     \bottomrule
%   \end{tabular}
% \end{table}

\begin{figure}[!h]
  \centering
  \begin{tikzpicture}
    \begin{axis}[
        no markers, domain=-6:6, samples=100,
        axis lines=center,
        xlabel={$z$}, ylabel={$f_Z(z)$},
        ymin=0, ymax=0.5,
        xmin=-5, xmax=5,
        height=5cm, width=14cm,
        xtick={-3,-2,-1,0,1,1.5,2,3},
        ytick=\empty
      ]
      % PDF curve
      \addplot [very thick, blue] {1/sqrt(2*pi)*exp(-x^2/2)};
      % Shaded right-tail for z>1.5
      \addplot [draw=none, fill=blue!30, domain=1.5:4] {1/sqrt(2*pi)*exp(-x^2/2)-0.005} \closedcycle;
      % Vertical guide line
      \draw[dashed] (axis cs:1.5,0) -- (axis cs:1.5,{1/sqrt(2*pi)*exp(-1.5^2/2)});
      \node at (axis cs:3,0.1) {\small $P(Z>1.5)=0.0668$};
    \end{axis}
  \end{tikzpicture}
\end{figure}



\chapter{Sampling Theory}
\section{Introduction}
Sampling theory is a part of statistics that helps us understand how to learn about a large group by looking at just a small part of it. For example, imagine a company makes a new type of battery and wants to know how long the batteries last. Testing every single battery would take too much time and money, so the company picks a few batteries to test. These few batteries are called a \textbf{sample}, and all the batteries made by the company are called the \textbf{population}. 

The company really wants to know the average lifetime of all batteries—this is called a \textbf{parameter}. But since they can’t test them all, they use the average lifetime from the sample—this is called a \textbf{statistic}. 

Sampling theory helps us understand how close this statistic is likely to be to the real average. It also helps us decide how many batteries to test and how to choose them so we get useful, reliable results.

\begin{textbox}
    \textbf{Population}: The entire group of individuals or items that we want to learn about.
    Example: All the batteries produced by a company.
    
    \vspace{3mm}
    \textbf{Sample}: A smaller group taken from the population, which is actually tested or studied.
    Example: 100 batteries chosen from the whole production batch.
    
    \vspace{3mm}
    \textbf{Parameter}: A numerical value that describes a characteristic of the population (usually unknown).
    Example: The true average lifetime of all the batteries.
    
    \vspace{3mm}
    \textbf{Statistic}: A numerical value that describes a characteristic of the sample (used to estimate the parameter).
    Example: The average lifetime of the 100 batteries tested.
\end{textbox}

\section{Sampling Methods}

\subsection{Simple Random Sampling}

\begin{textbox}
A \textbf{simple random sampling} is one in which every member of the population has an equal chance of being selected in the sample.
\end{textbox}
 Mathematically, this means that each possible sample of size $n$ from a population has the same probability of being chosen. For example, suppose a factory produces 10,000 batteries in a day. To estimate the average lifespan, 100 batteries are selected randomly so that each battery has the same chance of inclusion. An important advantage of simple random sampling is that it is straightforward to analyze using statistical theory, which makes inference about the population simpler

In this text, we will limit our discussion to \textbf{simple random sampling}.  Before a random sample of size $n$ is selected, the observations are modeled as the random variables $X_1 , X_2, \dots , X_n$. For example, if we randomly select 5 light bulbs from a production batch, their lifespans can be represented by the random variables \( X_1, X_2, X_3, X_4, X_5 \), each denoting the lifespan (in hours) of a selected bulb.

\begin{align*}
    X_1 &= \text{Lifespan (in hours) of 1st selected bulb} \\
    X_2 &= \text{Lifespan (in hours) of 2nd selected bulb} \\
    &\dots \\
    X_5 &= \text{Lifespan (in hours) of 5th selected bulb}
\end{align*}


Assume a first draw yields the following lifespans (in hours) for \(n = 5\) randomly selected light bulbs:
\[
\text{Draw 1:} \quad \{X_1=1200, X_2=1140, X_3=1180, X_4=1300, X_5=1250\}
\]

Because each sample is chosen at random, a fresh draw of five bulbs would almost surely yield different numerical values for \(X_1, X_2, \dots, X_5\). Assume a second draw produces:
\[
\text{Draw 2:} \quad \{X_1=1400, X_2=1550, X_3=1200, X_4=1420, X_5=1380\}
\]

In this way, each \(X_i\) behaves as a genuine random variable, capturing the uncertainty inherent in the sampling process.

There are two main types of simple random sampling:

\begin{enumerate}
    \item \textbf{Simple Random Sampling With Replacement (SRSWR)}: This is a method of selecting a sample of size \( n \) from a population of size \( N \) one by one such that after each stage of selection, the element is returned to the population before the next draw. Because each selection is made from the full population, the sample observations \( X_1, X_2, \dots, X_n \) are \textit{independent and identically distributed (i.i.d.)}\footnote{%
    \textbf{Independent and Identically Distributed (i.i.d.)} is a fundamental assumption in statistics. \textit{Identically distributed} means that each random variable \( X_i \) follows the same probability distribution (e.g., normal, binomial). \textit{Independent} means the outcome of one observation does not influence or provide information about the others; knowing \( X_1 \) gives no information about \( X_2, X_3, \) etc.
} random variables following the population distribution.
    
    \item \textbf{Simple Random Sampling Without Replacement (SRSWOR)}: This is a method of selecting a sample of size \( n \) from a population of size \( N \) one by one such that after each stage of selection, the element is not returned to the population. So there is no chance of a particular item being selected twice in the sample. Although the sample observations \( X_1, X_2, \dots, X_n \) are identically distributed (each has the same marginal distribution), they are \textit{not independent}, due to the changing composition of the population after each draw.
\end{enumerate}


\subsection{Other Sampling Methods}

\begin{enumerate}
    \item \textbf{Stratified Sampling}: In stratified sampling, the population is divided into distinct subgroups or strata based on a specific characteristic (e.g., age, income, region), and a random sample is drawn from each stratum. This method ensures representation from all key subgroups.

\textit{Example:} A company wants to sample employee opinions. Employees are divided into departments (e.g., HR, Sales, R\&D), and a random sample is taken from each department.

\textit{Advantages:} Increases accuracy by reducing variability; ensures important groups are represented.  

\textit{Disadvantages:} Requires knowledge of strata and population characteristics in advance.

\item \textbf{Systematic Sampling}: Systematic sampling selects every $k$-th individual from a population list after a random starting point. The interval $k$ is calculated by dividing the population size by the desired sample size.

\textit{Example:} If a company has a list of 1,000 employees and wants to survey 100, it selects a random starting point between 1 and 10, then picks every 10th employee on the list.

\textit{Advantages:} Simple and quick to implement; useful when population is ordered.  

\textit{Disadvantages:} Can introduce bias if there is a hidden pattern in the population that coincides with the sampling interval.

\item \textbf{Cluster Sampling}: In cluster sampling, the population is divided into clusters (often based on geography or natural groupings). A few clusters are randomly selected, and then all individuals within those clusters are included in the sample.

\textit{Example:} A research team wants to survey households in a city. The city is divided into neighborhoods (clusters), a few neighborhoods are selected at random, and all households in those neighborhoods are surveyed.

\textit{Advantages:} Cost-effective and practical for large, dispersed populations.  

\textit{Disadvantages:} Can lead to higher sampling error if clusters are not homogeneous.

\item \textbf{Multistage Sampling}: Multistage sampling combines several sampling techniques. Typically, it begins with cluster sampling to select large groups, and then simple random or stratified sampling is used within those groups.

\textit{Example:} In a national education survey, schools are randomly selected (cluster sampling), then students within each selected school are randomly chosen (simple random sampling).

\textit{Advantages:} Flexible and practical for large-scale surveys; reduces cost and time.  

\textit{Disadvantages:} More complex design and analysis; potential for increased sampling error if stages are not carefully planned.
\end{enumerate}

\section{Sample Mean, Sample Variance and Sample Proportion}

Let \( X_1, X_2, \dots, X_n \) be a random sample of size \( n \) drawn from a population which are modeled as random variables. The \textbf{sample mean} is defined as:
\begin{textbox}
     \[
\text{Sample Mean} = \overline{X} = \frac{1}{n} \sum_{i=1}^{n} X_i
\]
\end{textbox}
It represents the average of the observed sample values.

The \textbf{sample variance} is defined as:
\begin{textbox}
\[
\text{Sample Variance} = S^2 = \frac{1}{n - 1} \sum_{i=1}^{n} (X_i - \overline{X})^2
\]
\end{textbox}
This measures the spread or variability of the sample values around the sample mean. The denominator \( n - 1 \) (instead of \( n \)) ensures that \( S^2 \) is an \emph{unbiased estimator} of the population variance \( \sigma^2 \). We will discussed the concept of unbiased estimator in later chapter.

The \textbf{sample standard deviation} is the positive square root of the sample variance:
\begin{textbox}
\[
\text{Sample Standard Deviation} = S = \sqrt{\frac{1}{n - 1} \sum_{i=1}^{n} (X_i - \overline{X})^2}
\]
\end{textbox}

Now let's suppose \( X_i \) is modeled as a binary indicator variable where

\[
X_i = \begin{cases}
1, & \text{if the } i\text{-th observation has the characteristic of interest} \\
0, & \text{otherwise}
\end{cases}
\]

The \textbf{sample proportion} for the the characteristic of interest is defined as:
\begin{textbox}
\[
\text{Sample Proportion} = \hat{p} = \frac{1}{n} \sum_{i=1}^n X_i = \frac{X}{n}
\]
\end{textbox}

It represents the fraction of the sample exhibiting the characteristic of interest and serves as an estimator of the population proportion \( p \).



\section{Sampling Distributions}
The value of any statistic (e.g. sample mean) will vary from sample to sample.
\begin{textbox}
The \textbf{sampling distribution} of a statistic is the probability distribution of the statistic's values computed from all possible random samples of the same size taken from a given population.
\end{textbox}

Suppose a factory produces thousands of batteries, and the lifetimes of these batteries follow a distribution with a population mean \( \mu = 100 \) hours and a population standard deviation \( \sigma = 20 \) hours.

Now, imagine taking a random sample of 5 batteries and computing the average lifetime (sample mean). You repeat this process many times—each time taking a new random sample of 5 batteries and calculating its mean. Each of these sample means will be a bit different due to natural variation in the samples. If you plot all these sample means on a graph, the result is the \textbf{sampling distribution of the sample mean}.

The standard deviation of the sampling distribution of a statistic is given a specific name — it is called the \textbf{standard error} of that sample statistic.

\begin{textbox}
The \textbf{standard error} of a sample statistic is the standard deviation of its sampling distribution. It measures how much the statistic is expected to vary from sample to sample due to random chance.
\end{textbox}

\section{The Sampling Distribution of the Sample Mean}

\begin{textbox}
\textbf{Theorem}: Let $X_1 , X_2, \dots , X_n$ be random samples of size $n$ \textit{chosen with replacements} from a population with mean $\mu$ and variance $\sigma^2$, then
$$\mathbb{E}(\overline{X}) = \mu,  \text{ and } \mathrm{Var}(\overline{X}) = \dfrac{\sigma^2}{n}$$
\end{textbox}
% This theorem is also true when the population size in infinite.

\textbf{Proof}: We assume the population consists of $N$ elements $\{y_1, y_2, \dots, y_N\}$. The population mean and population variance are defined as:

$$\mu = \dfrac{1}{N}\sum_{j=1}^N y_j, \quad \sigma^2 = \dfrac{1}{N}\sum_{j=1}^N (y_j - \mu)^2$$

The sample mean is defined as:
\[
\overline{X} = \frac{1}{n} \sum_{i=1}^{n} X_i
\]

By the linearity of expectation:
\[
\mathbb{E}(\overline{X}) = \mathbb{E}\left( \frac{1}{n} \sum_{i=1}^{n} X_i \right) = \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}(X_i)
\]

Since each \( X_i \) is drawn from the population $\{y_1, y_2, \dots, y_N\}$ each with probability $\dfrac{1}{N}$. Hence, we have for all $i$:
\[
\mathbb{E}(X_i) = \sum_{j=1}^N y_j \cdot \underbrace{(X_i = y_j)}_{1/N}
 = \dfrac{1}{N}\sum_{j=1}^N y_j  = \mu
\]

So:
\[
\mathbb{E}(\overline{X}) = \frac{1}{n} \cdot n \cdot \mu = \mu
\]

Using the formula for the variance of a sum of independent random variables:
\[
\mathrm{Var}(\overline{X}) = \mathrm{Var} \left( \frac{1}{n} \sum_{i=1}^{n} X_i \right) = \frac{1}{n^2} \sum_{i=1}^{n} \mathrm{Var}(X_i)
\]
Now,
$$\mathrm{Var}(X_i) = \sum_{j=1}^N (y_j - \mu)^2 \cdot \underbrace{P(X_i = y_j)}_{1/N} = \dfrac{1}{N}\sum_{j=1}^N (y_j - \mu)^2 = \sigma^2$$
Therefore,
\[
\mathrm{Var}(\overline{X}) = \frac{1}{n^2} \cdot n \cdot \sigma^2 = \frac{\sigma^2}{n}
\]


% \[
% \therefore \quad \mathbb{E}(\overline{X}) = \mu \quad \text{and} \quad \mathrm{Var}(\overline{X}) = \frac{\sigma^2}{n} 
% \]

\hfill $\blacksquare$

\begin{textbox}
\textbf{Theorem}: Let $X_1 , X_2, \dots , X_n$ be random samples of size $n$ \textit{chosen without replacement} from a population of size $N$ with mean $\mu$ and variance $\sigma^2$, then
$$\mathbb{E}(\overline{X}) = \mu,  \text{ and } \mathrm{Var}(\overline{X}) = \dfrac{\sigma^2}{n}\left(\dfrac{N-n}{N-1}\right)$$
\end{textbox}

We skip the proof as it is beyond the scope of this text. The term $$\frac{N-n}{N-1}$$ is often called \textbf{finite population correction factor}, is close to 1 (and can be omitted for most practical purposes) unless the sample constitutes a substantial portion
of the population.

% \textbf{Proof}: By definition of sample mean:
% $$\overline{X} = \frac{1}{n} \sum_{i=1}^n X_i$$
% By the linearity of expectation:
% \[
% \mathbb{E}(\overline{X}) = \mathbb{E}\left( \frac{1}{n} \sum_{i=1}^{n} X_i \right) = \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}(X_i)
% \]
% First we need to find out the value of $\mathbb{E}(X_i)$. To do that, let us fix any population value $y_j$ and define the event
% $$
% H = \{\text{$y_j$ not among }X_1,\dots,X_{i-1}\},
% $$
% and its complement $\overline{H}$.  By the law of total probability,
% \[
% P(X_i=y_j)
% = P(X_i=y_j\mid H)\,P(H)
%   + P(X_i=y_j\mid \overline{H})\,P(\overline{H}).
% \]
% - If $\overline{H}$ occurs, then $y_j$ was already drawn, so $P(X_i=y_j\mid \overline{H})=0$.

% - If $H$ occurs, there are $N-(i-1)$ items left each with probability $\dfrac{1}{N-(i-1)}$ of being selected. So
%   $$P(X_i=y_j\mid H)=\frac{1}{N-(i-1)}.
%   $$

% By symmetry, the probability $y_j$ survives the first $i-1$ draws is
%   \begin{align*}
%       P(H)&=\frac{\text{Num of ways }i-1\text{ items can be selected from }N-1\text{ items which excludes }y_j}{\text{Num of ways }i-1\text{ items can be selected from }N\text{ items}} \\
%   &= \frac{\binom{N-1}{i-1}}{\binom{N}{i-1}}=\frac{N-i+1}{N}
%   \end{align*}
% Putting these together,
% \[
% P(X_i=y_j)
% = \frac{1}{N-(i-1)}\cdot\frac{N-i+1}{N}
% = \frac{1}{N},
% \]
% and thus
% \[
% \mathbb{E}(X_i)
% = \sum_{j=1}^N y_j\,P(X_i=y_j)
% = \frac{1}{N}\sum_{j=1}^N y_j
% = \mu.
% \]
% By linearity, $\mathbb{E}(\overline{X})=\mu$.

% Let us now calculate the variance. Since draws are dependent without replacement, we must account for
% covariances. Recall:
% \begin{align*}
% \mathrm{Var}(\overline{X}) &= \mathrm{Var}\left(\frac{1}{n} \sum_{i=1}^{n} X_i\right) = \frac{1}{n^2} \mathrm{Var}\left(\sum_{i=1}^n X_i\right) \\
% &= \frac{1}{n^2} \Bigl(\sum_{i=1}^n \mathrm{Var}(X_i) + 2\sum_{1 \le i < k \le n} \mathrm{Cov}(X_i, X_k)\Bigr)
% \end{align*}

% - For each $i$, as in the with-replacement case,
% $$
% \mathrm{Var}(X_i) = \sigma^2
% $$

% - For $i \neq k$, the covariance of two distinct draws satisfies (see e.g. properties of simple random sampling)
% $$
% \mathrm{Cov}(X_i, X_k) = -\frac{\sigma^2}{N - 1}.
% $$
% (One way to show this is to use the fact that the sum of all $N$ sample indicators is fixed at $n$, giving negative dependence.)

% Substituting into the variance formula,
% \begin{align*}
% \mathrm{Var}(\overline{X})
% &= \frac{1}{n^2} \Bigl(n\sigma^2 + 2\binom{n}{2} \Bigl(-\frac{\sigma^2}{N - 1}\Bigr)\Bigr) \\[6pt]
% &= \frac{1}{n^2} \Bigl(n\sigma^2 - n(n - 1)\frac{\sigma^2}{N - 1}\Bigr) \\[6pt]
% &= \frac{\sigma^2}{n}\Bigl(1 - \frac{n - 1}{N - 1}\Bigr) \\[4pt]
% &= \frac{\sigma^2}{n} \cdot \frac{(N - 1) - (n - 1)}{N - 1} \,=\, \frac{\sigma^2}{n} \cdot \frac{N - n}{N - 1}
% \end{align*}

\subsection{Sampling from a Normal Distribution}
In the preceding discussion, no specific assumptions were made about the actual distribution of the population from which the observations \( X_1, X_2, \dots, X_n \) were sampled. Nevertheless, we know two key characteristics of the sampling distribution of the sample mean \( \overline{X} \):
\begin{itemize}
    \item Its expected value: \( \mathbb{E}(\overline{X}) \)
    \item Its variance: \( \mathrm{Var}(\overline{X})\)
\end{itemize}
But what about the shape of the sampling distribution? If the population itself is normally distributed, then the sampling distribution of \( \overline{X} \) is also normal, regardless of the sample size.

\begin{textbox}
\textbf{Theorem}: When sampling is done from a normal distribution with mean \( \mu \) and standard deviation \( \sigma \), the sample mean \( \overline{X} \) follows a normal distribution:
\[
\overline{X} \sim \mathcal{N}\left(\mu, \frac{\sigma^2}{n}\right)
\]
\end{textbox}
\textbf{Proof}: Let \( X_1, X_2, \dots, X_n \overset{\text{iid}}{\sim} \mathcal{N}(\mu, \sigma^2) \) be a random sample of size \( n \) from a normal population with mean \( \mu \) and variance \( \sigma^2 \). Define the sample mean as:
\[
\overline{X} = \frac{1}{n} \sum_{i=1}^{n} X_i
\]

Since each \( X_i \) is normally distributed and is independent, the sample mean \( \overline{X} \) is a linear combination of independent normal random variables:
\[
\overline{X} = \frac{1}{n} X_1 + \frac{1}{n} X_2 + \dots + \frac{1}{n} X_n
\]
A linear combination of independent normal variables is also normally distributed. Therefore, \( \overline{X} \sim \mathcal{N}(\mathbb{E}(\overline{X}), \mathrm{Var}(\overline{X}) \).

From the previous theorem, we already know,
\[
\mathbb{E}[\overline{X}] = \mu \quad \text{and} \quad \mathrm{Var}(\overline{X}) = \frac{\sigma^2}{n}
\]
Thus we conclude:
\[
\overline{X} \sim \mathcal{N}\left( \mu, \frac{\sigma^2}{n} \right)
\]

\hfill $\blacksquare$
\subsection{Central Limit Theorem (CLT)}
In the previous section, we saw that when we are sampling from a normal distribution, $X$ is also normally distributed. However, there are many situations where we cannot determine the exact form of the distribution of
$X$. In such circumstances, we may appeal to the central limit theorem and obtain an approximate distribution.

\begin{textbox}
\textbf{Central Limit Theorem}: If $\overline{X}$ is the mean of a random sample of size $n$ taken from a population having the mean $\mu$ and the finite variance $\sigma^2$, then $\overline{X}$ approximately follows $\mathcal{N}\left(\mu, \dfrac{\sigma^2}{n}\right)$ as $n \to \infty$. 

In other words, the statistic
$$\dfrac{\overline{X}-\mu}{\frac{\sigma}{\sqrt{n}}}$$
is a random variable whose distribution function approaches to that of the standard normal distributions as $n \to \infty$.
\end{textbox}
\textbf{Proof}: Let $X_1, X_2, \dots, X_n$ be independent and identically distributed (i.i.d.) random variables with mean $\mu = \mathbb{E}[X_i]$ and variance $\sigma^2 = \text{Var}(X_i) < \infty$. Define the standardized sum:
\[
Z_n = \frac{\overline{X}_n - \mu}{\sigma / \sqrt{n}} = \frac{1}{\sqrt{n}} \sum_{i=1}^n \left( \frac{X_i - \mu}{\sigma} \right)
\]
Then, as $n \to \infty$, we have to prove\footnote{The notation \( Z_n \xrightarrow{d} Z \) (read as ``converges in distribution'') means: the distribution of a sequence of random variables \( Z_n \) converges to the distribution of another random variable \( Z \).}
\[
Z_n \xrightarrow{d} \mathcal{N}(0,1)
\]


Now define
\[
Y_i = \frac{X_i - \mu}{\sigma}
\quad \text{so that} \quad \mathbb{E}[Y_i] = 0, \quad \text{Var}(Y_i) = 1
\]
Then we can write:
\[
Z_n = \frac{1}{\sqrt{n}} \sum_{i=1}^n Y_i
\]

Let $M_Y(t)$ be the moment generating function (MGF) of $Y_i$. Then, since $Y_1, \dots, Y_n$ are i.i.d., the MGF of $Z_n$ is:
\[
M_{Z_n}(t) = \mathbb{E}\left[ e^{t Z_n} \right] = \left( M_Y\left( \frac{t}{\sqrt{n}} \right) \right)^n
\]

Using a Taylor expansion of $M_Y(t)$ around $t = 0$, we have:
\[
M_Y(t) = 1 + \frac{t^2}{2} + \frac{\kappa_3 t^3}{6} + \cdots
\]
where $\kappa_3$ is the third central moment of $Y_i$.

Substituting $t / \sqrt{n}$ into this expansion:
\[
M_Y\left( \frac{t}{\sqrt{n}} \right)
= 1 + \frac{t^2}{2n} + \frac{\kappa_3 t^3}{6 n^{3/2}} + o\left( \frac{1}{n} \right)
\]

Therefore,
\[
M_{Z_n}(t) = \left( 1 + \frac{t^2}{2n} + o\left( \frac{1}{n} \right) \right)^n
\xrightarrow{n \to \infty} e^{t^2 / 2}
\]

But $e^{t^2/2}$ is the MGF of the standard normal distribution $\mathcal{N}(0,1)$. By the uniqueness theorem for MGFs, this implies:
\[
Z_n \xrightarrow{d} \mathcal{N}(0,1)
\]
\hfill$\blacksquare$

The Central Limit Theorem says that even if the population distribution is not normal, the sampling distribution of the sample mean will be approximately normal when the sample size is sufficiently large.

A common question is ``how large does n have to be before the normality of $\overline{X}$ is reasonable?'' The answer
depends on the degree of non-normality of the underlying distribution from which the sample has been drawn.
The more non-normal the population distribution is, the larger $n$ needs to be.
\begin{textbox}
A useful \textbf{rule-of-thumb} is that $n$ should be at least 30 for the central limit theorem to take effect.
\end{textbox}

% \begin{center}
% \begin{tikzpicture}
% \draw[->] (-0.5,0) -- (5,0) node[right] {Sample Mean};
% \draw[->] (0,-0.5) -- (0,3) node[above] {Frequency};
% \draw[scale=1,domain=0:5,smooth,variable=\x,blue,thick] plot ({\x},{2*exp(-((\x-2.5)^2)/0.5)});
% \end{tikzpicture}
% \end{center}

If the number of observations \( n \) increases, the expected value of the sample mean \( \overline{X} \) remains fixed at \( \mu \), but its variance decreases, approaching zero. In other words,

\[
\mathrm{Var}(\overline{X}) = \mathbb{E}\left[(\overline{X} - \mu)^2\right] \to 0 \quad \text{as} \quad n \to \infty.
\]

This means the sample mean \( \overline{X} \) converges to \( \mu \) in mean square, since the average squared deviation from the true mean diminishes with larger samples. This result represents one form of the \textbf{Law of Large Numbers (LLN)}, which formalizes the idea that

\[
\overline{X} \to \mu \quad \text{as} \quad n \to \infty.
\]

Together with the Central Limit Theorem, the Law of Large Numbers assures us that the sample mean not only becomes approximately normally distributed but also increasingly concentrates around the true mean \( \mu \).

\subsection{The Sampling Distribution of the Sample Mean When $\sigma$ is Unknown}
In the preceding subsections, we assume that the population variance $\sigma^2$ is known. If $n$ is large, this does not pose any problems even when $\sigma$ is unknown, as it is reasonable in that case to substitute for it the sample standard deviation $S$. However, for small sample sizes, the distribution of the sample mean $\overline{X}$ is not known unless we assume that the  sample comes from a normal population. Under this assumption, one can prove the following:

\begin{textbox}
\textbf{Theorem}: Let \( \overline{X} \) be the sample mean of a random sample of size \( n \) drawn from a normal population with mean \( \mu \). Define the sample variance as

\[
S^2 = \frac{1}{n - 1} \sum_{i=1}^n (X_i - \overline{X})^2.
\]

Then the statistic (standardized sample mean)

\[
t = \frac{\overline{X} - \mu}{S / \sqrt{n}}
\]

follows a \textbf{t-distribution} with \( \nu = n - 1 \) degrees of freedom.

\end{textbox}

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    domain=-5:5,
    samples=200,
    axis lines=middle,
    xlabel={$x$},
    ylabel={$f(x)$},
    legend style={at={(1.07,0.95)}, anchor=north east},
    % grid=both,
    width=12cm,
    height=6cm,
    xtick={-4,-2,0,2,4},
    ytick=\empty,
    enlargelimits=upper,
    clip=false
]

% t-distribution with 5 degrees of freedom
% Formula: Gamma((ν+1)/2) / [sqrt(νπ) * Gamma(ν/2)] * (1 + x^2/ν)^{- (ν+1)/2}
% For ν = 5:
\addplot [blue, very thick] {0.37960669 * (1 + x^2 / 5)^(-3)};
\addlegendentry{\( t \)-distribution, \( \nu = 5 \)}

% Standard normal distribution: 1/sqrt(2pi) * e^{-x^2 / 2}
\addplot [red, dashed, very thick] {1/sqrt(2*pi) * exp(-x^2/2)};
\addlegendentry{Standard Normal \( \mathcal{N}(0,1) \)}


\end{axis}
\end{tikzpicture}
\end{center}
As illustrated in the figure above, the overall shape of the \( t \)-distribution closely resembles that of the standard normal distribution: both are bell-shaped and symmetric about the mean. Like the standard normal distribution, the \( t \)-distribution has a mean of 0. However, its variance depends on the parameter \( \nu \), known as the \textbf{degrees of freedom}. The variance of the \( t \)-distribution is greater than 1 but decreases as \( \nu \) increases, approaching 1 in the limit. 

\begin{textbox}
The \( t \)-distribution with \( \nu \) degrees of freedom converges to the standard normal distribution as \( \nu \to \infty \). As a general rule of thumb, the standard normal distribution provides a good approximation to the \( t \)-distribution when the sample size is 30 or larger.
\end{textbox}


\begin{center}
\begin{tikzpicture}
  \begin{axis}[
    domain=-3.5:3.5,
    samples=100,
    axis lines=middle,
    xlabel={$t$},
    width=8cm, height=4.5cm,
    ymin=0, ymax=0.5,
    xtick=\empty,
    ytick=\empty,
    tick style={draw=none},
    clip=false,
  ]
    % Full t_5 PDF curve
    \addplot [very thick, blue] {0.379*(1 + x^2/5)^(-3)};
    
    % Shaded right tail beyond t_{0.05} ≈ 2.015
    \addplot [
      domain=2.015:3.5,
      samples=100,
      draw=none,
      fill=red!30
    ] {0.379*(1 + x^2/5)^(-3)} \closedcycle;
    
    % Vertical line at t_{0.05}
    \addplot [red, dashed, thick] coordinates
      {(2.015,0) (2.015,{0.379*(1 + 2.015^2/5)^(-3)})};
    
    % Annotations
    \node[red!60!black, below] at (axis cs:2.015,0) {\(\displaystyle t_{\alpha, \nu}\)};
    \node[red!60!black] at (axis cs:2.5,0.07) {\(\alpha\)};
  \end{axis}
\end{tikzpicture}
\end{center}

The critical point \(t_{\alpha, \nu}\) is defined so that the area to its right under the \(t\)-distribution with \(\nu\) degrees of freedom equals \(\alpha\) i.e.  
$$P\left(t > t_{\alpha, \nu} \right)= \alpha$$

By symmetry,  
\[
t_{1-\alpha, \nu} = -\,t_{\alpha, \nu}
\]  
So the critical point for a left‐tail area of \(\alpha\) is \(-t_{\alpha, \nu}\).

\textbf{Example}: Suppose we take a random sample of \( n = 10 \) measurements of battery lifespans (in hours) from a normally distributed population. The data are:

\[
\{42,\ 38,\ 41,\ 39,\ 40,\ 37,\ 44,\ 36,\ 38,\ 40\}
\]

We want to estimate the population mean \( \mu \) and test whether the mean battery life is significantly different from 40 hours.

This is a case where the population standard deviation \( \sigma \) is unknown, so we use the sample standard deviation \( S \), and apply the following test statistic:

\[
t = \frac{\overline{X} - \mu_0}{S / \sqrt{n}}
\]

where:
\begin{itemize}
  \item \( \overline{X} \) is the sample mean,
  \item \( S \) is the sample standard deviation,
  \item \( \mu_0 = 40 \) is the hypothesized population mean,
  \item \( n = 10 \) is the sample size.
\end{itemize}

The statistic \( t \) follows a \( t \)-distribution with \( \nu = n - 1 = 9 \) degrees of freedom under the assumption that the population is normal.

Sample mean:

\[
\overline{X} = \frac{1}{10} (42 + 38 + 41 + 39 + 40 + 37 + 44 + 36 + 38 + 40) = \frac{395}{10} = 39.5
\]

Sample variance:

\[
S^2 = \frac{1}{n - 1} \sum_{i=1}^{10} (X_i - \overline{X})^2 = \frac{1}{9} \sum_{i=1}^{10} (X_i - 39.5)^2 \approx 6.17
\]

\[
S = \sqrt{6.17} \approx 2.48
\]

Test statistic:

\[
t = \frac{\overline{X} - \mu}{S / \sqrt{n}} = \frac{39.5 - 40}{2.48 / \sqrt{10}} \approx \frac{-0.5}{0.784} \approx -0.637
\]

The computed \( t \)-value is approximately \( -0.637 \), and it follows a \( t \)-distribution with \( \nu = 9 \) degrees of freedom. We can compare this value to critical values from the \( t \)-table or compute a \( p \)-value to make inference about \( \mu \).

\section{The Sampling Distribution of the Sample Variance}
When we take a random sample from a population, not only the sample mean but also the \textbf{sample variance} 
\[
S^2 = \frac{1}{n - 1} \sum_{i=1}^{n} (X_i - \overline{X})^2
\]
behaves as a random variable. That is, the value of the sample variance \( S^2 \) will vary from one sample to another. 

\begin{textbox}
\textbf{Theorem}: If $S^2$ is the variance of a random sample of size $n$ taken (with replacements) from a population of variance $\sigma^2$, then
\[
\mathbb{E}(S^2) = \sigma^2
\]
\end{textbox}

\textbf{Proof}: Let \( X_1, X_2, \dots, X_n \) be a random sample from a population with mean \( \mu \) and variance \( \sigma^2 \). The sample variance is defined as:
\[
S^2 = \frac{1}{n - 1} \sum_{i=1}^{n} (X_i - \overline{X})^2
\]

Now,
\begin{align*}
\sum_{i=1}^{n} (X_i - \overline{X})^2 &= \sum_{i=1}^{n} \left( (X_i - \mu) - (\overline{X} - \mu)\right) ^2\\
&= \sum_{i=1}^{n} (X_i - \mu)^2 - n(\overline{X} - \mu)^2
\end{align*}

Taking expectations on both sides:
\[
\mathbb{E}\left[\sum_{i=1}^{n} (X_i - \overline{X})^2 \right] = \mathbb{E}\left[ \sum_{i=1}^{n} (X_i - \mu)^2 \right] - n \cdot \mathbb{E}\left[(\overline{X} - \mu)^2 \right]
\]

Now, observe:
\begin{align*}
\mathbb{E}\left[\sum_{i=1}^{n} (X_i - \mu)^2 \right] &= \sum_{i=1}^{n} \mathbb{E}(X_i - \mu)^2 = n\sigma^2 \\
\mathbb{E}\left[(\overline{X} - \mu)^2 \right] &= \text{Var}(\overline{X}) = \frac{\sigma^2}{n}
\end{align*}

Therefore:
\[
\mathbb{E}\left[\sum_{i=1}^{n} (X_i - \overline{X})^2 \right] = n\sigma^2 - n \cdot \frac{\sigma^2}{n} = n\sigma^2 - \sigma^2 = (n - 1)\sigma^2
\]

Dividing both sides by \( n - 1 \), we get:
\[
\mathbb{E}(S^2) = \frac{1}{n - 1} \cdot (n - 1)\sigma^2 = \sigma^2
\]
\hfill $\blacksquare$

Thus the expectation value of the sample variance is the population variance. This result illustrates why the term \( n - 1 \) is used in the denominator of the definition of sample variance, rather than \( n \).
But we still don't know the exact shape of the sampling distribution. To describe the exact sampling distribution of \( S^2 \), we require the additional assumption that the population is normally distributed. Under this assumption, the following result holds:


\begin{textbox}
\textbf{Theorem}: If $S^2$ is the variance of a random sample of size $n$ taken from a normal population of variance $\sigma^2$, then the statistic
\[
\chi^2 = \frac{(n - 1)S^2}{\sigma^2}
\]
follows a \textbf{chi-squared distribution} with \( \nu = n - 1 \) degrees of freedom.
\end{textbox}

This theorem tells us how the sample variance \( S^2 \) is distributed around the true population variance \( \sigma^2 \).

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=12cm, height=7cm,
    domain=0:25, samples=200,
    axis lines=left,
    xlabel={$\chi^2$},
    ylabel={Density},
    legend style={at={(0.97,0.95)}, anchor=north east},
    % title={\small Chi-Squared Distributions for Different Degrees of Freedom},
    % grid=major,
    thick,
]

% ν = 2: f(x) = (1/2) * exp(-x/2)
\addplot [blue, very thick] {(1/2) * exp(-x/2)};
\addlegendentry{$\nu = 2$}

% ν = 5: f(x) = (1 / (2^{5/2} * Γ(5/2))) * x^{3/2} * exp(-x/2)
% Γ(5/2) = 1.3293..., 2^{5/2} = 5.6568...
% Constant = 1 / (5.6568 * 1.3293) ≈ 0.133
\addplot [red, very thick, dashed] {0.133 * x^(1.5) * exp(-x/2)};
\addlegendentry{$\nu = 5$}

% ν = 10: f(x) = (1 / (2^5 * Γ(5))) * x^4 * exp(-x/2)
% Γ(5) = 24, 2^5 = 32
% Constant = 1 / (32 * 24) = 1 / 768 ≈ 0.0013
\addplot [green!50!black, very thick, dotted] {0.0013 * x^4 * exp(-x/2)};
\addlegendentry{$\nu = 10$}

\end{axis}
\end{tikzpicture}
\end{center}

A Chi-squared distribution has the following properties:
\begin{itemize}
    \item The chi-squared distribution is not symmetric; it is skewed to the right, especially for small degrees of freedom.
    \item As the sample size increases (\( n \to \infty \)), the distribution becomes more symmetric and approaches normality.
    \item The expected value of the distribution is \( \mathbb{E}[\chi^2] = n-1 \).
    \item The critical point \(\chi^2_{\alpha,\nu}\) is defined so that
\[
P\bigl(\chi^2_\nu > \chi^2_{\alpha,\nu}\bigr) \;=\;\alpha
\]
where \(\chi^2_\nu\) denotes a chi-square random variable with \(\nu\) degrees of freedom.
\end{itemize}

\section{Distribution of the Ratio of Two Sample Variances}

A problem closely related to that of finding the distribution of the sample variance is that of determining the distribution of the ratio of the variances of two independent random samples. This problem is of considerable importance because it arises in hypothesis testing situations where we want to assess whether two samples come from populations with equal variances.

\begin{textbox}
\textbf{Theorem}: Let \( S_1^2 \) and \( S_2^2 \) be the sample variances of two independent random samples of sizes \( n_1 \) and \( n_2 \), respectively, drawn from two normal populations with equal variances. Then the statistic
\[
F = \frac{S_1^2}{S_2^2}
\]
follows an F-distribution with \( \nu_1 = n_1 - 1 \) and \( \nu_2 = n_2 - 1 \) degrees of freedom.
\end{textbox}

The F-distribution is characterized by two parameters:
\begin{itemize}
    \item \( \nu_1 \): the \textbf{numerator degrees of freedom} (associated with \( S_1^2 \)),
    \item \( \nu_2 \): the \textbf{denominator degrees of freedom} (associated with \( S_2^2 \)).
\end{itemize}

If two populations have the same variance, the sample variances obtained from them should be approximately equal. In such a case, the ratio of the two sample variances should be close to 1. To formally determine whether this ratio is unusually small or large, we use the \textbf{F-distribution}.


\section{The Sampling Distribution of the Sample Proportion}

Let \( X \) be the number of successes in a random sample of size \( n \) drawn from a population in which the proportion of successes is \( p \). Then the \textbf{sample proportion} is defined as:
\[
\hat{p} = \frac{X}{n}
\]
where \( \hat{p} \) is the observed proportion of successes in the sample. Since \( X \) is a binomial random variable with parameters \( n \) and \( p \), i.e., \( X \sim \text{Bin}(n, p) \), it follows that:
\begin{itemize}
    \item The mean of \( \hat{p} \) is:
    \[
    \mathbb{E}\left( \hat{p}\right)  = p
    \]
    \item The variance of \( \hat{p} \) is:
    \[
    \text{Var}(\hat{p}) = \frac{pq}{n}, \quad \text{where } q = 1 - p
    \]
\end{itemize}

\begin{textbox}
    \textbf{Theorem}: For large sample size \( n \), the distribution of sample proportion \( \hat{p} \) can be approximated by a normal distribution according to the Central Limit Theorem:
    \[
    \hat{p} \sim \mathcal{N}\left(p, \frac{pq}{n}\right)
    \]
\end{textbox}
This approximation is generally considered valid when both \( np \geq 5 \) and \( nq \geq 5 \).

The standardized form of \( \hat{p} \) is:
\[
\frac{\hat{p} - p}{\sqrt{pq/n}}
\]
which follows the standard normal distribution $\mathcal{N}\left(0, 1\right)$ for large sample.

\textbf{Example}: Suppose the true population proportion is \( p = 0.6 \) and a sample of size \( n = 100 \) is taken. Then:
\begin{align*}
\mathbb{E}\left( \hat{p}\right) &= 0.6 \\
\textrm{Var}(\hat{p}) &= \frac{0.6 \cdot 0.4}{100} = 0.0024
\end{align*}
Thus, the distribution of \( \hat{p} \) can be approximated as \( N(0.6, 0.0024) \).


\chapter{Theory of Estimation}

\section{Introduction}
Estimation is a fundamental component of \textbf{statistical inference}, which deals with drawing conclusions about population parameters from the analysis of sample data. There are two primary types of statistical inference:

\begin{enumerate}
    \item \textbf{Estimation of parameters}: The true value of a population parameter is an unknown constant. The goal of estimation is to make informed guesses about this parameter using sample data, along with an assessment of the accuracy of these guesses.
    
    \item \textbf{Hypothesis testing}: Sometimes, preliminary or tentative information about a population parameter is available. The objective of hypothesis testing is to use sample data to either support or reject such information about the parameter.
\end{enumerate}

In this chapter, we focus on the first type—{estimation of parameters}. Hypothesis testing will be addressed in the next chapter.

Statistical estimation techniques are broadly classified into two categories:

\begin{enumerate}
    \item \textbf{Point estimation}: A point estimation provides a single best guess of the unknown population parameter.
    
    \item \textbf{Interval estimation}: An interval estimation gives a range of plausible values for the parameter, along with a specified level of confidence that the interval contains the true value.
\end{enumerate}

Both point and interval estimation play crucial roles in quantifying uncertainty and guiding decision-making in the presence of incomplete information.


\section{Point Estimation}
Let $\theta$ ne an unknown parameter (e.g. the population mean) associated with a particular variable. For estimating $\theta$ on the basis of random samples $X_1, X_2, \dots, X_n$, we may use a particular statistic $ T $. This statistic $T$ is called the \textbf{point estimator} of $\theta$ and the value of $T$ obtained from a given sample is referred to as an \textbf{estimate} of $\theta$.

\textbf{Example}: When we estimate the population mean $\theta = \mu$, the most intuitive estimator is the sample mean $\overline{X} = \dfrac{1}{N}\sum_{i=1}^{n}X_i$. Similarly sample variance (\( S^2 \)) estimates population variance (\( \sigma^2 \)) and sample proportion (\( \hat{p} \)) estimates population proportion (\( p \))


\subsection{Desirable Properties of a Good Estimator}
There are often multiple point estimates available for any given parameter. So it is important to develop some evaluating criteria to judge the performance of each estimator and compare their performance. A good estimator should possess following desirable properties that make it reliable in estimating the true parameter value.

\begin{enumerate}
    \item \textbf{Unbiasedness}: 
    \begin{textbox}
    An estimator \( T \) is said to be an \textbf{unbiased} estimator of $\theta$ if
    \[
        \mathbb{E}(T) = \theta
        \]
    \end{textbox}
    Otherwise, $T$ is said to be biased. The \textbf{bias} ($\mathcal{B}$) is given by
    $$\mathcal{B} = \mathbb{E}(T) - \theta$$
    
    \textbf{Example}: The sample mean $\overline{X}$ and sample variance $S^2$ are unbiased estimator of the population mean $\mu$ and population variance $\sigma^2$ respectively, because
    $$\mathbb{E}\left( \overline{X}\right) = \mu, \quad \mathbb{E}\left( S^2\right) = \sigma^2$$
    
    \begin{textbox}
    The \textbf{mean-square-error} of the estimator $T$, denoted by $\textrm{MSE}(T)$ is defined as
        $$\mathrm{MSE}(T) = \mathbb{E}\left[\left( T-\theta\right) ^2\right]$$
    \end{textbox}
    
    MSE measures, on average, how close an estimator comes to the true value of the parameter.
    
    \begin{textbox}
    \textbf{Theorem}: Let \( T \) be an estimator of a population parameter \( \theta \). Then, the \textbf{Mean Squared Error (MSE)} of \( T \) is given by:
    \[
    \mathrm{MSE}(T) = \mathrm{Var}(T) + \mathcal{B}^2(T)
    \]
    \end{textbox}
    \textbf{Proof}:
    \begin{align*}
    \mathrm{MSE}(T) &= \mathbb{E}\left[(T - \theta)^2\right] \\
    &= \mathbb{E}\left[\left((T - \mathbb{E}(T)) + (\mathbb{E}(T) - \theta)\right)^2\right] \\
    &= \mathbb{E}\left[(T - \mathbb{E}(T))^2 + 2(T - \mathbb{E}(T))(\mathbb{E}(T) - \theta) + (\mathbb{E}(T) - \theta)^2\right] \\
    &= \mathbb{E}[(T - \mathbb{E}(T))^2] + \underbrace{2(\mathbb{E}(T) - \mathbb{E}(T))}_{= 0}\mathbb{E}\left( T - \mathbb{E}(T)\right)  + (\mathbb{E}(T) - \theta)^2 \\
    &= \mathrm{Var}(T) + \mathcal{B}^2(T)
    \end{align*}
    \hfill $\blacksquare$
    
    For an unbiased estimator $\mathcal{B} = 0$, and therefore $\mathrm{MSE}(T) = \mathrm{Var}(T)$.
    
    In this context, the \textbf{standard error (SE)} of $T$ is defined as the standard deviation of $T$ i.e. $ \sqrt{\operatorname{Var}(T)} $ which is deffierent from MSE($T$).

    \item \textbf{Consistency}:
    
    It is desirable that the estimator should behave more and more satisfactorily as the sample size $n$ becomes larger. Consistency provides the criteria.
    
    \begin{textbox}
    An estimator \(T_n\) (from a sample of size $n$) of a parameter \(\theta\) is said to be \textbf{consistent} if, as the sample size \(n\) grows, \(T_n\) converges in probability to the true parameter value. Which means that for every \(\varepsilon > 0\),
        \[
        P\bigl(|T_n - \theta| > \varepsilon\bigr) \to 0 \quad \text{as} \quad n \to \infty
        \]
    \end{textbox}
    
    Consistency as defined above is sometimes called \textbf{weak consistency}. If we replace convergence in probability with almost sure convergence, i.e. $$ P\left(\lim_{n \to \infty}T_n - \theta\right) = 1 \quad \text{as} \quad n \to \infty, $$
    then the estimator is said to be \textbf{strongly consistent}\footnote{\textbf{Weak consistency} says “in the long run, most of your estimates will be good,” but allows for occasional wildly bad estimates—even when \(n\) is very large.
    
    \textbf{Strong consistency} rules out even those rare catastrophes: it guarantees that once you’ve accumulated enough data, your estimator will stay arbitrarily close to \(\theta\) for every subsequent sample.
    }.
    
    \begin{textbox}
    \textbf{Sufficient Conditions for Consistency}: An estimator \(T_n\) of a parameter \(\theta\) is said to be {consistent} if it satisfies the following two conditions:
    \begin{enumerate}
      \item If $T_n$ is an \textit{asymptotically unbiased} estimator of $\theta$ i.e.
      \[
        \mathbb{E}(T_n) \to \theta \quad \text{as } n \to \infty
      \]
      \item The variance of estimator $ T_n $ decreases with increasing sample size i.e.
      \[
        \mathrm{Var}(T_n) \to 0 \quad \text{as } n \to \infty
      \]
    \end{enumerate}
    \end{textbox}
    \textbf{Proof}: By Chebyshev’s inequality, if both conditions hold, then
    \begin{align*}
    P\bigl(|T_n - \theta| \ge \varepsilon\bigr) 
        &\le \frac{\mathbb{E}(T_n-\theta)^2}{\varepsilon^2}, \quad \text{for every } \varepsilon > 0\\
        &= \frac{1}{\varepsilon^2}\left(\mathbb{E}\left[\left( T_n-\mathbb{E}(T_n)\right) + \left(\mathbb{E}(T_n)-\theta) \right)  \right]^2\right)\\
        &= \frac{1}{\varepsilon^2}\left(\underbrace{\mathbb{E}\left( T_n-\mathbb{E}(T_n)\right)^2}_{\mathrm{Var}(T_n)} +\left(\mathbb{E}(T_n)-\theta)\right) ^2 \right) \\
        &= \frac{1}{\varepsilon^2}\left( \mathrm{Var}(T_n)+\left(\mathbb{E}(T_n)-\theta)\right) ^2
        \right)\\
        &\to 0 \quad \text{as} \quad n \to \infty
     \end{align*}
    \hfill $\blacksquare$
    
    An estimator can be consistent even if it is biased for each finite \(n\), provided the bias vanishes as \(n \to \infty\).
    
    \textbf{Example}: Let \(X_1, X_2, \dots, X_n\) be i.i.d.\ with mean \(\mu\) and finite variance \(\sigma^2\). The sample mean
    \[
    \overline{X}_n = \frac{1}{n}\sum_{i=1}^n X_i
    \]
    satisfies
    \[
    \mathbb{E}[\overline{X}_n] = \mu,
    \qquad
    \mathrm{Var}(\overline{X}_n) = \frac{\sigma^2}{n} \;\longrightarrow\; 0.
    \]
    Hence, by the two conditions above, \(\overline{X}_n\) is a consistent estimator of \(\mu\).

    \item \textbf{Efficiency}:
    
    \begin{textbox}
    Among all unbiased estimators, the one with the smallest variance is said to be most \textbf{efficient}.
    \end{textbox}
    
    Unbiasedness is certainly a desirable property for point estimators but the criterion of unbiasedness does not generally provide a unique statistic for a given problem of estimation. For example, for symmetric population distribution, the sample median is also unbiased estimator for all sample sizes. Clearly, we need a further criterion to decide among different candidates.
        
    One natural refinement is to compare their variances which measures the spread
     of the sampling distribution. Although both the sample mean and the sample median of a normal population are unbiased and have bell‐shaped sampling distributions centered at \(\mu\), the variance of the sample mean is
        \[
        \mathrm{Var}\bigl(\overline{X}\bigr) = \frac{\sigma^2}{n},
        \]
        whereas the variance of the sample median is approximately
        \[
        \mathrm{Var}\bigl(X_{\text{median}}\bigr) \approx 1.5708\,\frac{\sigma^2}{n}.
        \]
        Because the mean’s distribution is more concentrated around \(\mu\), it will, on average, provide estimates closer to the truth. In other words, among unbiased estimators we favor the one with the smaller variance—and we call it, the most \textbf{efficient} estimator.
        
        This leads to the concept of the \emph{Minimum Variance Unbiased Estimator (MVUE)}:
        
        \begin{textbox}     
        The unbiased estimator $T^*$ is a \textbf{Minimum Variance Unbiased Estimator (MVUE)} of a parameter if it has the smallest variance among all unbiased estimators of the parameter.
        
        Formally, if \(\mathcal{U}\) is the class of all unbiased estimators of \(\theta\), then the MVUE \(T^*\) satisfies
                \[
                \mathrm{Var}\bigl(T^*\bigr) \;=\; \inf_{T \in \mathcal{U}} \mathrm{Var}\bigl(T\bigr)
                \]
            \end{textbox}
                               
        If two unbiased estimators $T_1$ and $T_2$ estimate the same parameter $\theta$, the \textbf{relative efficiency} of $T_1$ with respect to $T_2$ is defined as:
        
        \begin{textbox}
        \[
                \text{Relative Efficiency} = \frac{\operatorname{Var}(T_2)}{\operatorname{Var}(T_1)}.
                \]
        \end{textbox}
        
        An estimator is more efficient if it has a smaller variance. If the relative efficiency is close to 1, both estimators are equally good in terms of variance.

    \item \textbf{Sufficiency}: 
    
    \begin{textbox}
    A statistic is said to be \textbf{sufficient} for a parameter if it captures all the information in the sample about that parameter.
    \end{textbox} 
    
    Sufficiency is a key concept because it allows us to summarize the data without losing any relevant information about the parameter of interest.
    
    Let $\mathbf{X} = (X_1, X_2, \ldots, X_n)$ be a random sample from a distribution with conditional joint probability density function (or joint probability mass function) $$f_{\mathbf{X}}(x_1, x_2, \dots, x_n | \theta),$$ where $\theta$ is an unknown parameter. 
    
   \begin{textbox}
    A statistic $T(\mathbf{X})$ is said to be \textbf{sufficient} for $\theta$ if the conditional distribution of $X_1,X_2,\dots, X_n$ given $T(\mathbf{X}) = t$ does not depend on $\theta$. That is,
       \[
       f_{\mathbf{X}}(x_1, x_2, \dots, x_n \mid T = t, \theta) = f_{\mathbf{X}}(x_1, x_2, \dots, x_n \mid T = t)
       \]
       $ \text{for all } \theta $.
   \end{textbox}
   
   In other words, once you know \(T = t\), the probability (or density) of seeing any particular arrangement of the raw observations does not depends on \(\theta\). After you condition on \(T = t\), you look at the probability of different possible datasets that all share that same \(T\)-value. If that conditional probability still changes with \(\theta\), then those leftover items are carrying extra clues about \(\theta\). 
   
   
   A useful tool to verify sufficiency is the {Neyman–Fisher Factorization Theorem}, which states:
    
    \begin{textbox}
    \textbf{Neyman–Fisher Factorization Theorem}: A necessary and sufficient condition for the statistic $T(\textbf{X})$ to be a sufficient statistic for $\theta$ is that the joint PDF (or joint PMF) function of the sample can be factorized as:
        \[
         f_{\mathbf{X}}(x_1, x_2, \ldots, x_n| \theta) = g(T| \theta) \cdot h(x_1, x_2, \ldots, x_n)
        \]
        where
        \begin{itemize}
            \item $g(T| \theta)$ is a non negative function of $T$ and on $\theta$,
            \item $h(x_1, x_2, \ldots, x_n)$ is a function of the data that does not depend on $\theta$.
        \end{itemize}
    \end{textbox}
    
    \bigskip
    
    \textbf{Example}: Let \(X_1, X_2, \dots, X_n\) be independent Bernoulli random variables with common success probability \(p\). Therefore  
    \[
    X_i =
    \begin{cases}
    1, & \text{with probability } p\\
    0, & \text{with probability } 1 - p
    \end{cases}
    \]
    
    We wish to show that the total number of successes,
    \[
    T(\mathbf{X}) \;=\; \sum_{i=1}^n X_i
    \]
    is a sufficient statistic for \(p\).
    
    
    The joint probability mass function of the sample \(\textbf{X} = (X_1,X_2,\dots,X_n)\) is
    \[
    f_{\textbf{X}}(x_1,x_2,\dots,x_n|\,p) = \prod_{i=1}^{n} p^{x_i}(1-p)^{1-x_i}
    =
    p^{\sum_{i=1}^n x_i}
    \,(1 - p)^{\,n - \sum_{i=1}^n x_i}
    \]
      
    Observe that this can be written in the form
    \[
    f(x_1,x_2,\dots,x_n|\,p)
    =
    \underbrace{p^{T(\textbf{x})} \,(1-p)^{\,n - T(\textbf{x})}}_{g\bigl(T(\textbf{x}),p\bigr)}
    \;\times\;
    \underbrace{1}_{h(x)}
    \]
    where
    \[
    T(\textbf{x}) = \sum_{i=1}^n x_i
    \]
    Here:
    \begin{itemize}
      \item \(g\bigl(T(\textbf{x}),p\bigr) = p^{T(\textbf{x})} (1-p)^{\,n - T(\textbf{x})}\) depends only on the statistic \(T(\textbf{x})\) and the parameter \(p\).
      \item \(h(x) = 1\) depends on the full data \(\mathbf{x} = (x_1,x_2,\dots,x_n)\) but not on \(p\).
    \end{itemize}
    
    Therefore, the statistic \(T(\textbf{X})=\sum_{i=1}^n X_i\) is sufficient for the parameter \(p\).
    
    \bigskip
    
    \textbf{Example}: Let \(X_1, X_2, \dots, X_n\) be independent random variables drawn from a normal distribution with unknown mean \(\mu\) and known variance \(\sigma^2\).  That is,
    \[
    X_i \sim \mathcal{N}(\mu,\sigma^2),
    \]
    so each density is
    \[
    f_{X_i}(x_i \mid \mu)
    =
    \frac{1}{\sqrt{2\pi\,\sigma^2}}
    \exp\!\Bigl(-\tfrac{1}{2\sigma^2}(x_i - \mu)^2\Bigr).
    \]
    
    We wish to show that the sample mean
    \[
    T(\mathbf{X}) \;=\; \frac{1}{n}\sum_{i=1}^n X_i
    \]
    is a sufficient statistic for \(\mu\).
       
    The joint density of the sample \(\mathbf{X}=(X_1,X_2,\dots,X_n)\) is
    \[
    \begin{aligned}
    f_{\mathbf{X}}(x_1,x_2,\dots,x_n \mid \mu)
    &=
    \prod_{i=1}^{n}
    \frac{1}{\sqrt{2\pi\,\sigma^2}}
    \exp\!\left( -\tfrac{1}{2\sigma^2}(x_i - \mu)^2\right) \\
    &=
    (2\pi\,\sigma^2)^{-\tfrac{n}{2}}
    \exp\!\left( -\tfrac{1}{2\sigma^2}\sum_{i=1}^n (x_i - \mu)^2\right)
    \end{aligned}
    \]
    
    Rewrite the exponential term:
    \[
    \sum_{i=1}^n (x_i - \mu)^2
    =
    \sum_{i=1}^n x_i^2
    \;-\;2\mu\sum_{i=1}^n x_i
    \;+\;n\,\mu^2 = \sum_{i=1}^n x_i^2\;-\;n\,\mu^2
    \]
    Thus
    \[
    \exp\!\left( -\tfrac{1}{2\sigma^2}\sum_i (x_i - \mu)^2\right) 
    =
    \exp\!\left( -\tfrac{1}{2\sigma^2}\sum_i x_i^2\right) 
    \;\times\;
    \exp\!\left( \tfrac{\mu}{\sigma^2}\sum_i x_i \;-\;\tfrac{n\mu^2}{2\sigma^2}\right) 
    \]
    Hence the joint density factors as
    \[
    \begin{aligned}
    f_{\textbf{X}}(x_1,x_2,\dots,x_n \mid \mu)
    &=
    \underbrace{%
    \exp\!\left( \tfrac{n\mu}{\sigma^2}\,T(\textbf{x})
         \;-\;\tfrac{n\mu^2}{2\sigma^2}\right) 
    }_{g\bigl(T(\textbf{x}),\mu\bigr)}
    \;\times\;
    \underbrace{%
    (2\pi\,\sigma^2)^{-\tfrac{n}{2}}
    \exp\!\left( -\tfrac{1}{2\sigma^2}\sum_i x_i^2\right) 
    }_{h(x)}
    \end{aligned}
    \]
    where \(T(\textbf{x})=\sum_{i=1}^n x_i\). Therefore, by the Neyman–Fisher factorization theorem, because the statistic
    \(\displaystyle T(\mathbf{X})=\frac{1}{n}\sum_{i=1}^n X_i\) is sufficient for \(\mu\).
    
\end{enumerate}

\section{Methods of Estimation}
\subsection{Method of Moments}
Equates sample moments to population moments:
\[
\mu_k = \mathbb{E}[X^k] \approx \frac{1}{n} \sum_{i=1}^n X_i^k
\]

\subsection{Maximum Likelihood Estimation (MLE)}
MLE chooses the parameter value that maximizes the likelihood function:
\[
L(\theta) = \prod_{i=1}^n f(X_i;\theta)
\]

\textbf{Steps:}
\begin{enumerate}
    \item Write the likelihood function.
    \item Take the natural log to obtain the log-likelihood.
    \item Differentiate and solve for \( \theta \) by setting derivative to zero.
\end{enumerate}

\section{Interval Estimation}
\subsection{Definition}
An \textbf{interval estimator} provides a range (interval) of values that is believed to contain the true value of the parameter with a certain level of confidence.

\subsection{Confidence Interval}
A \textbf{confidence interval (CI)} for a parameter \( \theta \) is an interval \( (L, U) \) such that
\[
P(L \leq \theta \leq U) = 1 - \alpha
\]
where \( 1 - \alpha \) is the confidence level (e.g., 95\%).

\subsection{Confidence Interval for Mean}
\begin{itemize}
    \item \textbf{Known Variance:}
    \[
    \bar{X} \pm z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}
    \]

    \item \textbf{Unknown Variance:}
    \[
    \bar{X} \pm t_{\alpha/2, n-1} \cdot \frac{S}{\sqrt{n}}
    \]
\end{itemize}

\subsection{Confidence Interval for Proportion}
\[
\hat{p} \pm z_{\alpha/2} \cdot \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}
\]

\subsection{Interpretation of Confidence Intervals}
A 95\% confidence interval means that if we repeated the sampling procedure many times, approximately 95\% of the calculated intervals would contain the true parameter value.

\section{Estimation in Large Samples}
For large samples (\( n \to \infty \)), estimators often follow a normal distribution by the Central Limit Theorem, making interval estimation easier even with unknown distributions.

\section{Illustrative Examples}
\subsection*{Example 1: Point Estimation}
Given sample data: 5, 7, 9, 10, 6

Estimate the mean:
\[
\bar{X} = \frac{5 + 7 + 9 + 10 + 6}{5} = 7.4
\]

\subsection*{Example 2: Confidence Interval for Mean}
If \( \bar{X} = 50 \), \( \sigma = 10 \), \( n = 100 \), 95\% CI is:
\[
50 \pm 1.96 \cdot \frac{10}{\sqrt{100}} = (48.04, 51.96)
\]


\section{Sample Size Determination}
Sample size affects the accuracy and reliability of estimates. It depends on the desired confidence level, margin of error, and population variability.



\section{Conclusion}
Estimation is essential for making inferences about population parameters using sample data. Point estimation provides a single best guess, while interval estimation provides a range with a confidence level. Properties like unbiasedness and consistency ensure the quality of estimators, and methods like MLE and method of moments offer practical ways to derive them.



\chapter{Test of Hypothesis}
\section{What is Hypothesis Testing?}

There are many problems in which, rather than estimate the value of a parameter, we must decide whether a statement concerning a parameter is true or false. Statistically speaking, we test a hypothesis about a parameter.

% \begin{tcolorbox}[heading={Statistical Hypothesis}]
% A \textbf{statistical hypothesis} is a statement about the parameter of a population.
% \end{tcolorbox}

\begin{textbox}
A \textbf{statistical hypothesis} is a statement about the parameter of a population.
\end{textbox}

For example, a factory produces screws that are supposed to be 5 cm long. A quality inspector takes a sample of 50 screws and finds that the average length is 4.8 cm. Here, the hypothesis is the statement: 

\begin{center}
``{The average length of the screws is 5 cm.}'' 
\end{center} 

Based on the sample's average length, the inspector tests whether this difference is simply due to random variation or if the machine requires adjustment.

\begin{textbox}
\textbf{Hypothesis testing} is a statistical method used to make decisions or inferences about some parameter of a population based on sample data.
\end{textbox}
It helps us to determine whether the evidence in a sample supports a certain belief or hypothesis about the population.

\subsection{Null and Alternative Hypothesis}

The hypothesis that will actually be tested is called the \textbf{null hypothesis}, denoted by $H_0$. This is a particular claim about a population parameter. The null hypothesis is assumed to be true unless there is any strong evidence to the contrary.

The \textbf{alternative hypothesis}, denoted by $H_1$ or $H_a$, is a hypothesis that contradicts the null hypothesis. For the above example, we define the hypotheses as:

\begin{itemize}
    \item \textbf{Null Hypothesis ($H_0$):} The average length of screws is 5 cm.
    \item \textbf{Alternative Hypothesis ($H_1$ or $H_a$):} The average length is not 5 cm.
\end{itemize}

In simple expression we write:
    $$H_0: \mu = 5$$
    $$H_1 : \mu \neq 5$$

% The objective of hypothesis testing is to decide, based on
% sample information, if the alternative hypothesis is actually
% supported by the data. 

The standard procedure is to assume that $H_0$ is true. The burden of proof is placed on those who believe in the alternative claim\footnote{A close analogy can be made to a criminal court trial, where the jury holds to the null hypothesis of ``Not guilty'' unless there is convincing evidence of guilt.  The purpose of the hearing is to establish the assertion that the accused is guilty rather than to prove that he or she is innocent.} (hypothesis). This initially favored claim ($H_0$) will not be rejected in favor of the alternative claim ($H_1$ or $H_a$) unless the sample evidence provides significant support for the alternative claim. If the sample does not strongly contradict $H_0$, we will continue to believe in the plausibility of the null hypothesis.

\vspace{3mm}
\begin{center}
    \begin{tikzpicture}[node distance=3cm]

% Nodes
% \node (start) [startstop] {Start Hypothesis Test};
\node (evidence) [startstop] {Is there strong evidence against $H_0$?};
\node (reject) [startstop, below of=evidence, xshift=-2.0cm] {Reject $H_0$};
\node (fail) [startstop, below of=evidence, xshift=2.0cm] {Fail to reject $H_0$};

% Arrows
% \draw [arrow] (start) -- (evidence);
\draw [arrow] (evidence) -- node[left] {Yes} (reject);
\draw [arrow] (evidence) -- node[right] {No} (fail);

\end{tikzpicture}
\end{center}

To test the hypothesis, we assume that the
standard deviation $\sigma = 0.3$ is known. Since the sample size is $n = 50$, the sampling distribution of the sample mean is approximately normal: \[
    \overline{X} \sim N\left( \mu, \frac{\sigma}{\sqrt{n}} \right)
    \]
    \text{or, } \[
    \overline{X} \sim N\left( 50, 0.042 \right)
    \]

\begin{center}
\begin{tikzpicture}
  \begin{axis}[
    domain=4.8:5.2, samples=200,
    xlabel={$\overline{X}$}, ylabel={Probability Density},
    axis lines=left,
    height=6cm, width=10cm,
    xtick={4.9177, 5, 5.0823},
    xticklabels={$4.917$, $5$, $5.082$}
  ]

    % Plot the normal curve
    \addplot [very thick, blue] {1/(0.042*sqrt(2*pi)) * exp(-((x-5)^2)/(2*0.042^2))};

    % Shade the left tail
    \addplot [
      domain=4.8:4.9177, 
      fill=gray!40, 
      draw=none
    ] {1/(0.042*sqrt(2*pi)) * exp(-((x-5)^2)/(2*0.042^2))} \closedcycle;

    % Shade the right tail
    \addplot [
      domain=5.0823:5.2, 
      fill=gray!40, 
      draw=none
    ] {1/(0.042*sqrt(2*pi)) * exp(-((x-5)^2)/(2*0.042^2))} \closedcycle;

    % Add probability text
    \node at (axis cs:5,3.5) {\small 0.95};
    \node at (axis cs:4.88,1.2) {\small 0.025};
    \node at (axis cs:5.12,1.2) {\small 0.025};

  \end{axis}
\end{tikzpicture}
\end{center}

% \begin{center}
% \begin{tikzpicture}
%   \begin{axis}[
%     domain=-3.5:3.5, samples=200,
%     xlabel={$\overline{X}$}, ylabel={Probability Density},
%     axis lines=left,
%     height=6cm, width=10cm,
%     xtick={-1.96, 0, 1.96},
%     xticklabels={$ \mu - z_{\alpha/2} $, $ \mu $, $ \mu + z_{\alpha/2} $},
%     enlargelimits=0.1
%   ]

%     % Plot the normal curve
%     \addplot [very thick, blue] {1/sqrt(2*pi) * exp(-x^2/2)};

%     % Shade the left tail
%     \addplot [
%       domain=-3.5:-1.96, 
%       fill=gray!40, 
%       draw=none
%     ] {1/sqrt(2*pi) * exp(-x^2/2)} \closedcycle;

%     % Shade the right tail
%     \addplot [
%       domain=1.96:3.5, 
%       fill=gray!40, 
%       draw=none
%     ] {1/sqrt(2*pi) * exp(-x^2/2)} \closedcycle;

%     % Add probability text
%     \node at (axis cs:0,0.25) {\small $1 - \alpha$};
%     \node at (axis cs:-2.6,0.05) {\small $\alpha/2$};
%     \node at (axis cs:2.6,0.05) {\small $\alpha/2$};

%   \end{axis}
% \end{tikzpicture}
% \end{center}


The distribution of $\overline{X}$ (sampling distribution) is shown in the figure. From the figure, we can see that there is a $95\%$ chance that the value of $\overline{X}$ measured from a random sample will lie in the region $4.917 \leq \overline{X} \leq 5.082$. However, the observed value is 4.8 cm, which falls well outside of this interval. The chance of obtaining such an extreme value when the true mean is actually 5 cm is less than $5\%$.

This provides strong statistical evidence against the null hypothesis. Therefore, we reject the null hypothesis $H_0: \mu = 5$ in favor of the alternative hypothesis $H_1: \mu \ne 5$. It suggests that the mean length of the screws is significantly different from 5 cm, and that the manufacturing process may need to be adjusted.


\begin{textbox}
The probability of the tails of the distribution, which determines the threshold for making a decision, is called the \textbf{level of significance}, denoted by $\alpha$. 
\end{textbox}
In our example, we chose the level of significance $\alpha = 0.05$, which is equally split between the two tails of the distribution, allocating $0.025$ to each side.

\begin{textbox}
The range of values for which the null hypothesis is
rejected is called the \textbf{critical region}.    
\end{textbox}

For the above example, the critical region is characterized by $\overline{X} < 4.917$ and $\overline{X} > 5.082$.

\subsection{One-Sided and Two-Sided Hypothesis Testing}

In hypothesis testing, the form of the alternative hypothesis determines whether the test is \textbf{one-sided} (one-tailed) or \textbf{two-sided} (two-tailed).

\begin{itemize}
    \item \textbf{Two-Sided Test:} Used when we are interested in detecting any difference from the null hypothesis value, whether it is an increase or a decrease. For example:
    \[
    H_0: \mu = 5 \quad \text{vs.} \quad H_1: \mu \ne 5
    \]
    This test considers deviations on both sides of the hypothesized mean as we saw in the previous example. The significance level $\alpha$ is split between the two tails of the sampling distribution.

    \item \textbf{One-Sided Test:} Used when we are only interested in deviations in one direction.
    \begin{itemize}
        \item To test if the mean is \emph{less than} 5:
        \[
        H_0: \mu = 5 \quad \text{vs.} \quad H_1: \mu < 5
        \]
        \item To test if the mean is \emph{greater than} 5:
        \[
        H_0: \mu = 5 \quad \text{vs.} \quad H_1: \mu > 5
        \]
    \end{itemize}
    In this case, the entire significance level $\alpha$ is placed in one tail of the distribution.
\end{itemize}

\noindent
The choice between one-sided and two-sided testing depends on the research question. If deviations in both directions are meaningful, a two-sided test is appropriate. If only an increase or a decrease is relevant, a one-sided test is more powerful.


% \section{Tests of Statistical Hypotheses}

% Let us take the same previous example where a factory claims that the average length of screws produced by a machine is 5 cm. To verify this claim, a quality inspector takes a random sample of 50 screws and finds that the average length is 4.8 cm. We want to test whether this observed difference is due to random sampling variation or if it indicates that the machine is no longer operating correctly.

% \begin{enumerate}
%     \item \textbf{State the Hypotheses:} 
%     \begin{itemize}
%         \item Null Hypothesis ($H_0$): The true mean length is 5 cm. $$H_0: \mu = 5$$
%         \item Alternative Hypothesis ($H_1$): The true mean length is not 5 cm. $$H_1: \mu \ne 5$$
%     \end{itemize}

%     \item \textbf{Compute the Test Statistic} \\
%     The \textbf{test statistic} is a function of the sample data that will be used to make a decision about whether the null hypothesis should be rejected or not. 
    
%     Assume that the population standard deviation is known to be $\sigma = 0.3$ cm. Since the sample size is $n = 50$, the sampling distribution of the sample mean is approximately normal:
%     \[
%     \overline{X} \sim N\left( \mu, \frac{\sigma}{\sqrt{n}} \right)
%     \]
%     This implies that
%     \[
%     Z = \dfrac{\overline{x} - \mu_0}{\dfrac{\sigma}{\sqrt{n}}}
%     \]
%     will follow a standard normal distribution, or Z distribution. The z-test statistic is:
%     \[
%     z = \frac{\overline{x} - \mu_0}{\frac{\sigma}{\sqrt{n}}} = \frac{4.8 - 5}{\frac{0.3}{\sqrt{50}}} \approx -4.72
%     \]

%     \item \textbf{Determine the Critical Region:}
%     For standard normal distribution, we know
%     \[
%     Prob\left[-z_{\frac{\alpha}{2}} < Z < z_{\frac{\alpha}{2}}\right] = 1-\alpha
%     \]
%     For $\alpha=0.05$, $z_{\frac{\alpha}{2}} = 1.96$, and therefore
%     \[
%     Prob\left[-1.96 < Z < 1.96\right] = 0.95
%     \]
%     The region outside
%     \[-1.96 < Z < 1.96\]
%     is called the critical region. The probability that the z-value will fall in the critical region is 0.05 and if the computed z-value falls in the critical region, we reject the null hypothesis. The computed z-value in this example is $-4.72$, which falls in the critical region ($z < -1.96$), we reject the null hypothesis.

%     \item \textbf{Conclusion} \\
%     We reject the null hypothesis $H_0$. There is strong statistical evidence that the true mean length of the screws is not 5 cm. This suggests the machine may be out of adjustment.
% \end{enumerate}

\section{Type I and Type II Error}
This decision procedure can lead to either of two incorrect conclusions, known as Type I and Type II errors.

For example, suppose the true average length of the screws is indeed 5 cm. However, due to random variation in the sample, we might observe a test statistic that falls into the critical region. In this case, we would reject the null hypothesis $H_0$ in favor of the alternative $H_1$, even though $H_0$ is actually true. This mistake is called a \textbf{Type I error}. The probability of a Type I error is also called the \textbf{level of significance}, denoted by $\alpha$. It is usually set at $\alpha = 0.05$ or $\alpha = 0.01$. 

\begin{textbox}
    $P$(\text{Type I error})  = $P$(Rejecting $H_0$ $\mid$ $H_0$ is true) = $\alpha$
\end{textbox}

On the other hand, suppose the true average length of the screws has actually changed (for example, to 4.8 cm), but the observed sample does not provide enough evidence to reject $H_0$. In this case, we fail to reject the null hypothesis, even though it is false. This mistake is called a \textbf{Type II error}. The probability of Type II error is denoted by $\beta$.

\begin{textbox}
    $P$(\text{Type II error}) = $P$(Not rejecting $H_0$ $\mid$ $H_0$ is false) = $\beta$
\end{textbox}

\begin{table}[h!]
\centering
\vspace{0.5em}
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{l|c|c}

 & $H_0$ is True & $H_1$ is True \\
\hline
Reject $H_0$        & \textbf{Type I Error} ($\alpha$) & Correct Decision \\
Fail to Reject $H_0$ & Correct Decision        & \textbf{Type II Error} ($\beta$) \\
\end{tabular}
\end{table}

\begin{center}
\begin{tikzpicture}
  \begin{axis}[
    domain=-3:7, samples=200,
    xlabel={ }, ylabel={Probability Density},
    axis lines=left,
    height=6cm, width=12cm,
    xtick={0, 1.645, 3},
    xticklabels={$ \mu $, Threshold, $ \mu_1 $},
    ytick=\empty,  % <-- remove y-ticks
    enlargelimits=0.05,
    legend style={at={(0.85,0.75)}, anchor=south}
  ]

    % Null hypothesis distribution
    \addplot [very thick, blue] {1/sqrt(2*pi) * exp(-x^2/2)};
    \addlegendentry{$H_0$}

    % Alternative hypothesis distribution
    \addplot [very thick, red, dashed, domain=-1:7] {1/sqrt(2*pi) * exp(-(x-3)^2/2)};
    \addlegendentry{$H_1$}

    % Type I error region (right tail of H0)
    \addplot [
      domain=1.645:4, 
      fill=gray!40, 
      draw=none
    ] {1/sqrt(2*pi) * exp(-x^2/2)} \closedcycle;
    \node at (axis cs:3.4,0.05) {\small Type I Error ($\alpha$)};

    % Type II error region (left of critical value under H1)
    \addplot [
      domain=-1:1.645, 
      fill=red!20, 
      draw=none
    ] {1/sqrt(2*pi) * exp(-(x-3)^2/2)} \closedcycle;
    \node at (axis cs:0.25,0.07) {\small Type II Error ($\beta$)};

  \end{axis}
\end{tikzpicture}
\end{center}

\section{Test Statistic}
\begin{textbox}
The \textbf{test statistic} is a function of the sample data that forms the basis for making the statistical decision to either reject or fail to reject the null hypothesis.
\end{textbox}

The main purpose of the test statistic is to provide a measure of how far the sample statistic (such as the sample mean) deviates from the hypothesized value under the null hypothesis. The further this value is from the hypothesized value, the stronger the evidence against the null hypothesis.

Depending on the type of hypothesis test being conducted, the test statistic can take various forms. For instance, a \textbf{z-test statistic} is used to test hypotheses about a population mean when the population standard deviation ($\sigma$) is known and the sample size is large ($n > 30$). The z-test compares the sample mean to the population mean, and the test statistic is given by:
    \[
    Z = \frac{\overline{X} - \mu}{\frac{\sigma}{\sqrt{n}}}
    \]
    where $\overline{X}$ is the sample mean, $\mu$ is the population mean under the null hypothesis, $\sigma$ is the population standard deviation, and $n$ is the sample size.

For the example with a sample of 50 screws, where the sample mean is $\overline{X} = 4.8$ cm, the population mean under the null hypothesis is $\mu = 5$ cm, and the population standard deviation is $\sigma = 0.3$ cm. The z-test statistic is then calculated as follows:

\[
Z = \frac{\overline{X} - \mu}{\frac{\sigma}{\sqrt{n}}} = \frac{4.8 - 5}{\frac{0.3}{\sqrt{50}}} \approx -4.72
\]
In this example, the computed z-value is $-4.72$. 

Once the test statistic is calculated, it is compared to a \textbf{critical value} from the relevant probability distribution (e.g., the standard normal distribution). The critical value is determined by the level of significance $\alpha$ and the nature of the test (one-tailed or two-tailed). For instance, in a two-tailed test with $\alpha = 0.05$, the critical z-values are $\pm 1.96$.

The decision rule can be summarized as follows:

\begin{itemize}
    \item If the absolute value of the test statistic exceeds the critical value ($\left|Z\right| > 1.96$), we reject the null hypothesis.
    \item If the absolute value of the test statistic is less than or equal to the critical value ($\left|Z\right| \leq 1.96$), we fail to reject the null hypothesis.
\end{itemize}

In general, the larger the magnitude of the test statistic, the stronger the evidence against the null hypothesis. In our example, the computed z-value is $-4.72$, which lies far in the left tail and is less than $-1.96$. Therefore, we reject the null hypothesis $H_0$.



\section{P-Value}

\begin{itemize}
    \item \textbf{Significance Level (\( \alpha \))}: The probability of rejecting the null hypothesis when it is actually true. Common values are 0.05 (5\%) or 0.01 (1\%).
    \item \textbf{P-value}: The probability of getting the observed result (or more extreme) if the null hypothesis is true.
    \item \textbf{Test Statistic}: A standardized value that is calculated from sample data during a hypothesis test.
    \item \textbf{Critical Region}: The range of values for which the null hypothesis is rejected.
\end{itemize}

\section{The 5 Steps of Hypothesis Testing}

\begin{enumerate}
    \item \textbf{State the hypotheses} \\
    \textit{Example:} A factory claims their lightbulbs last an average of 1,000 hours. We suspect they don’t.\\
    \( H_0: \mu = 1000 \) hours \\
    \( H_1: \mu \neq 1000 \) hours
    
    \item \textbf{Choose a significance level} \\
    Let’s use \( \alpha = 0.05 \).
    
    \item \textbf{Collect data and calculate the test statistic} \\
    Suppose we test 30 lightbulbs and find the sample mean \( \overline{x} = 980 \), with a standard deviation \( s = 50 \).
    
    \item \textbf{Calculate the p-value or compare the test statistic to a critical value} \\
    Using a Z-test:
    \[
    z = \frac{\overline{x} - \mu}{\sigma / \sqrt{n}} = \frac{980 - 1000}{50 / \sqrt{30}} \approx -2.19
    \]
    From Z-tables, \( p \approx 0.0286 \) (two-tailed).
    
    \item \textbf{Make a decision} \\
    Since \( p < \alpha \), we reject \( H_0 \). \\
    \textbf{Conclusion:} There is evidence that the average bulb life is not 1,000 hours.
\end{enumerate}

\section{Types of Hypothesis Tests}

\begin{itemize}
    \item \textbf{One-sample Z-test:} When population standard deviation is known.
    \item \textbf{One-sample t-test:} When population standard deviation is unknown.
    \item \textbf{Proportion test:} For claims about population proportions.
\end{itemize}

\textbf{Example for t-test:} A teacher claims the average test score is 75. You collect scores from 20 students. \\
\( H_0: \mu = 75 \) \\
\( H_1: \mu \neq 75 \)

\textbf{Example for proportion test:} You believe 60\% of voters support a new policy. You survey 100 voters and 54 agree. \\
\( H_0: p = 0.60 \) \\
\( H_1: p \neq 0.60 \)

\section*{5. Common Errors in Hypothesis Testing}

\begin{itemize}
    \item \textbf{Type I Error:} Rejecting \( H_0 \) when it is true (false positive).
    \item \textbf{Type II Error:} Not rejecting \( H_0 \) when \( H_1 \) is true (false negative).
\end{itemize}

\textbf{Example:}
\begin{itemize}
    \item Type I: Concluding a drug works when it actually doesn’t.
    \item Type II: Concluding a drug doesn’t work when it actually does.
\end{itemize}

\section{Summary Table}

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{Concept} & \textbf{Description} \\
\midrule
Null Hypothesis (\( H_0 \)) & Default assumption (no change/difference) \\
Alternative Hypothesis (\( H_1 \)) & What you want to test \\
Significance Level (\( \alpha \)) & Threshold for decision-making (e.g., 0.05) \\
P-value & Probability of getting sample data if \( H_0 \) is true \\
Reject \( H_0 \) if & \( p < \alpha \) \\
\bottomrule
\end{tabular}
\end{center}

\section*{7. Final Example: Coin Toss}

You suspect a coin is biased. You flip it 100 times and get 60 heads. \\
\( H_0: p = 0.5 \quad \) (fair coin) \\
\( H_1: p \neq 0.5 \quad \) (biased coin)

\[
z = \frac{0.6 - 0.5}{\sqrt{0.5 \times 0.5 / 100}} = 2.0
\]

From Z-tables, \( p \approx 0.0455 \). Since \( p < 0.05 \), we reject \( H_0 \). \\
\textbf{Conclusion:} There is evidence the coin might be biased.
\chapter{Regression Analysis}

\section{What is Regression Analysis?}

\begin{textbox}
    \textbf{Regression analysis} is a statistical method used to explore and model the relationship between a dependent variable and one or more independent variables.
\end{textbox}
 It plays a central role in data analysis, prediction, and inference, particularly when trying to establish a functional relationship between variables.

In its simplest form—\textbf{simple linear regression}—we wish to study the relationship between two variables $X$ and $Y$ and use it to predict $Y$ from $X$. The variable $X$ acts as the \textbf{independent variable} (predictor, causal variable) whose values are controlled by the experimenter and $Y$ is the \textbf{dependent variable} (response) which is also subjected to unaccountable variations (errors).

For example, a teacher wants to examine whether there's a relationship between how long students study and the scores they achieve in a test. By treating the number of hours studied as the independent variable and the test score as the dependent variable, regression helps us determine whether there is a consistent trend between the two.

\section{The Simple Linear Regression Model}

A simple linear regression model assumes the existence of a linear relationship between $X$ (predictor variable) and $Y$ (response) that is disturbed by a random error $\epsilon$ which can be written as an equation of the form:

\begin{textbox}
\[
Y = \beta_0 + \beta_1 X + \epsilon
\]
\end{textbox}

where:
\begin{itemize}
    % \item \( Y \): dependent (response) variable
    % \item \( X \): independent (predictor) variable
    \item \( \beta_0 \): $y$-intercept of the line,
    \item \( \beta_1 \): slope of the line (rate of change in \( Y \) per unit increase in \( X \)),
    \item \( \epsilon \): random error, accounting for unexplained variation
\end{itemize}

Given a dataset of \( n \) observations, represented as pairs:
$$(x_1,y_1), (x_2, y_2), \dots (x_n, y_n)$$
the objective is to estimate the unknown parameters \( \beta_0 \) and \( \beta_1 \), and then use these estimates to define a straight line that best fits the data.

The \textbf{fitted regression line} (also called the prediction equation) is:
\begin{textbox}
    $$\hat{Y} = \hat{\beta_0} + \hat{\beta_1}X$$
\end{textbox}
Here, \( \hat{\beta}_0 \) and \( \hat{\beta}_1 \) are the estimated values of the intercept and slope, respectively, obtained from the sample data.

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=10cm,
    height=6.5cm,
    xlabel={Independent Variable ($X$)},
    ylabel={Dependent Variable ($Y$)},
    axis lines=left,
    % grid=both,
    xmin=0, xmax=10,
    ymin=0, ymax=10,
    enlargelimits=true,
    clip=false
]

% Scatter data points
\addplot[
    only marks,
    color=blue,
    mark=*,
    mark size=2pt
] coordinates {
    (1,1.7) (2,1.7) (3,1.8) (4,4.8) (5,5.2)
    (6,6.4) (7,6.0) (8,9) (9,8.8)
};

% Regression line
\addplot[
    domain=0:10,
    samples=2,
    color=black,
    very thick
] {x};

% Arrow to data points
\draw[->, thin] (axis cs:6,8.2) -- (axis cs:6,6.6);
\draw[->, thin] (axis cs:6,8.2) -- (axis cs:6.9,6.2);
\node at (axis cs:6,8.5) {Data Points};

% Arrow to regression line
\draw[->, thin] (axis cs:2,8.3) -- (axis cs:3.4,3.5);
\node at (axis cs:1.5,8.7) {Line of Regression};

\end{axis}
\end{tikzpicture}
\end{center}

% \section{Assumptions of the Linear Model}

% To perform valid inference, the model makes the following assumptions:
% \begin{enumerate}
%     \item Linearity: \( Y \) changes linearly with \( X \)
%     \item Independence: Errors \( \epsilon_i \) are independent
%     \item Homoscedasticity: Constant variance of errors \( \mathrm{Var}(\epsilon_i) = \sigma^2 \)
%     \item Normality: Errors are normally distributed (for inference)
% \end{enumerate}

\section{Estimating Parameters Using Least Squares}

Given \( n \) data points \( (x_1, y_1), \ldots, (x_n, y_n) \), the estimates of the parameters \( \beta_0 \) and \( \beta_1 \) should result in a line that is (in some sense) a ``best ﬁt'' to the data. To define what we mean by a ``best fit'' line, consider each data point \( (x_i, y_i) \) and its corresponding prediction \( \hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i \) from the regression line. This predicted value is known as the \textbf{fitted value}. The difference between the observed value \( y_i \) and the fitted value \( \hat{y}_i \) is called the \textbf{residual} (error), denoted by \( \epsilon_i \):

\begin{textbox}
    \[
\epsilon_i = y_i - \hat{y}_i
\]
\end{textbox}

The residual \( \epsilon_i \) represents the vertical distance between an observed data point and the regression line. A positive residual indicates that the point lies above the regression line, while a negative residual indicates that it lies below. The closer the residuals are to zero, the better the fitted values approximate the observed data. Therefore, the estimates of the parameters \( \beta_0 \) and \( \beta_1 \) should be such that these residuals (errors) are as small as possible. However, minimizing the simple sum of residuals is not appropriate, because the positive and negative errors can cancel each other out, even when individual errors are large. A more effective approach is the \textbf{method of least squares}, which involves minimizing the sum of the squares of the residuals.

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=10cm,
    height=6.5cm,
    xlabel={Independent Variable ($X$)},
    ylabel={Dependent Variable ($Y$)},
    axis lines=left,
    xmin=0, xmax=10,
    ymin=0, ymax=10,
    enlargelimits=true,
    clip=false
]

% Scatter data points
\addplot[
    only marks,
    color=blue,
    mark=*,
    mark size=2pt
] coordinates {
    (1,1.7) (2,1.7) (3,1.8) (4,5.5) (5,5.2)
    (6,6.4) (7,5.8) (8,9) (9,8.8)
};

% Regression line y = x
\addplot[
    domain=0:10,
    samples=2,
    color=black,
    very thick
] {x};

% Red vertical line for residual at (4,5.5) to (4,4)
\draw[red, thick] (axis cs:4,5.5) -- (axis cs:4,4);
\node[black] at (axis cs:2.7,4.7) {$\epsilon_i = y_i - \hat{y}_i$};
\node[black] at (axis cs:4.3,6.2) {$ (x_i, y_i)$};
\node[black] at (axis cs:4.3,3.3) {$ (x_i, \hat{y}_i)$};

\end{axis}
\end{tikzpicture}
\end{center}

The \textbf{least-squares line} is the line that minimizes the \textbf{residual sum of squares (RSS)}\footnote{In some texts, the residual sum of squares (RSS) is also called the \textbf{sum of squares of errors (SSE)}}:

\begin{textbox}
\[
\text{RSS} = \sum_{i=1}^{n} \epsilon_i^2 = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \sum_{i=1}^{n} (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2
\]
\end{textbox}

To derive the expressions for $\hat{\beta_0}$ and $\hat{\beta_1}$, we have to take the partial derivatives of $RSS$ with respect to $\hat{\beta_0}$ and $\hat{\beta_1}$ and set them to zero.

\begin{align*}
    \dfrac{\partial}{\partial \hat{\beta_0}} (RSS) &=-2\sum_{i=1}^{n} (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) = 0,\\ \dfrac{\partial}{\partial \hat{\beta_1}} (RSS) &= -2\sum_{i=1}^{n} (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)x_i = 0
\end{align*}

Simplifying these two equations yields
\begin{align*}
 n\hat{\beta}_0 + \hat{\beta}_1 \sum_{i=1}^{n}x_i &= \sum_{i=1}^{n} y_i, \\
\hat{\beta}_0\sum_{i=1}^{n}  x_i + \hat{\beta}_1 \sum_{i=1}^{n}x_i^2 &= \sum_{i=1}^{n} y_i x_i
\end{align*}

Multiplying the first equation by $\sum_{i=1}^n x_i$ and second equation by $n$ and then subtracting second from the first yields
$$\left(\sum_{i=1}^{n} x_i\right)\left(\sum_{i=1}^{n} y_i\right) - n\sum_{i=1}^{n} x_i y_i = \hat{\beta}_1\left(\sum_{i=1}^{n} x_i\right)^2 - n\hat{\beta}_1\sum_{i=1}^{n} x_i^2  $$

Thus we get the expression for $\hat{\beta}_1$

\begin{align*}
    \hat{\beta}_1 &= \dfrac{n\sum_{i=1}^{n} x_i y_i-\left(\sum_{i=1}^{n} x_i\right)\left(\sum_{i=1}^{n} y_i\right)}{n\sum_{i=1}^{n} x_i^2-\left(\sum_{i=1}^{n} x_i\right)^2} \\
    &= \dfrac{\sum_{i=1}^{n} x_i y_i-\frac{1}{n}\left(\sum_{i=1}^{n} x_i\right)\left(\sum_{i=1}^{n} y_i\right)}{\sum_{i=1}^{n} x_i^2-\frac{1}{n}\left(\sum_{i=1}^{n} x_i\right)^2} \\
    % &=\dfrac{\frac{1}{n}\sum_{i=1}^{n} x_i y_i-\overline{x}\overline{y}}{\frac{1}{n}\sum_{i=1}^{n} x_i^2-\overline{x}^2} = \dfrac{\frac{1}{n}\sum_{i=1}^{n} (x_i-\overline{x})(y_i-\overline{y})}{\frac{1}{n}\sum_{i=1}^{n} \left(x_i-\overline{x}\right)^2} \\
    % &= \dfrac{\sum_{i=1}^{n} (x_i-\overline{x})(y_i-\overline{y})}{\sum_{i=1}^{n} \left(x_i-\overline{x}\right)^2}
\end{align*}

It is convenient to introduce some notation for the sums of squared deviation from mean and sums of cross-products of deviation.

\begin{textbox}
\begin{align*}
S_{xx} &= \sum_{i=1}^{n} (x_i - \overline{x})^2 = \sum_{i=1}^{n} x_i^2 - \frac{1}{n}\left( \sum_{i=1}^{n} x_i \right)^2 \\
S_{yy} &= \sum_{i=1}^{n} (y_i - \overline{y})^2 = \sum_{i=1}^{n} y_i^2 - \frac{1}{n}\left( \sum_{i=1}^{n} y_i \right)^2 \\
S_{xy} &= \sum_{i=1}^{n} (x_i - \overline{x})(y_i - \overline{y}) = \sum_{i=1}^{n} x_i y_i - \frac{1}{n}\left( \sum_{i=1}^{n} x_i \right) \left( \sum_{i=1}^{n} y_i \right)
\end{align*}
\end{textbox}

Using these notation we can write,
\begin{textbox}
$$\hat{\beta}_1 = \dfrac{S_{xy}}{S_{xx}}$$
\end{textbox}
The expression for $\hat{\beta}_0$ is calculated as
\begin{textbox}
\[
\hat{\beta}_0 = \overline{y} - \hat{\beta}_1 \overline{x}
\]
\end{textbox}

\subsection{Calculation of RSS}
We can now calculate the value of RSS based on the value of $\hat{\beta}_0$ and $\hat{\beta}_0$ found using the method of least square:

\begin{align*}
\text{RSS} &= \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \\
&= \sum_{i=1}^{n} \left[ y_i - (\hat{\beta}_0 + \hat{\beta}_1x_i) \right]^2 \qquad \text{Since }\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1x_i\\
&= \sum_{i=1}^{n} \left[ y_i - (\overline{y} - \hat{\beta}_1 \overline{x} + \hat{\beta}_1x_i) \right]^2 \qquad \text{Since }\hat{\beta}_0 = \overline{y} - \hat{\beta}_1 \overline{x}\\
&= \sum_{i=1}^{n} \left[ (y_i - \overline{y}) - \hat{\beta}_1 (x_i - \overline{x}) \right]^2 \\
&= \sum_{i=1}^{n} (y_i - \overline{y})^2 - 2\hat{\beta}_1 \sum_{i=1}^{n} (y_i - \overline{y})(x_i - \overline{x}) + \hat{\beta}_1^2 \sum_{i=1}^{n} (x_i - \overline{x})^2 \\
\end{align*}
\begin{align*}
&= S_{yy} - 2\hat{\beta}_1 S_{xy} + \hat{\beta}_1^2 S_{xx}\\
&= S_{yy} - 2\left( \frac{S_{xy}}{S_{xx}} \right) S_{xy} + \left( \frac{S_{xy}}{S_{xx}} \right)^2 S_{xx} \qquad \text{Since }\hat{\beta}_1 = \dfrac{S_{xy}}{S_{xx}} \\
&= S_{yy} - \frac{2 S_{xy}^2}{S_{xx}} + \frac{S_{xy}^2}{S_{xx}} \\
&= S_{yy} - \frac{S_{xy}^2}{S_{xx}} \\
&= S_{yy} - \hat{\beta}_1 S_{xy}
\end{align*}

\begin{textbox}
    $$\text{RSS} = S_{yy} - \hat{\beta}_1 S_{xy}$$
\end{textbox}

\subsection{Example}

We aim to model the relationship between the number of hours studied (\(X\)) and the corresponding test score (\(Y\)) using simple linear regression. The goal is to estimate a linear equation that best describes this relationship based on observed data from five students. Once the model is established, we will use it to predict the expected test score for a student who studies for six hours.

The observed data are as follows:

\begin{center}
\begin{tabular}{ccc}
\toprule
\textbf{Student} & \textbf{Hours Studied} (\(x_i\)) & \textbf{Test Score} (\(y_i\)) \\
\midrule
1 & 2 & 65 \\
2 & 3 & 70 \\
3 & 5 & 75 \\
4 & 7 & 85 \\
5 & 9 & 95 \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Step 1: Compute Means}

\begin{align*}
    \overline{x} &= \frac{2 + 3 + 5 + 7 + 9}{5} = \frac{26}{5} = 5.2, \\
\overline{y} &= \frac{65 + 70 + 75 + 85 + 95}{5} = \frac{390}{5} = 78
\end{align*}

\textbf{Step 2: Compute $S_{xx}$ and $S_{xy}$}

\begin{align*}
    S_{xx} &= \sum (x_i - \overline{x})^2 \\
    &= (2 - 5.2)^2 + (3 - 5.2)^2 + (5 - 5.2)^2 + (7 - 5.2)^2 + (9 - 5.2)^2 \\
    &= 32.8
\end{align*}

\begin{align*}
    S_{xy} &= \sum (x_i - \overline{x})(y_i - \overline{y}) \\
    &= (2 - 5.2)(65 - 78) + (3 - 5.2)(70 - 78) + \ldots + (9 - 5.2)(95 - 78) \\
    &= 137.0
\end{align*}


\textbf{Step 3: Estimate Parameters}

\[
\hat{\beta}_1 = \frac{S_{xy}}{S_{xx}} = \frac{137.0}{32.80}\approx4.177
\]

\[
\hat{\beta}_0 = \overline{y} - \hat{\beta}_1 \overline{x} = 78-4.177\times 5.2\approx56.28
\]

\textbf{Step 4: Regression Equation}

\[
\hat{Y} = 56.28 + 4.177X
\]

\textbf{Step 5: Predict Test Score for $X = 6$}

\[
\hat{Y} = 56.28 + 4.177\times6 \approx 81.34
\]

% \textbf{Step 6: Calculate Residuals and RSS}

% \begin{align*}
%     \text{RSS} &= S_{yy} - \hat{\beta}_1 S_{xy} \\
%     &=580 - (2.317 \cdot 76) = 580 - 176.092 = 403.91
% \end{align*}

% \begin{center}
% \begin{tabular}{cccc}
% \toprule
% $x_i$ & $y_i$ & $\hat{y}_i$ & Residual $\epsilon_i = y_i - \hat{y}_i$ \\
% \midrule
% 2 & 65 & $65.96 + 2.317(2) = 70.594$ & $65 - 70.594 = -5.594$ \\
% 3 & 70 & $65.96 + 2.317(3) = 72.911$ & $70 - 72.911 = -2.911$ \\
% 5 & 75 & $65.96 + 2.317(5) = 77.545$ & $75 - 77.545 = -2.545$ \\
% 7 & 85 & $65.96 + 2.317(7) = 82.179$ & $85 - 82.179 = 2.821$ \\
% 9 & 95 & $65.96 + 2.317(9) = 86.813$ & $95 - 86.813 = 8.187$ \\
% \bottomrule
% \end{tabular}
% \end{center}

% \[
% \text{RSS} = \sum_{i=1}^5 \epsilon_i^2 = (-5.594)^2 + (-2.911)^2 + (-2.545)^2 + (2.821)^2 + (8.187)^2
% \]

% \[
% \text{RSS} = 31.30 + 8.47 + 6.48 + 7.96 + 67.02 = \boxed{121.23}
% \]

\begin{center}
\begin{tikzpicture}
\begin{axis}[
    width=11cm,
    height=7cm,
    xlabel={Hours studied ($X$)},
    ylabel={Test score ($Y$)},
    axis lines=left,
    xmin=0, xmax=10,
    ymin=50, ymax=100,
    enlargelimits=true,
    clip=false
]

% Scatter data points
\addplot[
    only marks,
    color=blue,
    mark=*,
    mark size=2pt
] coordinates {
    (2,65) (3,70) (5,75) (7,85) (9,95)
};

% Regression line y = x
\addplot[
    domain=0:10,
    samples=2,
    color=black,
    very thick
] {56.28 + 4.177*x};


\node[black] at (axis cs:3.8,92) {\small $\hat{Y} = 56.28 + 4.177X$};
\draw[->, thin] (axis cs:3.8,90) -- (axis cs:3.8,72.4);
\draw[dashed, thin] (axis cs:-1,81.34) -- (axis cs:6,81.34);
\draw[dashed, thin] (axis cs:6,45) -- (axis cs:6,81.34);
\node[black] at (axis cs:1.2,65) {\small $(2,65)$};
\node[black] at (axis cs:2.2,70) {\small $(3,70)$};
\node[black] at (axis cs:5.1,72) {\small $(5,75)$};
\node[black] at (axis cs:7.8,85) {\small $(7,85)$};
\node[black] at (axis cs:8.2,95) {\small $(9,95)$};
\node[purple] at (axis cs:7,80) {\small $(6,81.34)$};

\end{axis}
\end{tikzpicture}
\end{center}

\end{document}
